{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4367,"status":"ok","timestamp":1663316653167,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"m_fG6lRj7mGy","outputId":"7fe2bb85-baea-4674-89a3-92904b15d58f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663316655251,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"xcdKG22C8Ltt"},"outputs":[],"source":["import os\n","os.listdir(\"./drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest\")\n","os.chdir(\"./drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest\") "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663316658290,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"8rhl1egXLC0b","outputId":"e0770208-4b49-48e3-df6a-efc7520911af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['README.md',\n"," 'Training and Results.md',\n"," 'required_packages.txt',\n"," 'Vulnerable Functions Statistical Analysis.md',\n"," 'Graph',\n"," 'src',\n"," 'Data',\n"," 'config',\n"," '.git',\n"," 'result',\n"," 'logs',\n"," 'data',\n"," 'main.py',\n"," 'Word_to_vec_embedding.py',\n"," 'Untitled0.ipynb']"]},"metadata":{},"execution_count":3}],"source":["os.listdir(\"./\")"]},{"cell_type":"code","source":["import zipfile\n","from pathlib import Path\n","from zipfile import ZipFile\n","\n","def zip_comporession(source, target):\n","  with ZipFile(target, mode='w') as zf:\n","    for path, dirName, fileName in os.walk(source):\n","      path = Path(path)\n","      arcDir = path.relative_to(source)\n","      for filename in fileName:\n","        zf.write(path.joinpath(filename), arcDir.joinpath(filename))\n","zip_comporession(\"README.md\", 'try')"],"metadata":{"id":"qduCoF3FZhG5","executionInfo":{"status":"ok","timestamp":1663316677544,"user_tz":-480,"elapsed":2,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3775,"status":"ok","timestamp":1659334450348,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"rcSumrduBh0u","outputId":"0e89c882-8369-4bc0-d20f-e245ab2770ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"]}],"source":["!pip install scipy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3KKPBzrybT0"},"outputs":[],"source":["!pip install tensorflow-gpu==1.15.0\n","!pip install tensorflow==1.15\n","#!pip install \"tensorflow_hub>=0.6.0\"\n","#!pip3 install tensorflow_text==1.15\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0f2r7pH9r91"},"outputs":[],"source":["!pip install keras==2.3.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1ZaxHno0o87"},"outputs":[],"source":["!pip install --upgrade tensorflow-gpu\n","!pip install --upgrade tensorflow\n","!pip3 install --upgrade tensorflow_text\n","!pip install --upgrade keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57803,"status":"ok","timestamp":1659357383288,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"Y7O4WAfZZNI1","outputId":"9033dd48-9fc1-4db9-ce12-a7acbae2ecb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be upgraded:\n","  libcudnn8\n","1 upgraded, 0 newly installed, 1 to remove and 47 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 3,139 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 7s (60.7 MB/s)\n","(Reading database ... 155673 files and directories currently installed.)\n","Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n","(Reading database ... 155651 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}],"source":["!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiENEtPaYGIt"},"outputs":[],"source":["!pip install --upgrade tensorflow-gpu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCEyC3n-CDgY"},"outputs":[],"source":["import zipfile\n","\n","zip_ref1 = zipfile.ZipFile(\"./Data/LibPNG.zip\", 'r')\n","zip_ref2 = zipfile.ZipFile(\"./Data/Pidgin.zip\", 'r')\n","zip_ref3 = zipfile.ZipFile(\"./Data/VLC.zip\", 'r')\n","\n","zip_ref1.extractall(\"./Data/\")\n","zip_ref2.extractall(\"./Data/\")\n","zip_ref3.extractall(\"./Data/\")\n","\n","zip_ref1.close()\n","zip_ref2.close()\n","zip_ref3.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdm73hFRG3GX"},"outputs":[],"source":["zip_ref3 = zipfile.ZipFile(\"./Data/VLC.zip\", 'r')\n","zip_ref3.extractall(\"./Data/VLC\")\n","zip_ref3.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48776,"status":"ok","timestamp":1663314630786,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"3RQHd6h49I-R","outputId":"72f21ed2-10a4-48a1-990d-8f9b99e2d0ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data/LibPNG/\n","[['void', 'PNGAPI', 'png_read_row', '(', 'png_structrp', 'png_ptr', ',', 'png_bytep', 'row', ',', 'png_bytep', 'dsp_row', ')', '{', 'png_row_info', 'row_info', ';', 'if', '(', 'png_ptr', '=', '=', 'NULL', ')', 'return', ';', 'png_debug2', '(', '1', ',', '\"', 'in', 'png_read_row', '(', 'row', '%lu', ',', 'pass', '%d', ')', '\"', ',', '(', 'unsigned', 'long', ')', 'png_ptr', '-', '>', 'row_number', ',', 'png_ptr', '-', '>', 'pass', ')', ';', 'if', '(', '!', '(', 'png_ptr', '-', '>', 'flags', '&', 'PNG_FLAG_ROW_INIT', ')', ')', 'png_read_start_row', '(', 'png_ptr', ')', ';', 'row_info.width', '=', 'png_ptr', '-', '>', 'iwidth', ';', 'row_info.color_type', '=', 'png_ptr', '-', '>', 'color_type', ';', 'row_info.bit_depth', '=', 'png_ptr', '-', '>', 'bit_depth', ';', 'row_info.channels', '=', 'png_ptr', '-', '>', 'channels', ';', 'row_info.pixel_depth', '=', 'png_ptr', '-', '>', 'pixel_depth', ';', 'row_info.rowbytes', '=', 'PNG_ROWBYTES', '(', 'row_info.pixel_depth', ',', 'row_info.width', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'row_number', '=', '=', '0', '&&', 'png_ptr', '-', '>', 'pass', '=', '=', '0', ')', '{', '#if', 'defined', '(', 'PNG_WRITE_INVERT_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_INVERT_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_INVERT_MONO', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_INVERT_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_FILLER_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_FILLER_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_FILLER', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_FILLER_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_PACKSWAP_SUPPORTED', ')', '&&', '\\\\', '!defined', '(', 'PNG_READ_PACKSWAP_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_PACKSWAP', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_PACKSWAP_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_PACK_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_PACK_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_PACK', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_PACK_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_SHIFT_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_SHIFT_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_SHIFT', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_SHIFT_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_BGR_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_BGR_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_BGR', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_BGR_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_SWAP_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_SWAP_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_SWAP_BYTES', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_SWAP_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '}', '#ifdef', 'PNG_READ_INTERLACING_SUPPORTED', 'if', '(', 'png_ptr', '-', '>', 'interlaced', '&&', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_INTERLACE', ')', ')', '{', 'switch', '(', 'png_ptr', '-', '>', 'pass', ')', '{', 'case', '0:', 'if', '(', 'png_ptr', '-', '>', 'row_number', '&', '0x07', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '1:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '0x07', ')', '||', 'png_ptr', '-', '>', 'width', '<', '5', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '2:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '0x07', ')', '!', '=', '4', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', '&&', '(', 'png_ptr', '-', '>', 'row_number', '&', '4', ')', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '3:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '3', ')', '||', 'png_ptr', '-', '>', 'width', '<', '3', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '4:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '3', ')', '!', '=', '2', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', '&&', '(', 'png_ptr', '-', '>', 'row_number', '&', '2', ')', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '5:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '1', ')', '||', 'png_ptr', '-', '>', 'width', '<', '2', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'default:', 'case', '6:', 'if', '(', '!', '(', 'png_ptr', '-', '>', 'row_number', '&', '1', ')', ')', '{', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', '}', '}', '#endif', 'if', '(', '!', '(', 'png_ptr', '-', '>', 'mode', '&', 'PNG_HAVE_IDAT', ')', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'Invalid', 'attempt', 'to', 'read', 'row', 'data', '\"', ')', ';', 'png_read_IDAT_data', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'row_buf', ',', 'row_info.rowbytes', '+', '1', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'row_buf', '[', '0', ']', '>', 'PNG_FILTER_VALUE_NONE', ')', '{', 'if', '(', 'png_ptr', '-', '>', 'row_buf', '[', '0', ']', '<', 'PNG_FILTER_VALUE_LAST', ')', 'png_read_filter_row', '(', 'png_ptr', ',', '&row_info', ',', 'png_ptr', '-', '>', 'row_buf', '+', '1', ',', 'png_ptr', '-', '>', 'prev_row', '+', '1', ',', 'png_ptr', '-', '>', 'row_buf', '[', '0', ']', ')', ';', 'else', 'png_error', '(', 'png_ptr', ',', '\"', 'bad', 'adaptive', 'filter', 'value', '\"', ')', ';', '}', 'memcpy', '(', 'png_ptr', '-', '>', 'prev_row', ',', 'png_ptr', '-', '>', 'row_buf', ',', 'row_info.rowbytes', '+', '1', ')', ';', '#ifdef', 'PNG_MNG_FEATURES_SUPPORTED', 'if', '(', '(', 'png_ptr', '-', '>', 'mng_features_permitted', '&', 'PNG_FLAG_MNG_FILTER_64', ')', '&&', '(', 'png_ptr', '-', '>', 'filter_type', '=', '=', 'PNG_INTRAPIXEL_DIFFERENCING', ')', ')', '{', 'png_do_read_intrapixel', '(', '&row_info', ',', 'png_ptr', '-', '>', 'row_buf', '+', '1', ')', ';', '}', '#endif', '#ifdef', 'PNG_READ_TRANSFORMS_SUPPORTED', 'if', '(', 'png_ptr', '-', '>', 'transformations', ')', 'png_do_read_transformations', '(', 'png_ptr', ',', '&row_info', ')', ';', '#endif', 'if', '(', 'png_ptr', '-', '>', 'transformed_pixel_depth', '=', '=', '0', ')', '{', 'png_ptr', '-', '>', 'transformed_pixel_depth', '=', 'row_info.pixel_depth', ';', 'if', '(', 'row_info.pixel_depth', '>', 'png_ptr', '-', '>', 'maximum_pixel_depth', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'sequential', 'row', 'overflow', '\"', ')', ';', '}', 'else', 'if', '(', 'png_ptr', '-', '>', 'transformed_pixel_depth', '!', '=', 'row_info.pixel_depth', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'internal', 'sequential', 'row', 'size', 'calculation', 'error', '\"', ')', ';', '#ifdef', 'PNG_READ_INTERLACING_SUPPORTED', 'if', '(', 'png_ptr', '-', '>', 'interlaced', '&&', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_INTERLACE', ')', ')', '{', 'if', '(', 'png_ptr', '-', '>', 'pass', '<', '6', ')', 'png_do_read_interlace', '(', '&row_info', ',', 'png_ptr', '-', '>', 'row_buf', '+', '1', ',', 'png_ptr', '-', '>', 'pass', ',', 'png_ptr', '-', '>', 'transformations', ')', ';', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'if', '(', 'row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'row', ',', '0', ')', ';', '}', 'else', '#endif', '{', 'if', '(', 'row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'row', ',', '-', '1', ')', ';', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '-', '1', ')', ';', '}', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'read_row_fn', '!', '=', 'NULL', ')', '(', '*', '(', 'png_ptr', '-', '>', 'read_row_fn', ')', ')', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'row_number', ',', 'png_ptr', '-', '>', 'pass', ')', ';', '}', '#endif'], ['void', 'png_formatted_warning', '(', 'png_structp', 'png_ptr', ',', 'png_warning_parameters', 'p', ',', 'png_const_charp', 'message', ')', '{', 'size_t', 'i', ';', 'char', 'msg', '[', '128', ']', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', '(', 'sizeof', 'msg', ')', '-', '1', '&&', '*', 'message', '!', '=', \"'\\\\0'\", ';', '+', '+', 'i', ')', '{', 'if', '(', '*', 'message', '=', '=', \"'@'\", ')', '{', 'int', 'parameter', '=', '-', '1', ';', 'switch', '(', '*', '+', '+', 'message', ')', '{', 'case', \"'1':\", 'parameter', '=', '0', ';', 'break', ';', 'case', \"'2':\", 'parameter', '=', '1', ';', 'break', ';', 'case', \"'\\\\0':\", 'continue', ';', 'default:', 'break', ';', '}', 'if', '(', 'parameter', '>', '=', '0', '&&', 'parameter', '<', 'PNG_WARNING_PARAMETER_COUNT', ')', '{', 'png_const_charp', 'parm', '=', 'p', '[', 'parameter', ']', ';', 'png_const_charp', 'pend', '=', 'p', '[', 'parameter', ']', '+', '(', 'sizeof', 'p', '[', 'parameter', ']', ')', ';', 'for', '(', ';', 'i', '<', '(', 'sizeof', 'msg', ')', '-', '1', '&&', 'parm', '!', '=', \"'\\\\0'\", '&&', 'parm', '<', 'pend', ';', '+', '+', 'i', ')', 'msg', '[', 'i', ']', '=', '*', 'parm', '+', '+', ';', '+', '+', 'message', ';', 'continue', ';', '}', '}', 'msg', '[', 'i', ']', '=', '*', 'message', '+', '+', ';', '}', 'msg', '[', 'i', ']', '=', \"'\\\\0'\", ';', 'png_warning', '(', 'png_ptr', ',', 'msg', ')', ';', '}', '#endif'], ['void', 'png_read_IDAT_data', '(', 'png_structrp', 'png_ptr', ',', 'png_bytep', 'output', ',', 'png_alloc_size_t', 'avail_out', ')', '{', 'png_ptr', '-', '>', 'zstream.next_out', '=', 'output', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', '0', ';', 'if', '(', 'output', '=', '=', 'NULL', ')', 'avail_out', '=', '0', ';', 'do', '{', 'int', 'ret', ';', 'png_byte', 'tmpbuf', '[', 'PNG_INFLATE_BUF_SIZE', ']', ';', 'if', '(', 'png_ptr', '-', '>', 'zstream.avail_in', '=', '=', '0', ')', '{', 'uInt', 'avail_in', ';', 'png_bytep', 'buffer', ';', 'while', '(', 'png_ptr', '-', '>', 'idat_size', '=', '=', '0', ')', '{', 'png_crc_finish', '(', 'png_ptr', ',', '0', ')', ';', 'png_ptr', '-', '>', 'idat_size', '=', 'png_read_chunk_header', '(', 'png_ptr', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'chunk_name', '!', '=', 'png_IDAT', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'Not', 'enough', 'image', 'data', '\"', ')', ';', '}', 'avail_in', '=', 'png_ptr', '-', '>', 'IDAT_read_size', ';', 'if', '(', 'avail_in', '>', 'png_ptr', '-', '>', 'idat_size', ')', 'avail_in', '=', '(', 'uInt', ')', 'png_ptr', '-', '>', 'idat_size', ';', 'buffer', '=', 'png_read_buffer', '(', 'png_ptr', ',', 'avail_in', ',', '0', ')', ';', 'png_crc_read', '(', 'png_ptr', ',', 'buffer', ',', 'avail_in', ')', ';', 'png_ptr', '-', '>', 'idat_size', '-', '=', 'avail_in', ';', 'png_ptr', '-', '>', 'zstream.next_in', '=', 'buffer', ';', 'png_ptr', '-', '>', 'zstream.avail_in', '=', 'avail_in', ';', '}', 'if', '(', 'output', '!', '=', 'NULL', ')', '{', 'uInt', 'out', '=', 'ZLIB_IO_MAX', ';', 'if', '(', 'out', '>', 'avail_out', ')', 'out', '=', '(', 'uInt', ')', 'avail_out', ';', 'avail_out', '-', '=', 'out', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', 'out', ';', '}', 'else', '{', 'png_ptr', '-', '>', 'zstream.next_out', '=', 'tmpbuf', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', '(', 'sizeof', 'tmpbuf', ')', ';', '}', 'ret', '=', 'inflate', '(', '&png_ptr', '-', '>', 'zstream', ',', 'Z_NO_FLUSH', ')', ';', 'if', '(', 'output', '!', '=', 'NULL', ')', 'avail_out', '+', '=', 'png_ptr', '-', '>', 'zstream.avail_out', ';', 'else', 'avail_out', '+', '=', '(', 'sizeof', 'tmpbuf', ')', '-', 'png_ptr', '-', '>', 'zstream.avail_out', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', '0', ';', 'if', '(', 'ret', '=', '=', 'Z_STREAM_END', ')', '{', 'png_ptr', '-', '>', 'zstream.next_out', '=', 'NULL', ';', 'png_ptr', '-', '>', 'mode', '|', '=', 'PNG_AFTER_IDAT', ';', 'png_ptr', '-', '>', 'flags', '|', '=', 'PNG_FLAG_ZSTREAM_ENDED', ';', 'if', '(', 'png_ptr', '-', '>', 'zstream.avail_in', '>', '0', '||', 'png_ptr', '-', '>', 'idat_size', '>', '0', ')', 'png_chunk_benign_error', '(', 'png_ptr', ',', '\"', 'Extra', 'compressed', 'data', '\"', ')', ';', 'break', ';', '}', 'if', '(', 'ret', '!', '=', 'Z_OK', ')', '{', 'png_zstream_error', '(', 'png_ptr', ',', 'ret', ')', ';', 'if', '(', 'output', '!', '=', 'NULL', ')', 'png_chunk_error', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'zstream.msg', ')', ';', 'else', '{', 'png_chunk_benign_error', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'zstream.msg', ')', ';', 'return', ';', '}', '}', '}', 'while', '(', 'avail_out', '>', '0', ')', ';', 'if', '(', 'avail_out', '>', '0', ')', '{', 'if', '(', 'output', '!', '=', 'NULL', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'Not', 'enough', 'image', 'data', '\"', ')', ';', 'else', 'png_chunk_benign_error', '(', 'png_ptr', ',', '\"', 'Too', 'much', 'image', 'data', '\"', ')', ';', '}', '}'], ['void', 'png_do_expand_palette', '(', 'png_row_infop', 'row_info', ',', 'png_bytep', 'row', ',', 'png_const_colorp', 'palette', ',', 'png_const_bytep', 'trans_alpha', ',', 'int', 'num_trans', ')', '{', 'int', 'shift', ',', 'value', ';', 'png_bytep', 'sp', ',', 'dp', ';', 'png_uint_32', 'i', ';', 'png_uint_32', 'row_width', '=', 'row_info', '-', '>', 'width', ';', 'png_debug', '(', '1', ',', '\"', 'in', 'png_do_expand_palette', '\"', ')', ';', 'if', '(', 'row_info', '-', '>', 'color_type', '=', '=', 'PNG_COLOR_TYPE_PALETTE', ')', '{', 'if', '(', 'row_info', '-', '>', 'bit_depth', '<', '8', ')', '{', 'switch', '(', 'row_info', '-', '>', 'bit_depth', ')', '{', 'case', '1:', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', '(', '(', 'row_width', '-', '1', ')', '>', '>', '3', ')', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'shift', '=', '7', '-', '(', 'int', ')', '(', '(', 'row_width', '+', '7', ')', '&', '0x07', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'if', '(', '(', '*', 'sp', '>', '>', 'shift', ')', '&', '0x01', ')', '*', 'dp', '=', '1', ';', 'else', '*', 'dp', '=', '0', ';', 'if', '(', 'shift', '=', '=', '7', ')', '{', 'shift', '=', '0', ';', 'sp', '-', '-', ';', '}', 'else', 'shift', '+', '+', ';', 'dp', '-', '-', ';', '}', 'break', ';', '}', 'case', '2:', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', '(', '(', 'row_width', '-', '1', ')', '>', '>', '2', ')', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'shift', '=', '(', 'int', ')', '(', '(', '3', '-', '(', '(', 'row_width', '+', '3', ')', '&', '0x03', ')', ')', '<', '<', '1', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'value', '=', '(', '*', 'sp', '>', '>', 'shift', ')', '&', '0x03', ';', '*', 'dp', '=', '(', 'png_byte', ')', 'value', ';', 'if', '(', 'shift', '=', '=', '6', ')', '{', 'shift', '=', '0', ';', 'sp', '-', '-', ';', '}', 'else', 'shift', '+', '=', '2', ';', 'dp', '-', '-', ';', '}', 'break', ';', '}', 'case', '4:', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', '(', '(', 'row_width', '-', '1', ')', '>', '>', '1', ')', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'shift', '=', '(', 'int', ')', '(', '(', 'row_width', '&', '0x01', ')', '<', '<', '2', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'value', '=', '(', '*', 'sp', '>', '>', 'shift', ')', '&', '0x0f', ';', '*', 'dp', '=', '(', 'png_byte', ')', 'value', ';', 'if', '(', 'shift', '=', '=', '4', ')', '{', 'shift', '=', '0', ';', 'sp', '-', '-', ';', '}', 'else', 'shift', '+', '=', '4', ';', 'dp', '-', '-', ';', '}', 'break', ';', '}', 'default:', 'break', ';', '}', 'row_info', '-', '>', 'bit_depth', '=', '8', ';', 'row_info', '-', '>', 'pixel_depth', '=', '8', ';', 'row_info', '-', '>', 'rowbytes', '=', 'row_width', ';', '}', 'else', 'if', '(', 'row_info', '-', '>', 'bit_depth', '=', '=', '8', ')', '{', '{', 'if', '(', 'trans_alpha', '!', '=', 'NULL', ')', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', '(', 'row_width', '<', '<', '2', ')', '-', '1', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'if', '(', '(', 'int', ')', '(', '*', 'sp', ')', '>', '=', 'num_trans', ')', '*', 'dp', '-', '-', '=', '0xff', ';', 'else', '*', 'dp', '-', '-', '=', 'trans_alpha', '[', '*', 'sp', ']', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.blue', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.green', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.red', ';', 'sp', '-', '-', ';', '}', 'row_info', '-', '>', 'bit_depth', '=', '8', ';', 'row_info', '-', '>', 'pixel_depth', '=', '32', ';', 'row_info', '-', '>', 'rowbytes', '=', 'row_width', '*', '4', ';', 'row_info', '-', '>', 'color_type', '=', '6', ';', 'row_info', '-', '>', 'channels', '=', '4', ';', '}', 'else', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', '(', 'row_width', '*', '3', ')', '-', '1', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.blue', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.green', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.red', ';', 'sp', '-', '-', ';', '}', 'row_info', '-', '>', 'bit_depth', '=', '8', ';', 'row_info', '-', '>', 'pixel_depth', '=', '24', ';', 'row_info', '-', '>', 'rowbytes', '=', 'row_width', '*', '3', ';', 'row_info', '-', '>', 'color_type', '=', '2', ';', 'row_info', '-', '>', 'channels', '=', '3', ';', '}', '}', '}', '}', '}'], ['void', 'PNGAPI', 'png_set_unknown_chunks', '(', 'png_structp', 'png_ptr', ',', 'png_infop', 'info_ptr', ',', 'png_const_unknown_chunkp', 'unknowns', ',', 'int', 'num_unknowns', ')', '{', 'png_unknown_chunkp', 'np', ';', 'int', 'i', ';', 'if', '(', 'png_ptr', '=', '=', 'NULL', '||', 'info_ptr', '=', '=', 'NULL', '||', 'num_unknowns', '=', '=', '0', ')', 'return', ';', 'np', '=', '(', 'png_unknown_chunkp', ')', 'png_malloc_warn', '(', 'png_ptr', ',', '(', 'png_size_t', ')', '(', 'info_ptr', '-', '>', 'unknown_chunks_num', '+', 'num_unknowns', ')', '*', 'png_sizeof', '(', 'png_unknown_chunk', ')', ')', ';', 'if', '(', 'np', '=', '=', 'NULL', ')', '{', 'png_warning', '(', 'png_ptr', ',', '\"', 'Out', 'of', 'memory', 'while', 'processing', 'unknown', 'chunk', '\"', ')', ';', 'return', ';', '}', 'png_memcpy', '(', 'np', ',', 'info_ptr', '-', '>', 'unknown_chunks', ',', '(', 'png_size_t', ')', 'info_ptr', '-', '>', 'unknown_chunks_num', '*', 'png_sizeof', '(', 'png_unknown_chunk', ')', ')', ';', 'png_free', '(', 'png_ptr', ',', 'info_ptr', '-', '>', 'unknown_chunks', ')', ';', 'info_ptr', '-', '>', 'unknown_chunks', '=', 'NULL', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'num_unknowns', ';', 'i', '+', '+', ')', '{', 'png_unknown_chunkp', 'to', '=', 'np', '+', 'info_ptr', '-', '>', 'unknown_chunks_num', '+', 'i', ';', 'png_const_unknown_chunkp', 'from', '=', 'unknowns', '+', 'i', ';', 'png_memcpy', '(', 'to', '-', '>', 'name', ',', 'from', '-', '>', 'name', ',', 'png_sizeof', '(', 'from', '-', '>', 'name', ')', ')', ';', 'to', '-', '>', 'name', '[', 'png_sizeof', '(', 'to', '-', '>', 'name', ')', '-', '1', ']', '=', \"'\\\\0'\", ';', 'to', '-', '>', 'size', '=', 'from', '-', '>', 'size', ';', 'to', '-', '>', 'location', '=', '(', 'png_byte', ')', '(', 'png_ptr', '-', '>', 'mode', '&', '0xff', ')', ';', 'if', '(', 'from', '-', '>', 'size', '=', '=', '0', ')', 'to', '-', '>', 'data', '=', 'NULL', ';', 'else', '{', 'to', '-', '>', 'data', '=', '(', 'png_bytep', ')', 'png_malloc_warn', '(', 'png_ptr', ',', '(', 'png_size_t', ')', 'from', '-', '>', 'size', ')', ';', 'if', '(', 'to', '-', '>', 'data', '=', '=', 'NULL', ')', '{', 'png_warning', '(', 'png_ptr', ',', '\"', 'Out', 'of', 'memory', 'while', 'processing', 'unknown', 'chunk', '\"', ')', ';', 'to', '-', '>', 'size', '=', '0', ';', '}', 'else', 'png_memcpy', '(', 'to', '-', '>', 'data', ',', 'from', '-', '>', 'data', ',', 'from', '-', '>', 'size', ')', ';', '}', '}', 'info_ptr', '-', '>', 'unknown_chunks', '=', 'np', ';', 'info_ptr', '-', '>', 'unknown_chunks_num', '+', '=', 'num_unknowns', ';', 'info_ptr', '-', '>', 'free_me', '|', '=', 'PNG_FREE_UNKN', ';', '}']]\n","['cve-2014-9495.c', 'cve-2011-3464.c', 'cve-2015-0973.c', 'cve-2011-0408-1.c', 'cve-2013-7353.c', 'cve-2004-0599-2.c', 'CVE-2018-14048.c', 'cve-2008-6218.c', 'cve-2011-3045.c', 'cve-2011-2501.c', 'cve-2013-7354-2.c', 'cve-2004-0597-3.c', 'cve-2014-0333.c', 'cve-2007-5267.c', 'cve-2009-0040.c', 'cve-2007-2445.c', 'cve-2010-0205.c', 'cve-2004-0599-1.c', 'cve-2012-3425.c', 'cve-2011-0408-2.c', 'cve-2011-3048.c', 'cve-2016-10087.c', 'cve-2013-7354-1.c', 'cve-2009-5063.c', 'cve-2007-5266.c', 'cve-2007-5269-1.c', 'cve-2015-8126_2.c', 'cve-2006-7244.c', 'cve-2006-5793.c', 'cve-2015-7981.c', 'cve-2006-0481.c', 'CVE-2018-13785.c', 'cve-2013-6954.c', 'cve-2007-5629-3.c', 'cve-2015-8472.c', 'cve-2004-0597-1.c', 'cve-2011-3328.c', 'cve-2007-5269-2.c', 'cve-2011-2692.c', 'cve-2015-8540.c', 'cve-2004-0598.c', 'cve-2006-3334.c', 'cve-2015-8126_1.c', 'cve-2008-5907.c', 'cve-2004-0597-2.c', '0155_pngstest.c_gp_ga16.c', '0412_rpng2-x.c_rpng2_x_msb.c', '058_pngstest.c_cmppixel.c', '047_pngimage.c_display_clean_write.c', '0071_pngfix.c_main.c', '0193_pngstest.c_sRGB.c', '0015_fakepng.c_put_chunk.c', '0189_pngstest.c_random_color.c', '0046_png-fix-itxt.c_main.c', '080_pngstest.c_logpixel.c', '160_pngvalid.c_store_read.c', '188_rpng2-win.c_WinMain.c', '0280_pngvalid.c_make_size.c', '0315_pngvalid.c_print_one.c', '0268_pngvalid.c_image_transform_png_set_tRNS_to_alpha_set.c', '0411_rpng2-x.c_rpng2_x_load_bg_image.c', '127_pngvalid.c_pcerr.c', '0009_VisualPng.c_WndProc.c', '018_makepng.c_pixel_depth_of_type.c', '133_pngvalid.c_perform_standard_test.c', '0031_makepng.c_insert_zTXt.c', '0056_pngfix.c_clear.c', '103_pngvalid.c_image_pixel_setf.c', '0150_pngstest.c_gp_bgr8.c', '0428_tarith.c_png_log8bit.c', '0190_pngstest.c_read_file.c', '0297_pngvalid.c_modifier_total_encodings.c', '152_pngvalid.c_standard_name.c', '0429_tarith.c_png_log16bit.c', '129_pngvalid.c_perform_formatting_test.c', '161_pngvalid.c_store_read_buffer_avail.c', '087_pngtest.c_read_user_chunk_callback.c', '0377_pngvalid.c_white_point.c', '0209_pngunknown.c_PNG_FUNCTION.c', '157_pngvalid.c_store_image_free.c', '185_rpng-win.c_rpng_win_display_image.c', '0194_pngstest.c_test_one_file.c', '0259_pngvalid.c_image_transform_png_set_rgb_to_gray_mod.c', '0329_pngvalid.c_set_store_for_write.c', '0417_rpng2-win.c_rpng2_win_finish_display.c', '0137_pngstest.c_check16.c', '065_pngstest.c_gp_ag16.c', '015_makepng.c_clear_text.c', '0067_pngfix.c_get_control.c', '0328_pngvalid.c_sequential_row.c', '0339_pngvalid.c_standard_name_from_id.c', '0266_pngvalid.c_image_transform_png_set_strip_alpha_set.c', '0424_tarith.c_main.c', '061_pngstest.c_freebuffer.c', '094_pngunknown.c_usage.c', '059_pngstest.c_component_loc.c', '0283_pngvalid.c_make_standard_palette.c', '178_pnm2png.c_usage.c', '0126_pngimage.c_read_png.c', '0407_rpng2-x.c_rpng2_x_cleanup.c', '0040_makepng.c_set_text.c', '0372_pngvalid.c_transform_end.c', '0197_pngstest.c_u16d.c', '0019_linux-auxv.c_png_have_neon.c', '0181_pngstest.c_initimage.c', '0035_makepng.c_make_insert.c', '0332_pngvalid.c_standard_end.c', '0367_pngvalid.c_store_write.c', '0237_pngvalid.c_gama_modification_init.c', '0207_pngtest.c_write_row_callback.c', '167_pngvalid.c_store_write_palette.c', '101_pngvalid.c_image_pixel_add_alpha.c', '0141_pngstest.c_compare_two_images.c', '0025_makepng.c_generate_palette.c', '014_linux.c_png_have_neon.c', '046_pngimage.c_buffer_start_write.c', '038_pngfix.c_type_sep.c', '0144_pngstest.c_format_is_initial.c', '0039_makepng.c_set_color.c', '0131_pngpixel.c_main.c', '162_pngvalid.c_store_read_buffer_size.c', '113_pngvalid.c_image_transform_png_set_palette_to_rgb_mod.c', '0176_pngstest.c_gpc_unpc.c', '0210_pngunknown.c_ancillary.c', '110_pngvalid.c_image_transform_png_set_expand_gray_1_2_4_to_8_mod.c', '0135_pngstest.c_YfromRGBint.c', '0177_pngstest.c_ilinear.c', '0069_pngfix.c_global_end.c', '195_writepng.c_writepng_error_handler.c', '0439_wpng.c_main.c', '019_makesRGB.c_finvsRGB.c', '0321_pngvalid.c_sBIT0_error_fn.c', '148_pngvalid.c_signal_handler.c', '0445_writepng.c_writepng_version_info.c', '144_pngvalid.c_sample_scale.c', '0278_pngvalid.c_make_four_random_bytes.c', '0017_iccfrompng.c_extract_one_file.c', '0103_pngfix.c_zlib_end.c', '0423_tarith.c_check_some_characters.c', '0139_pngstest.c_checkopaque.c', '0041_makepng.c_set_value.c', '0184_pngstest.c_main.c', '0416_rpng2-win.c_rpng2_win_display_row.c', '045_pngimage.c_buffer_read.c', '0350_pngvalid.c_store_free.c', '0355_pngvalid.c_store_log.c', '158_pngvalid.c_store_image_row.c', '0263_pngvalid.c_image_transform_png_set_strip_16_add.c', '0440_wpng.c_wpng_cleanup.c', '0001_PngFile.c_PngFileInitialize.c', '154_pngvalid.c_standard_test.c', '056_pngpixel.c_component.c', '0292_pngvalid.c_modifier_read.c', '0432_tarith.c_validation_checkfp.c', '138_pngvalid.c_png_pass_cols.c', '081_pngstest.c_transform_from_formats.c', '0401_rpng-win.c_repl_getch.c', '0299_pngvalid.c_normalize_color_encoding.c', '0165_pngstest.c_gpc_bckc.c', '131_pngvalid.c_perform_gamma_scale16_tests.c', '0306_pngvalid.c_perform_size_test.c', '037_pngfix.c_type_name.c', '0379_pngwio.c_png_default_write_data.c', '0104_pngfix.c_zlib_flevel.c', '0199_pngtest.c_count_zero_samples.c', '0172_pngstest.c_gpc_sCp.c', '0368_pngvalid.c_test_size.c', '004_PngFile.c_PngSaveImage.c', '0011_checksum-icc.c_read_one_file.c', '0124_pngimage.c_main.c', '0226_pngvalid.c_abserr.c', '0048_png2pnm.c_usage.c', '0148_pngstest.c_gp_ag8.c', '117_pngvalid.c_image_transform_png_set_strip_16_mod.c', '106_pngvalid.c_image_transform_png_set_background_set.c', '0250_pngvalid.c_image_transform_ini_end.c', '183_readpng2.c_readpng2_init.c', '0044_makesRGB.c_main.c', '067_pngstest.c_gp_bgra16.c', '002_PngFile.c_PngFileSaveDlg.c', '0325_pngvalid.c_safecatn.c', '0205_pngtest.c_pngtest_write_data.c', '0130_pngimage.c_write_png.c', '0319_pngvalid.c_randomize.c', '0232_pngvalid.c_chromaticity_x.c', '159_pngvalid.c_store_message.c', '0034_makepng.c_main.c', '187_rpng2-x.c_rpng2_x_reload_bg_image.c', '0218_pngunknown.c_get_unknown.c', '0427_tarith.c_png_fixed_warning.c', '0014_fakepng.c_main.c', '0213_pngunknown.c_check_handling.c', '0387_readpng.c_readpng_cleanup.c', '0021_makepng.c_bad_parameter_count.c', '0369_pngvalid.c_test_standard.c', '0360_pngvalid.c_store_pool_init.c', '0431_tarith.c_validation_ascii_to_fp.c', '0277_pngvalid.c_make_errors.c', '0309_pngvalid.c_png_pass_row_shift.c', '0023_makepng.c_check_param_count.c', '0392_readpng2.c_readpng2_check_sig.c', '168_pngvalid.c_store_write_reset.c', '082_pngtest.c_count_filters.c', '0059_pngfix.c_crc_one_byte.c', '088_pngunknown.c_ancillaryb.c', '0398_readppm.c_readpng_init.c', '0373_pngvalid.c_transform_image_validate.c', '0305_pngvalid.c_perform_interlace_macro_validation.c', '0304_pngvalid.c_perform_gamma_threshold_tests.c', '0352_pngvalid.c_store_freenew.c', '0028_makepng.c_insert_hIST.c', '044_pngimage.c_buffer_from_file.c', '0361_pngvalid.c_store_pool_mark.c', '0167_pngstest.c_gpc_g8.c', '0430_tarith.c_png_warning.c', '0064_pngfix.c_error_handler.c', '086_pngtest.c_read_row_callback.c', '063_pngstest.c_get_pixel.c', '0153_pngstest.c_gp_g16.c', '0186_pngstest.c_newimage.c', '0296_pngvalid.c_modifier_setbuffer.c', '0390_readpng2.c_readpng2_decode_data.c', '0234_pngvalid.c_digitize.c', '0422_tarith.c_check_one_character.c', '0230_pngvalid.c_chrm_modification_init.c', '0147_pngstest.c_gp_abgr16.c', '172_pngvalid.c_transform_info.c', '0274_pngvalid.c_interlace_row.c', '0191_pngstest.c_read_one_file.c', '139_pngvalid.c_progressive_row.c', '0346_pngvalid.c_store_current_palette.c', '0389_readpng.c_readpng_version_info.c', '0362_pngvalid.c_store_progressive_read.c', '0359_pngvalid.c_store_pool_error.c', '0173_pngstest.c_gpc_sG.c', '120_pngvalid.c_image_transform_reset_count.c', '0192_pngstest.c_resetimage.c', '0260_pngvalid.c_image_transform_png_set_rgb_to_gray_set.c', '0033_makepng.c_load_file.c', '109_pngvalid.c_image_transform_png_set_expand_gray_1_2_4_to_8_add.c', '009_VisualPng.c_DisplayImage.c', '0117_pngimage.c_display_clean_read.c', '099_pngvalid.c_gamma_info_imp.c', '153_pngvalid.c_standard_row.c', '182_readpng2.c_readpng2_info_callback.c', '076_pngstest.c_gpc_nop6.c', '177_pnm2png.c_main.c', '0281_pngvalid.c_make_size_image.c', '0010_android-ndk.c_png_have_neon.c', '0052_pngfix.c_allocate.c', '0214_pngunknown.c_clean_display.c', '0323_pngvalid.c_safecat_color_encoding.c', '175_pngvalid.c_transform_test.c', '191_timepng.c_perform_one_test.c', '190_tarith.c_png_exp16bit.c', '0076_pngfix.c_process_iTXt.c', '0225_pngvalid.c__set.c', '0371_pngvalid.c_transform_enable.c', '0043_makesRGB.c_fsRGB.c', '128_pngvalid.c_perform_error_test.c', '0122_pngimage.c_is_bad_combo.c', '0239_pngvalid.c_gamma_component_compose.c', '0224_pngvalid.c__mod.c', '0161_pngstest.c_gpc_Lin.c', '0217_pngunknown.c_findb.c', '0272_pngvalid.c_init_standard_palette.c', '073_pngstest.c_gpc_bckg.c', '0353_pngvalid.c_store_image_check.c', '0132_pngpixel.c_print_pixel.c', '068_pngstest.c_gp_g8.c', '0347_pngvalid.c_store_delete.c', '0403_rpng-win.c_rpng_win_create_window.c', '0287_pngvalid.c_modifier_color_encoding_is_set.c', '0289_pngvalid.c_modifier_encoding_iterate.c', '0240_pngvalid.c_gamma_composition_test.c', '121_pngvalid.c_make_error.c', '0054_pngfix.c_chunk_message.c', '0282_pngvalid.c_make_size_images.c', '0301_pngvalid.c_output_quantization_factor.c', '0444_writepng.c_writepng_init.c', '0436_timepng.c_main.c', '071_pngstest.c_gpc_Gpre.c', '0343_pngvalid.c_standard_rowsize.c', '0264_pngvalid.c_image_transform_png_set_strip_16_set.c', '066_pngstest.c_gp_argb8.c', '156_pngvalid.c_store_freefile.c', '007_VisualPng.c_AboutDlgProc.c', '069_pngstest.c_gp_rgb16.c', '021_png2pnm.c_main.c', '0273_pngvalid.c_init_validate_info.c', '0437_timepng.c_mytime.c', '0204_pngtest.c_pngtest_warning.c', '0253_pngvalid.c_image_transform_png_set_expand_gray_1_2_4_to_8_set.c', '0162_pngstest.c_gpc_Pre.c', '0208_pngtopng.c_main.c', '0020_linux-auxv.c_safe_read.c', '0349_pngvalid.c_store_flush.c', '093_pngunknown.c_read_callback.c', '064_pngstest.c_gp_abgr8.c', '0327_pngvalid.c_sbit_modification_init.c', '0300_pngvalid.c_outlog.c', '0434_tarith.c_validation_muldiv.c', '0142_pngstest.c_format_default.c', '0414_rpng2-win.c_rpng2_win_cleanup.c', '022_pngfix.c_IDAT_end.c', '0140_pngstest.c_closestinteger.c', '0099_pngfix.c_warning_handler.c', '0254_pngvalid.c_image_transform_png_set_expand_set.c', '0307_pngvalid.c_perform_transform_test.c', '008_VisualPng.c_BuildPngList.c', '0433_tarith.c_validation_gamma.c', '0160_pngstest.c_gpc_Gprq.c', '130_pngvalid.c_perform_gamma_composition_tests.c', '141_pngvalid.c_row_copy.c', '0441_wpng.c_wpng_isvalid_latin1.c', '171_pngvalid.c_transform_height.c', '102_pngvalid.c_image_pixel_init.c', '0291_pngvalid.c_modifier_progressive_read.c', '0265_pngvalid.c_image_transform_png_set_strip_alpha_add.c', '0322_pngvalid.c_sBIT_error_fn.c', '149_pngvalid.c_size_row.c', '0116_pngimage.c_display_clean.c', '027_pngfix.c_crc_init_4.c', '0098_pngfix.c_usage.c', '0426_tarith.c_png_exp8bit.c', '0163_pngstest.c_gpc_Preq.c', '0005_VisualPng.c_InitBitmap.c', '0340_pngvalid.c_standard_palette_init.c', '0442_writepng.c_writepng_encode_image.c', '0415_rpng2-win.c_rpng2_win_create_window.c', '0356_pngvalid.c_store_malloc.c', '176_pnm2png.c_get_data.c', '0121_pngimage.c_first_transform.c', '0384_pnm2png.c_get_token.c', '0154_pngstest.c_gp_ga8.c', '0036_makepng.c_makepng_error.c', '0038_makepng.c_parse_color.c', '0146_pngstest.c_format_set.c', '0331_pngvalid.c_standard_display_init.c', '0169_pngstest.c_gpc_g16q.c', '192_wpng.c_dos_kbd_gets.c', '0012_cvtcolor.c_main.c', '0302_pngvalid.c_perform_gamma_sbit_tests.c', '126_pngvalid.c_outerr.c', '0408_rpng2-x.c_rpng2_x_create_window.c', '0314_pngvalid.c_png_row_in_interlace_pass.c', '0252_pngvalid.c_image_transform_png_set_expand_add.c', '0357_pngvalid.c_store_memory_free.c', '170_pngvalid.c_transform_disable.c', '0245_pngvalid.c_gamma_transform_test.c', '039_pngfix.c_uarb_mult32.c', '029_pngfix.c_file_setpos.c', '0168_pngstest.c_gpc_g16.c', '025_pngfix.c_chunk_end.c', '0013_cvtcolor.c_usage.c', '0303_pngvalid.c_perform_gamma_test.c', '0159_pngstest.c_gpc_Glin.c', '164_pngvalid.c_store_storenew.c', '0002_PngFile.c_png_flush.c', '0145_pngstest.c_format_isset.c', '0275_pngvalid.c_internal_error.c', '062_pngstest.c_freeimage.c', '0363_pngvalid.c_store_read_buffer_next.c', '024_pngfix.c_IDAT_list_end.c', '0158_pngstest.c_gp_rgba16.c', '0294_pngvalid.c_modifier_reset.c', '0198_pngstest.c_write_one_file.c', '0418_rpng2-win.c_rpng2_win_init.c', '0396_readppm.c_readpng_cleanup.c', '0244_pngvalid.c_gamma_threshold_test.c', '0179_pngstest.c_ilineara.c', '0249_pngvalid.c_image_transform_default_ini.c', '0251_pngvalid.c_image_transform_png_set_expand_16_mod.c', '0049_pngfix.c_IDAT_list_extend.c', '0196_pngstest.c_u8d.c', '0114_pngimage.c_compare_read.c', '0438_timepng.c_read_png.c', '124_pngvalid.c_modifier_crc.c', '072_pngstest.c_gpc_b16c.c', '0118_pngimage.c_display_destroy.c', '0366_pngvalid.c_store_storefile.c', '035_pngfix.c_strcode.c', '0229_pngvalid.c_check_interlace_type.c', '119_pngvalid.c_image_transform_png_set_tRNS_to_alpha_add.c', '0222_pngunknown.c_warning.c', '136_pngvalid.c_png_col_in_interlace_pass.c', '0397_readppm.c_readpng_get_bgcolor.c', '108_pngvalid.c_image_transform_png_set_expand_16_set.c', '0133_pngrio.c_png_default_read_data.c', '189_rpng2-win.c_repl_getch.c', '006_PngFile.c_png_write_data.c', '0070_pngfix.c_global_init.c', '0380_pngwio.c_png_far_to_near.c', '0065_pngfix.c_file_end.c', '0336_pngvalid.c_standard_info_imp.c', '0435_timepng.c_add_one_file.c', '0231_pngvalid.c_chrm_modify.c', '165_pngvalid.c_store_verbose.c', '0258_pngvalid.c_image_transform_png_set_rgb_to_gray_ini.c', '0335_pngvalid.c_standard_info.c', '0029_makepng.c_insert_iCCP.c', '0090_pngfix.c_type_char.c', '0279_pngvalid.c_make_random_bytes.c', '118_pngvalid.c_image_transform_png_set_strip_alpha_mod.c', '0050_pngfix.c_IDAT_list_init.c', '0317_pngvalid.c_random_32.c', '0170_pngstest.c_gpc_noop.c', '0326_pngvalid.c_sample.c', '0157_pngstest.c_gp_rgba8.c', '0383_pngwio.c_png_write_data.c', '0406_rpng2-x.c_main.c', '074_pngstest.c_gpc_g8b.c', '0123_pngimage.c_is_combo.c', '090_pngunknown.c_find_by_flag.c', '0216_pngunknown.c_display_rc.c', '0337_pngvalid.c_standard_info_part1.c', '0385_pnm2png.c_get_value.c', '132_pngvalid.c_perform_gamma_transform_tests.c', '089_pngunknown.c_find.c', '0413_rpng2-x.c_rpng2_x_redisplay_image.c', '0221_pngunknown.c_perform_one_test.c', '0255_pngvalid.c_image_transform_png_set_gray_to_rgb_add.c', '169_pngvalid.c_summarize_gamma_errors.c', '0097_pngfix.c_uarb_printx.c', '0022_makepng.c_channels_of_type.c', '0386_pnm2png.c_pnm2png.c', '184_readppm.c_readpng_get_image.c', '0151_pngstest.c_gp_bgr16.c', '016_makepng.c_find_parameters.c', '0211_pngunknown.c_check.c', '0298_pngvalid.c_next_format.c', '140_pngvalid.c_random_mod.c', '0402_rpng-win.c_rpng_win_cleanup.c', '0138_pngstest.c_checkbuffer.c', '0134_pngrio.c_png_read_data.c', '0212_pngunknown.c_check_error.c', '078_pngstest.c_ilineara_g22.c', '079_pngstest.c_logclose.c', '0047_png2pnm.c_png2pnm.c', '0236_pngvalid.c_fix.c', '0338_pngvalid.c_standard_info_part2.c', '0008_VisualPng.c_WinMain.c', '0004_VisualPng.c_CenterAbout.c', '0269_pngvalid.c_image_transform_set_end.c', '055_pngimage.c_write_function.c', '0203_pngtest.c_pngtest_read_data.c', '116_pngvalid.c_image_transform_png_set_scale_16_add.c', '111_pngvalid.c_image_transform_png_set_expand_mod.c', '0220_pngunknown.c_init_display.c', '0358_pngvalid.c_store_pool_delete.c', '143_pngvalid.c_safecat_current_encoding.c', '0215_pngunknown.c_clear_keep.c', '096_pngvalid.c_chromaticity_y.c', '0267_pngvalid.c_image_transform_png_set_tRNS_to_alpha_mod.c', '0243_pngvalid.c_gamma_image_validate.c', '125_pngvalid.c_npasses_from_interlace_type.c', '142_pngvalid.c_safecat.c', '145_pngvalid.c_sbit_modify.c', '0185_pngstest.c_make_random_bytes.c', '0175_pngstest.c_gpc_sRGB.c', '0348_pngvalid.c_store_error.c', '020_makesRGB.c_invsRGB.c', '114_pngvalid.c_image_transform_png_set_palette_to_rgb_set.c', '0003_PngFile.c_png_read_data.c', '001_PngFile.c_PngFileOpenDlg.c', '0421_tarith.c_check_all_characters.c', '0370_pngvalid.c_transform_display_init.c', '146_pngvalid.c_set_modifier_for_read.c', '083_pngtest.c_main.c', '0393_readpng2.c_readpng2_end_callback.c', '0143_pngstest.c_format_init.c', '0399_readppm.c_readpng_version_info.c', '060_pngstest.c_formatof.c', '0188_pngstest.c_print_pixel.c', '0109_pngimage.c_buffer_destroy.c', '0382_pngwio.c_png_set_write_fn.c', '097_pngvalid.c_gamma_component_validate.c', '0410_rpng2-x.c_rpng2_x_finish_display.c', '0242_pngvalid.c_gamma_end.c', '0057_pngfix.c_control_end.c', '0066_pngfix.c_file_getpos.c', '0293_pngvalid.c_modifier_read_imp.c', '150_pngvalid.c_srgb_modification_init.c', '012_cvtcolor.c_component.c', '050_pngimage.c_display_warning.c', '193_writepng.c_writepng_cleanup.c', '0286_pngvalid.c_modifier_color_encoding_is_sRGB.c', '0164_pngstest.c_gpc_b16g.c', '0290_pngvalid.c_modifier_init.c', '0016_iccfrompng.c_extract.c', '0201_pngtest.c_pngtest_check_io_state.c', '0061_pngfix.c_current_type.c', '0425_tarith.c_png_exp.c', '0256_pngvalid.c_image_transform_png_set_gray_to_rgb_set.c', '0311_pngvalid.c_png_pass_start_col.c', '0288_pngvalid.c_modifier_current_encoding.c', '057_pngrio.c_png_set_read_fn.c', '0378_pngwio.c_png_default_flush.c', '0007_VisualPng.c_SearchPngList.c', '0376_pngvalid.c_transform_set_encoding.c', '122_pngvalid.c_make_transform_image.c', '0270_pngvalid.c_image_transform_test_counter.c', '0354_pngvalid.c_store_init.c', '0042_makepng.c_write_png.c', '098_pngvalid.c_gamma_info.c', '0178_pngstest.c_ilinear_g22.c', '115_pngvalid.c_image_transform_png_set_rgb_to_gray_add.c', '0233_pngvalid.c_deinterlace_row.c', '095_pngvalid.c__add.c', '0128_pngimage.c_test_one_file.c', '179_readpng.c_readpng_get_bgcolor.c', '174_pngvalid.c_transform_rowsize.c', '003_PngFile.c_PngLoadImage.c', '107_pngvalid.c_image_transform_png_set_expand_16_add.c', '181_readpng2.c_readpng2_cleanup.c', '104_pngvalid.c_image_transform_mod_end.c', '0341_pngvalid.c_standard_palette_validate.c', '0246_pngvalid.c_image_pixel_convert_PLTE.c', '0261_pngvalid.c_image_transform_png_set_scale_16_set.c', '0284_pngvalid.c_make_transform_images.c', '0365_pngvalid.c_store_read_set.c', '0027_makepng.c_image_size_of_type.c', '0276_pngvalid.c_main.c', '0324_pngvalid.c_safecatd.c', '0219_pngunknown.c_get_valid.c', '0344_pngvalid.c_standard_text_validate.c', '0345_pngvalid.c_standard_width.c', '173_pngvalid.c_transform_info_imp.c', '0351_pngvalid.c_store_freebuffer.c', '013_fakepng.c_put_uLong.c', '0149_pngstest.c_gp_argb16.c', '0374_pngvalid.c_transform_range_check.c', '0156_pngstest.c_gp_rgb8.c', '0088_pngfix.c_stop_invalid.c', '0330_pngvalid.c_standard_check_text.c', '0310_pngvalid.c_png_pass_rows.c', '0136_pngstest.c_allocbuffer.c', '0262_pngvalid.c_image_transform_png_set_scale_16_mod.c', '010_VisualPng.c_FillBitmap.c', '084_pngtest.c_png_debug_malloc.c', '137_pngvalid.c_png_pass_col_shift.c', '0313_pngvalid.c_png_row_from_pass_row.c', '0125_pngimage.c_read_function.c', '0174_pngstest.c_gpc_sGp.c', '0391_readpng2.c_readpng2_version_info.c', '0171_pngstest.c_gpc_nop8.c', '105_pngvalid.c_image_transform_png_set_background_mod.c', '0200_pngtest.c_png_debug_free.c', '0247_pngvalid.c_image_transform_add.c', '180_readpng.c_readpng_get_image.c', '0235_pngvalid.c_fail.c', '0024_makepng.c_find_insert.c', '0388_readpng.c_readpng_init.c', '0187_pngstest.c_print_opts.c', '0227_pngvalid.c_bit_size.c', '0400_rpng-win.c_WinMain.c', '0409_rpng2-x.c_rpng2_x_display_row.c', '070_pngstest.c_gpc_A.c', '0312_pngvalid.c_png_pass_start_row.c', '0119_pngimage.c_display_error.c', '0320_pngvalid.c_read_palette.c', '0112_pngimage.c_buffer_start_read.c', '0395_readpng2.c_readpng2_error_handler.c', '0248_pngvalid.c_image_transform_default_add.c', '0183_pngstest.c_logerror.c', '134_pngvalid.c_pixel_cmp.c', '0419_rpng2-win.c_rpng2_win_load_bg_image.c', '043_pngimage.c_buffer_extend.c', '0166_pngstest.c_gpc_cb16.c', '0078_pngfix.c_read_byte.c', '032_pngfix.c_one_file.c', '091_pngunknown.c_main.c', '0180_pngstest.c_init_sRGB_to_d.c', '077_pngstest.c_gpc_unpg.c', '0195_pngstest.c_testimage.c', '0037_makepng.c_makepng_warning.c', '0110_pngimage.c_buffer_destroy_list.c', '0030_makepng.c_insert_iTXt.c', '0271_pngvalid.c_init_gamma_errors.c', '0295_pngvalid.c_modifier_set_encoding.c', '147_pngvalid.c_set_store_for_read.c', '017_makepng.c_insert_tEXt.c', '0045_makesRGB.c_sRGB.c', '0394_readpng2.c_readpng2_row_callback.c', '0308_pngvalid.c_png_col_from_pass_col.c', '0238_pngvalid.c_gama_modify.c', '0333_pngvalid.c_standard_height.c', '0257_pngvalid.c_image_transform_png_set_palette_to_rgb_add.c', '112_pngvalid.c_image_transform_png_set_gray_to_rgb_mod.c', '0006_VisualPng.c_LoadImageFile.c', '0285_pngvalid.c_modification_init.c', '0381_pngwio.c_png_flush.c', '151_pngvalid.c_srgb_modify.c', '0334_pngvalid.c_standard_image_validate.c', '155_pngvalid.c_store_ensure_image.c', '0228_pngvalid.c_calcerr.c', '0072_pngfix.c_make_random_bytes.c', '011_checksum-icc.c_main.c', '0032_makepng.c_load_fake.c', '0182_pngstest.c_isRGB.c', '0018_iccfrompng.c_main.c', '0206_pngtest.c_test_one_file.c', '0420_rpng2-win.c_rpng2_win_wndproc.c', '0026_makepng.c_generate_row.c', '005_PngFile.c_png_cexcept_error.c', '135_pngvalid.c_pixel_copy.c', '0364_pngvalid.c_store_read_imp.c', '0152_pngstest.c_gp_bgra8.c', '0404_rpng-win.c_rpng_win_wndproc.c', '0405_rpng2-x.c_is_number.c', '166_pngvalid.c_store_warning.c', '123_pngvalid.c_modification_reset.c', '085_pngtest.c_pngtest_error.c', '186_rpng2-x.c_rpng2_x_init.c', '163_pngvalid.c_store_read_reset.c', '092_pngunknown.c_perform_one_test_safe.c', '0241_pngvalid.c_gamma_display_init.c', '0342_pngvalid.c_standard_row_validate.c', '0375_pngvalid.c_transform_row.c', '0318_pngvalid.c_random_choice.c', '0202_pngtest.c_pngtest_flush.c', '075_pngstest.c_gpc_gb16.c']\n","The length of the list is : 622\n","[['void', 'PNGAPI', 'png_read_row', '(', 'png_structrp', 'png_ptr', ',', 'png_bytep', 'row', ',', 'png_bytep', 'dsp_row', ')', '{', 'png_row_info', 'row_info', ';', 'if', '(', 'png_ptr', '=', '=', 'NULL', ')', 'return', ';', 'png_debug2', '(', '1', ',', '\"', 'in', 'png_read_row', '(', 'row', '%lu', ',', 'pass', '%d', ')', '\"', ',', '(', 'unsigned', 'long', ')', 'png_ptr', '-', '>', 'row_number', ',', 'png_ptr', '-', '>', 'pass', ')', ';', 'if', '(', '!', '(', 'png_ptr', '-', '>', 'flags', '&', 'PNG_FLAG_ROW_INIT', ')', ')', 'png_read_start_row', '(', 'png_ptr', ')', ';', 'row_info.width', '=', 'png_ptr', '-', '>', 'iwidth', ';', 'row_info.color_type', '=', 'png_ptr', '-', '>', 'color_type', ';', 'row_info.bit_depth', '=', 'png_ptr', '-', '>', 'bit_depth', ';', 'row_info.channels', '=', 'png_ptr', '-', '>', 'channels', ';', 'row_info.pixel_depth', '=', 'png_ptr', '-', '>', 'pixel_depth', ';', 'row_info.rowbytes', '=', 'PNG_ROWBYTES', '(', 'row_info.pixel_depth', ',', 'row_info.width', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'row_number', '=', '=', '0', '&&', 'png_ptr', '-', '>', 'pass', '=', '=', '0', ')', '{', '#if', 'defined', '(', 'PNG_WRITE_INVERT_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_INVERT_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_INVERT_MONO', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_INVERT_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_FILLER_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_FILLER_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_FILLER', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_FILLER_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_PACKSWAP_SUPPORTED', ')', '&&', '\\\\', '!defined', '(', 'PNG_READ_PACKSWAP_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_PACKSWAP', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_PACKSWAP_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_PACK_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_PACK_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_PACK', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_PACK_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_SHIFT_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_SHIFT_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_SHIFT', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_SHIFT_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_BGR_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_BGR_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_BGR', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_BGR_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '#if', 'defined', '(', 'PNG_WRITE_SWAP_SUPPORTED', ')', '&&', '!defined', '(', 'PNG_READ_SWAP_SUPPORTED', ')', 'if', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_SWAP_BYTES', ')', 'png_warning', '(', 'png_ptr', ',', '\"', 'PNG_READ_SWAP_SUPPORTED', 'is', 'not', 'defined', '\"', ')', ';', '#endif', '}', '#ifdef', 'PNG_READ_INTERLACING_SUPPORTED', 'if', '(', 'png_ptr', '-', '>', 'interlaced', '&&', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_INTERLACE', ')', ')', '{', 'switch', '(', 'png_ptr', '-', '>', 'pass', ')', '{', 'case', '0:', 'if', '(', 'png_ptr', '-', '>', 'row_number', '&', '0x07', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '1:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '0x07', ')', '||', 'png_ptr', '-', '>', 'width', '<', '5', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '2:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '0x07', ')', '!', '=', '4', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', '&&', '(', 'png_ptr', '-', '>', 'row_number', '&', '4', ')', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '3:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '3', ')', '||', 'png_ptr', '-', '>', 'width', '<', '3', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '4:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '3', ')', '!', '=', '2', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', '&&', '(', 'png_ptr', '-', '>', 'row_number', '&', '2', ')', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'case', '5:', 'if', '(', '(', 'png_ptr', '-', '>', 'row_number', '&', '1', ')', '||', 'png_ptr', '-', '>', 'width', '<', '2', ')', '{', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', 'default:', 'case', '6:', 'if', '(', '!', '(', 'png_ptr', '-', '>', 'row_number', '&', '1', ')', ')', '{', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'return', ';', '}', 'break', ';', '}', '}', '#endif', 'if', '(', '!', '(', 'png_ptr', '-', '>', 'mode', '&', 'PNG_HAVE_IDAT', ')', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'Invalid', 'attempt', 'to', 'read', 'row', 'data', '\"', ')', ';', 'png_read_IDAT_data', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'row_buf', ',', 'row_info.rowbytes', '+', '1', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'row_buf', '[', '0', ']', '>', 'PNG_FILTER_VALUE_NONE', ')', '{', 'if', '(', 'png_ptr', '-', '>', 'row_buf', '[', '0', ']', '<', 'PNG_FILTER_VALUE_LAST', ')', 'png_read_filter_row', '(', 'png_ptr', ',', '&row_info', ',', 'png_ptr', '-', '>', 'row_buf', '+', '1', ',', 'png_ptr', '-', '>', 'prev_row', '+', '1', ',', 'png_ptr', '-', '>', 'row_buf', '[', '0', ']', ')', ';', 'else', 'png_error', '(', 'png_ptr', ',', '\"', 'bad', 'adaptive', 'filter', 'value', '\"', ')', ';', '}', 'memcpy', '(', 'png_ptr', '-', '>', 'prev_row', ',', 'png_ptr', '-', '>', 'row_buf', ',', 'row_info.rowbytes', '+', '1', ')', ';', '#ifdef', 'PNG_MNG_FEATURES_SUPPORTED', 'if', '(', '(', 'png_ptr', '-', '>', 'mng_features_permitted', '&', 'PNG_FLAG_MNG_FILTER_64', ')', '&&', '(', 'png_ptr', '-', '>', 'filter_type', '=', '=', 'PNG_INTRAPIXEL_DIFFERENCING', ')', ')', '{', 'png_do_read_intrapixel', '(', '&row_info', ',', 'png_ptr', '-', '>', 'row_buf', '+', '1', ')', ';', '}', '#endif', '#ifdef', 'PNG_READ_TRANSFORMS_SUPPORTED', 'if', '(', 'png_ptr', '-', '>', 'transformations', ')', 'png_do_read_transformations', '(', 'png_ptr', ',', '&row_info', ')', ';', '#endif', 'if', '(', 'png_ptr', '-', '>', 'transformed_pixel_depth', '=', '=', '0', ')', '{', 'png_ptr', '-', '>', 'transformed_pixel_depth', '=', 'row_info.pixel_depth', ';', 'if', '(', 'row_info.pixel_depth', '>', 'png_ptr', '-', '>', 'maximum_pixel_depth', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'sequential', 'row', 'overflow', '\"', ')', ';', '}', 'else', 'if', '(', 'png_ptr', '-', '>', 'transformed_pixel_depth', '!', '=', 'row_info.pixel_depth', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'internal', 'sequential', 'row', 'size', 'calculation', 'error', '\"', ')', ';', '#ifdef', 'PNG_READ_INTERLACING_SUPPORTED', 'if', '(', 'png_ptr', '-', '>', 'interlaced', '&&', '(', 'png_ptr', '-', '>', 'transformations', '&', 'PNG_INTERLACE', ')', ')', '{', 'if', '(', 'png_ptr', '-', '>', 'pass', '<', '6', ')', 'png_do_read_interlace', '(', '&row_info', ',', 'png_ptr', '-', '>', 'row_buf', '+', '1', ',', 'png_ptr', '-', '>', 'pass', ',', 'png_ptr', '-', '>', 'transformations', ')', ';', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '1', ')', ';', 'if', '(', 'row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'row', ',', '0', ')', ';', '}', 'else', '#endif', '{', 'if', '(', 'row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'row', ',', '-', '1', ')', ';', 'if', '(', 'dsp_row', '!', '=', 'NULL', ')', 'png_combine_row', '(', 'png_ptr', ',', 'dsp_row', ',', '-', '1', ')', ';', '}', 'png_read_finish_row', '(', 'png_ptr', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'read_row_fn', '!', '=', 'NULL', ')', '(', '*', '(', 'png_ptr', '-', '>', 'read_row_fn', ')', ')', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'row_number', ',', 'png_ptr', '-', '>', 'pass', ')', ';', '}', '#endif'], ['void', 'png_formatted_warning', '(', 'png_structp', 'png_ptr', ',', 'png_warning_parameters', 'p', ',', 'png_const_charp', 'message', ')', '{', 'size_t', 'i', ';', 'char', 'msg', '[', '128', ']', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', '(', 'sizeof', 'msg', ')', '-', '1', '&&', '*', 'message', '!', '=', \"'\\\\0'\", ';', '+', '+', 'i', ')', '{', 'if', '(', '*', 'message', '=', '=', \"'@'\", ')', '{', 'int', 'parameter', '=', '-', '1', ';', 'switch', '(', '*', '+', '+', 'message', ')', '{', 'case', \"'1':\", 'parameter', '=', '0', ';', 'break', ';', 'case', \"'2':\", 'parameter', '=', '1', ';', 'break', ';', 'case', \"'\\\\0':\", 'continue', ';', 'default:', 'break', ';', '}', 'if', '(', 'parameter', '>', '=', '0', '&&', 'parameter', '<', 'PNG_WARNING_PARAMETER_COUNT', ')', '{', 'png_const_charp', 'parm', '=', 'p', '[', 'parameter', ']', ';', 'png_const_charp', 'pend', '=', 'p', '[', 'parameter', ']', '+', '(', 'sizeof', 'p', '[', 'parameter', ']', ')', ';', 'for', '(', ';', 'i', '<', '(', 'sizeof', 'msg', ')', '-', '1', '&&', 'parm', '!', '=', \"'\\\\0'\", '&&', 'parm', '<', 'pend', ';', '+', '+', 'i', ')', 'msg', '[', 'i', ']', '=', '*', 'parm', '+', '+', ';', '+', '+', 'message', ';', 'continue', ';', '}', '}', 'msg', '[', 'i', ']', '=', '*', 'message', '+', '+', ';', '}', 'msg', '[', 'i', ']', '=', \"'\\\\0'\", ';', 'png_warning', '(', 'png_ptr', ',', 'msg', ')', ';', '}', '#endif'], ['void', 'png_read_IDAT_data', '(', 'png_structrp', 'png_ptr', ',', 'png_bytep', 'output', ',', 'png_alloc_size_t', 'avail_out', ')', '{', 'png_ptr', '-', '>', 'zstream.next_out', '=', 'output', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', '0', ';', 'if', '(', 'output', '=', '=', 'NULL', ')', 'avail_out', '=', '0', ';', 'do', '{', 'int', 'ret', ';', 'png_byte', 'tmpbuf', '[', 'PNG_INFLATE_BUF_SIZE', ']', ';', 'if', '(', 'png_ptr', '-', '>', 'zstream.avail_in', '=', '=', '0', ')', '{', 'uInt', 'avail_in', ';', 'png_bytep', 'buffer', ';', 'while', '(', 'png_ptr', '-', '>', 'idat_size', '=', '=', '0', ')', '{', 'png_crc_finish', '(', 'png_ptr', ',', '0', ')', ';', 'png_ptr', '-', '>', 'idat_size', '=', 'png_read_chunk_header', '(', 'png_ptr', ')', ';', 'if', '(', 'png_ptr', '-', '>', 'chunk_name', '!', '=', 'png_IDAT', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'Not', 'enough', 'image', 'data', '\"', ')', ';', '}', 'avail_in', '=', 'png_ptr', '-', '>', 'IDAT_read_size', ';', 'if', '(', 'avail_in', '>', 'png_ptr', '-', '>', 'idat_size', ')', 'avail_in', '=', '(', 'uInt', ')', 'png_ptr', '-', '>', 'idat_size', ';', 'buffer', '=', 'png_read_buffer', '(', 'png_ptr', ',', 'avail_in', ',', '0', ')', ';', 'png_crc_read', '(', 'png_ptr', ',', 'buffer', ',', 'avail_in', ')', ';', 'png_ptr', '-', '>', 'idat_size', '-', '=', 'avail_in', ';', 'png_ptr', '-', '>', 'zstream.next_in', '=', 'buffer', ';', 'png_ptr', '-', '>', 'zstream.avail_in', '=', 'avail_in', ';', '}', 'if', '(', 'output', '!', '=', 'NULL', ')', '{', 'uInt', 'out', '=', 'ZLIB_IO_MAX', ';', 'if', '(', 'out', '>', 'avail_out', ')', 'out', '=', '(', 'uInt', ')', 'avail_out', ';', 'avail_out', '-', '=', 'out', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', 'out', ';', '}', 'else', '{', 'png_ptr', '-', '>', 'zstream.next_out', '=', 'tmpbuf', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', '(', 'sizeof', 'tmpbuf', ')', ';', '}', 'ret', '=', 'inflate', '(', '&png_ptr', '-', '>', 'zstream', ',', 'Z_NO_FLUSH', ')', ';', 'if', '(', 'output', '!', '=', 'NULL', ')', 'avail_out', '+', '=', 'png_ptr', '-', '>', 'zstream.avail_out', ';', 'else', 'avail_out', '+', '=', '(', 'sizeof', 'tmpbuf', ')', '-', 'png_ptr', '-', '>', 'zstream.avail_out', ';', 'png_ptr', '-', '>', 'zstream.avail_out', '=', '0', ';', 'if', '(', 'ret', '=', '=', 'Z_STREAM_END', ')', '{', 'png_ptr', '-', '>', 'zstream.next_out', '=', 'NULL', ';', 'png_ptr', '-', '>', 'mode', '|', '=', 'PNG_AFTER_IDAT', ';', 'png_ptr', '-', '>', 'flags', '|', '=', 'PNG_FLAG_ZSTREAM_ENDED', ';', 'if', '(', 'png_ptr', '-', '>', 'zstream.avail_in', '>', '0', '||', 'png_ptr', '-', '>', 'idat_size', '>', '0', ')', 'png_chunk_benign_error', '(', 'png_ptr', ',', '\"', 'Extra', 'compressed', 'data', '\"', ')', ';', 'break', ';', '}', 'if', '(', 'ret', '!', '=', 'Z_OK', ')', '{', 'png_zstream_error', '(', 'png_ptr', ',', 'ret', ')', ';', 'if', '(', 'output', '!', '=', 'NULL', ')', 'png_chunk_error', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'zstream.msg', ')', ';', 'else', '{', 'png_chunk_benign_error', '(', 'png_ptr', ',', 'png_ptr', '-', '>', 'zstream.msg', ')', ';', 'return', ';', '}', '}', '}', 'while', '(', 'avail_out', '>', '0', ')', ';', 'if', '(', 'avail_out', '>', '0', ')', '{', 'if', '(', 'output', '!', '=', 'NULL', ')', 'png_error', '(', 'png_ptr', ',', '\"', 'Not', 'enough', 'image', 'data', '\"', ')', ';', 'else', 'png_chunk_benign_error', '(', 'png_ptr', ',', '\"', 'Too', 'much', 'image', 'data', '\"', ')', ';', '}', '}'], ['void', 'png_do_expand_palette', '(', 'png_row_infop', 'row_info', ',', 'png_bytep', 'row', ',', 'png_const_colorp', 'palette', ',', 'png_const_bytep', 'trans_alpha', ',', 'int', 'num_trans', ')', '{', 'int', 'shift', ',', 'value', ';', 'png_bytep', 'sp', ',', 'dp', ';', 'png_uint_32', 'i', ';', 'png_uint_32', 'row_width', '=', 'row_info', '-', '>', 'width', ';', 'png_debug', '(', '1', ',', '\"', 'in', 'png_do_expand_palette', '\"', ')', ';', 'if', '(', 'row_info', '-', '>', 'color_type', '=', '=', 'PNG_COLOR_TYPE_PALETTE', ')', '{', 'if', '(', 'row_info', '-', '>', 'bit_depth', '<', '8', ')', '{', 'switch', '(', 'row_info', '-', '>', 'bit_depth', ')', '{', 'case', '1:', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', '(', '(', 'row_width', '-', '1', ')', '>', '>', '3', ')', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'shift', '=', '7', '-', '(', 'int', ')', '(', '(', 'row_width', '+', '7', ')', '&', '0x07', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'if', '(', '(', '*', 'sp', '>', '>', 'shift', ')', '&', '0x01', ')', '*', 'dp', '=', '1', ';', 'else', '*', 'dp', '=', '0', ';', 'if', '(', 'shift', '=', '=', '7', ')', '{', 'shift', '=', '0', ';', 'sp', '-', '-', ';', '}', 'else', 'shift', '+', '+', ';', 'dp', '-', '-', ';', '}', 'break', ';', '}', 'case', '2:', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', '(', '(', 'row_width', '-', '1', ')', '>', '>', '2', ')', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'shift', '=', '(', 'int', ')', '(', '(', '3', '-', '(', '(', 'row_width', '+', '3', ')', '&', '0x03', ')', ')', '<', '<', '1', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'value', '=', '(', '*', 'sp', '>', '>', 'shift', ')', '&', '0x03', ';', '*', 'dp', '=', '(', 'png_byte', ')', 'value', ';', 'if', '(', 'shift', '=', '=', '6', ')', '{', 'shift', '=', '0', ';', 'sp', '-', '-', ';', '}', 'else', 'shift', '+', '=', '2', ';', 'dp', '-', '-', ';', '}', 'break', ';', '}', 'case', '4:', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', '(', '(', 'row_width', '-', '1', ')', '>', '>', '1', ')', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'shift', '=', '(', 'int', ')', '(', '(', 'row_width', '&', '0x01', ')', '<', '<', '2', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'value', '=', '(', '*', 'sp', '>', '>', 'shift', ')', '&', '0x0f', ';', '*', 'dp', '=', '(', 'png_byte', ')', 'value', ';', 'if', '(', 'shift', '=', '=', '4', ')', '{', 'shift', '=', '0', ';', 'sp', '-', '-', ';', '}', 'else', 'shift', '+', '=', '4', ';', 'dp', '-', '-', ';', '}', 'break', ';', '}', 'default:', 'break', ';', '}', 'row_info', '-', '>', 'bit_depth', '=', '8', ';', 'row_info', '-', '>', 'pixel_depth', '=', '8', ';', 'row_info', '-', '>', 'rowbytes', '=', 'row_width', ';', '}', 'else', 'if', '(', 'row_info', '-', '>', 'bit_depth', '=', '=', '8', ')', '{', '{', 'if', '(', 'trans_alpha', '!', '=', 'NULL', ')', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', '(', 'row_width', '<', '<', '2', ')', '-', '1', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', 'if', '(', '(', 'int', ')', '(', '*', 'sp', ')', '>', '=', 'num_trans', ')', '*', 'dp', '-', '-', '=', '0xff', ';', 'else', '*', 'dp', '-', '-', '=', 'trans_alpha', '[', '*', 'sp', ']', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.blue', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.green', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.red', ';', 'sp', '-', '-', ';', '}', 'row_info', '-', '>', 'bit_depth', '=', '8', ';', 'row_info', '-', '>', 'pixel_depth', '=', '32', ';', 'row_info', '-', '>', 'rowbytes', '=', 'row_width', '*', '4', ';', 'row_info', '-', '>', 'color_type', '=', '6', ';', 'row_info', '-', '>', 'channels', '=', '4', ';', '}', 'else', '{', 'sp', '=', 'row', '+', '(', 'png_size_t', ')', 'row_width', '-', '1', ';', 'dp', '=', 'row', '+', '(', 'png_size_t', ')', '(', 'row_width', '*', '3', ')', '-', '1', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'row_width', ';', 'i', '+', '+', ')', '{', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.blue', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.green', ';', '*', 'dp', '-', '-', '=', 'palette', '[', '*', 'sp', ']', '.red', ';', 'sp', '-', '-', ';', '}', 'row_info', '-', '>', 'bit_depth', '=', '8', ';', 'row_info', '-', '>', 'pixel_depth', '=', '24', ';', 'row_info', '-', '>', 'rowbytes', '=', 'row_width', '*', '3', ';', 'row_info', '-', '>', 'color_type', '=', '2', ';', 'row_info', '-', '>', 'channels', '=', '3', ';', '}', '}', '}', '}', '}'], ['void', 'PNGAPI', 'png_set_unknown_chunks', '(', 'png_structp', 'png_ptr', ',', 'png_infop', 'info_ptr', ',', 'png_const_unknown_chunkp', 'unknowns', ',', 'int', 'num_unknowns', ')', '{', 'png_unknown_chunkp', 'np', ';', 'int', 'i', ';', 'if', '(', 'png_ptr', '=', '=', 'NULL', '||', 'info_ptr', '=', '=', 'NULL', '||', 'num_unknowns', '=', '=', '0', ')', 'return', ';', 'np', '=', '(', 'png_unknown_chunkp', ')', 'png_malloc_warn', '(', 'png_ptr', ',', '(', 'png_size_t', ')', '(', 'info_ptr', '-', '>', 'unknown_chunks_num', '+', 'num_unknowns', ')', '*', 'png_sizeof', '(', 'png_unknown_chunk', ')', ')', ';', 'if', '(', 'np', '=', '=', 'NULL', ')', '{', 'png_warning', '(', 'png_ptr', ',', '\"', 'Out', 'of', 'memory', 'while', 'processing', 'unknown', 'chunk', '\"', ')', ';', 'return', ';', '}', 'png_memcpy', '(', 'np', ',', 'info_ptr', '-', '>', 'unknown_chunks', ',', '(', 'png_size_t', ')', 'info_ptr', '-', '>', 'unknown_chunks_num', '*', 'png_sizeof', '(', 'png_unknown_chunk', ')', ')', ';', 'png_free', '(', 'png_ptr', ',', 'info_ptr', '-', '>', 'unknown_chunks', ')', ';', 'info_ptr', '-', '>', 'unknown_chunks', '=', 'NULL', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', 'num_unknowns', ';', 'i', '+', '+', ')', '{', 'png_unknown_chunkp', 'to', '=', 'np', '+', 'info_ptr', '-', '>', 'unknown_chunks_num', '+', 'i', ';', 'png_const_unknown_chunkp', 'from', '=', 'unknowns', '+', 'i', ';', 'png_memcpy', '(', 'to', '-', '>', 'name', ',', 'from', '-', '>', 'name', ',', 'png_sizeof', '(', 'from', '-', '>', 'name', ')', ')', ';', 'to', '-', '>', 'name', '[', 'png_sizeof', '(', 'to', '-', '>', 'name', ')', '-', '1', ']', '=', \"'\\\\0'\", ';', 'to', '-', '>', 'size', '=', 'from', '-', '>', 'size', ';', 'to', '-', '>', 'location', '=', '(', 'png_byte', ')', '(', 'png_ptr', '-', '>', 'mode', '&', '0xff', ')', ';', 'if', '(', 'from', '-', '>', 'size', '=', '=', '0', ')', 'to', '-', '>', 'data', '=', 'NULL', ';', 'else', '{', 'to', '-', '>', 'data', '=', '(', 'png_bytep', ')', 'png_malloc_warn', '(', 'png_ptr', ',', '(', 'png_size_t', ')', 'from', '-', '>', 'size', ')', ';', 'if', '(', 'to', '-', '>', 'data', '=', '=', 'NULL', ')', '{', 'png_warning', '(', 'png_ptr', ',', '\"', 'Out', 'of', 'memory', 'while', 'processing', 'unknown', 'chunk', '\"', ')', ';', 'to', '-', '>', 'size', '=', '0', ';', '}', 'else', 'png_memcpy', '(', 'to', '-', '>', 'data', ',', 'from', '-', '>', 'data', ',', 'from', '-', '>', 'size', ')', ';', '}', '}', 'info_ptr', '-', '>', 'unknown_chunks', '=', 'np', ';', 'info_ptr', '-', '>', 'unknown_chunks_num', '+', '=', 'num_unknowns', ';', 'info_ptr', '-', '>', 'free_me', '|', '=', 'PNG_FREE_UNKN', ';', '}']]\n","----------------------------------------\n","The trained word2vec model: \n","Word2Vec(vocab=1886, size=100, alpha=0.025)\n"]}],"source":["!python Word_to_vec_embedding.py --data_dir Data/LibPNG/ --output_dir result/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37813,"status":"ok","timestamp":1663315253768,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"L006cAiH9tY7","outputId":"1342f032-181a-4b51-bee0-db43471a3161"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Start training process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] -------------------------------------------------------\n","[INFO] Data processing completed!\n","[INFO] There are 397 total samples in the tr*aining set. 29 vulnerable samples. \n","[INFO] There are 100 total samples in the validation set. 9 vulnerable samples. \n","[INFO] -------------------------------------------------------\n","[INFO] Loading trained Word2vec model. \n","[INFO] The trained word2vec model: \n","<_io.TextIOWrapper name='result/w2v_model_CBOW_dict.txt' mode='r' encoding='UTF-8'>\n","[INFO] Found 1887 word vectors.\n","[0.53940217 6.84482759]\n","[INFO] -------------------------------------------------------\n","[INFO] Loading the DNN model.\n","2022-09-16 08:00:25.334932: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] Model structure loaded.\n","Model: \"DNN_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," flatten (Flatten)           (None, 100000)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               12800128  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 13,400,109\n","Trainable params: 12,827,009\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","Epoch 1/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.9727 - accuracy: 0.4167  \n","Epoch 1: val_loss improved from inf to 0.65814, saving model to result/models/DNN_01_0.820_0.658140.h5\n","25/25 [==============================] - 8s 158ms/step - loss: 0.8293 - accuracy: 0.4660 - val_loss: 0.6581 - val_accuracy: 0.8200\n","Epoch 2/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.6073 - accuracy: 0.7500\n","Epoch 2: val_loss did not improve from 0.65814\n","25/25 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.7531 - val_loss: 0.7997 - val_accuracy: 0.7200\n","Epoch 3/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.4013 - accuracy: 0.8167\n","Epoch 3: val_loss improved from 0.65814 to 0.47630, saving model to result/models/DNN_03_0.820_0.476304.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.3973 - accuracy: 0.8363 - val_loss: 0.4763 - val_accuracy: 0.8200\n","Epoch 4/150\n","12/25 [=============>................] - ETA: 0s - loss: 0.4884 - accuracy: 0.8698\n","Epoch 4: val_loss did not improve from 0.47630\n","25/25 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8413 - val_loss: 0.5736 - val_accuracy: 0.7600\n","Epoch 5/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.3635 - accuracy: 0.8125\n","Epoch 5: val_loss improved from 0.47630 to 0.24342, saving model to result/models/DNN_05_0.900_0.243423.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.3317 - accuracy: 0.8438 - val_loss: 0.2434 - val_accuracy: 0.9000\n","Epoch 6/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.3137 - accuracy: 0.8833\n","Epoch 6: val_loss improved from 0.24342 to 0.12479, saving model to result/models/DNN_06_0.980_0.124788.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.2872 - accuracy: 0.8917 - val_loss: 0.1248 - val_accuracy: 0.9800\n","Epoch 7/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.8917\n","Epoch 7: val_loss did not improve from 0.12479\n","25/25 [==============================] - 0s 6ms/step - loss: 0.2734 - accuracy: 0.8917 - val_loss: 0.3474 - val_accuracy: 0.8100\n","Epoch 8/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.3877 - accuracy: 0.8705\n","Epoch 8: val_loss did not improve from 0.12479\n","25/25 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8892 - val_loss: 0.2992 - val_accuracy: 0.8400\n","Epoch 9/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.2576 - accuracy: 0.8833\n","Epoch 9: val_loss did not improve from 0.12479\n","25/25 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9093 - val_loss: 0.2335 - val_accuracy: 0.8600\n","Epoch 10/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1199 - accuracy: 0.9500\n","Epoch 10: val_loss did not improve from 0.12479\n","25/25 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.9446 - val_loss: 0.1861 - val_accuracy: 0.9200\n","Epoch 11/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0831 - accuracy: 0.9423\n","Epoch 11: val_loss improved from 0.12479 to 0.10624, saving model to result/models/DNN_11_0.980_0.106245.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.9647 - val_loss: 0.1062 - val_accuracy: 0.9800\n","Epoch 12/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1166 - accuracy: 0.9292\n","Epoch 12: val_loss did not improve from 0.10624\n","25/25 [==============================] - 0s 5ms/step - loss: 0.1541 - accuracy: 0.9219 - val_loss: 0.2404 - val_accuracy: 0.8600\n","Epoch 13/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.2776 - accuracy: 0.8875\n","Epoch 13: val_loss did not improve from 0.10624\n","25/25 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.8866 - val_loss: 0.1203 - val_accuracy: 0.9600\n","Epoch 14/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0793 - accuracy: 0.9667\n","Epoch 14: val_loss improved from 0.10624 to 0.10144, saving model to result/models/DNN_14_0.980_0.101436.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0710 - accuracy: 0.9698 - val_loss: 0.1014 - val_accuracy: 0.9800\n","Epoch 15/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0623 - accuracy: 0.9777\n","Epoch 15: val_loss did not improve from 0.10144\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9849 - val_loss: 0.1062 - val_accuracy: 0.9700\n","Epoch 16/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9849\n","Epoch 16: val_loss improved from 0.10144 to 0.09953, saving model to result/models/DNN_16_0.980_0.099530.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.9849 - val_loss: 0.0995 - val_accuracy: 0.9800\n","Epoch 17/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0858 - accuracy: 0.9732\n","Epoch 17: val_loss improved from 0.09953 to 0.08362, saving model to result/models/DNN_17_0.980_0.083621.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0740 - accuracy: 0.9773 - val_loss: 0.0836 - val_accuracy: 0.9800\n","Epoch 18/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0429 - accuracy: 0.9866\n","Epoch 18: val_loss improved from 0.08362 to 0.08130, saving model to result/models/DNN_18_0.980_0.081302.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0381 - accuracy: 0.9849 - val_loss: 0.0813 - val_accuracy: 0.9800\n","Epoch 19/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0460 - accuracy: 0.9958\n","Epoch 19: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9950 - val_loss: 0.0926 - val_accuracy: 0.9700\n","Epoch 20/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0368 - accuracy: 0.9856\n","Epoch 20: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9849 - val_loss: 0.0919 - val_accuracy: 0.9700\n","Epoch 21/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0668 - accuracy: 0.9917\n","Epoch 21: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9924 - val_loss: 0.0847 - val_accuracy: 0.9800\n","Epoch 22/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\n","Epoch 22: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9800\n","Epoch 23/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n","Epoch 23: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9800\n","Epoch 24/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0231 - accuracy: 0.9958\n","Epoch 24: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9874 - val_loss: 0.1329 - val_accuracy: 0.9500\n","Epoch 25/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n","Epoch 25: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9800\n","Epoch 26/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0225 - accuracy: 0.9875\n","Epoch 26: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9849 - val_loss: 0.2863 - val_accuracy: 0.9200\n","Epoch 27/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0362 - accuracy: 0.9777\n","Epoch 27: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9849 - val_loss: 0.1073 - val_accuracy: 0.9800\n","Epoch 28/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0222 - accuracy: 0.9917\n","Epoch 28: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.1090 - val_accuracy: 0.9800\n","Epoch 29/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0111 - accuracy: 0.9961\n","Epoch 29: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9924 - val_loss: 0.1012 - val_accuracy: 0.9800\n","Epoch 30/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.1692 - accuracy: 0.9375\n","Epoch 30: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.1070 - accuracy: 0.9547 - val_loss: 0.1065 - val_accuracy: 0.9800\n","Epoch 31/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0162 - accuracy: 0.9958\n","Epoch 31: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.1065 - val_accuracy: 0.9800\n","Epoch 32/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0126 - accuracy: 0.9917    \n","Epoch 32: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9899 - val_loss: 0.1150 - val_accuracy: 0.9800\n","Epoch 33/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000    \n","Epoch 33: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1282 - val_accuracy: 0.9800\n","Epoch 34/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1019 - accuracy: 0.9875\n","Epoch 34: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.9698 - val_loss: 1.2718 - val_accuracy: 0.7900\n","Epoch 35/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.1818 - accuracy: 0.9318\n","Epoch 35: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 7ms/step - loss: 0.1658 - accuracy: 0.9345 - val_loss: 0.1201 - val_accuracy: 0.9600\n","Epoch 36/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0418 - accuracy: 0.9708\n","Epoch 36: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9824 - val_loss: 0.1015 - val_accuracy: 0.9800\n","Epoch 37/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0113 - accuracy: 0.9955\n","Epoch 37: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9950 - val_loss: 0.1082 - val_accuracy: 0.9800\n","Epoch 38/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0386 - accuracy: 0.9952\n","Epoch 38: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9975 - val_loss: 0.0935 - val_accuracy: 0.9800\n","Epoch 39/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0141 - accuracy: 0.9958    \n","Epoch 39: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.1002 - val_accuracy: 0.9800\n","Epoch 40/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0500 - accuracy: 0.9937\n","Epoch 40: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9950 - val_loss: 0.1035 - val_accuracy: 0.9800\n","Epoch 41/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9975\n","Epoch 41: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.1082 - val_accuracy: 0.9800\n","Epoch 42/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.1487 - accuracy: 0.9554    \n","Epoch 42: val_loss did not improve from 0.08130\n","25/25 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9673 - val_loss: 0.0882 - val_accuracy: 0.9700\n","Epoch 43/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0205 - accuracy: 0.9948\n","Epoch 43: val_loss improved from 0.08130 to 0.07732, saving model to result/models/DNN_43_0.990_0.077319.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.0773 - val_accuracy: 0.9900\n","Epoch 44/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0262 - accuracy: 1.0000\n","Epoch 44: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 0.9975 - val_loss: 0.0804 - val_accuracy: 0.9900\n","Epoch 45/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0311 - accuracy: 0.9875\n","Epoch 45: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9899 - val_loss: 0.0836 - val_accuracy: 0.9800\n","Epoch 46/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0456 - accuracy: 0.9875    \n","Epoch 46: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9899 - val_loss: 0.0828 - val_accuracy: 0.9800\n","Epoch 47/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000\n","Epoch 47: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9800\n","Epoch 48/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.2853 - accuracy: 0.9911\n","Epoch 48: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9748 - val_loss: 0.2077 - val_accuracy: 0.9100\n","Epoch 49/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9899\n","Epoch 49: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9899 - val_loss: 0.1197 - val_accuracy: 0.9500\n","Epoch 50/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0181 - accuracy: 0.9946\n","Epoch 50: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1088 - val_accuracy: 0.9700\n","Epoch 51/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000\n","Epoch 51: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9800\n","Epoch 52/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0629 - accuracy: 0.9792\n","Epoch 52: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0615 - accuracy: 0.9798 - val_loss: 0.1574 - val_accuracy: 0.9300\n","Epoch 53/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0472 - accuracy: 0.9844\n","Epoch 53: val_loss did not improve from 0.07732\n","25/25 [==============================] - 1s 22ms/step - loss: 0.0461 - accuracy: 0.9849 - val_loss: 0.1541 - val_accuracy: 0.9200\n","Epoch 54/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0175 - accuracy: 0.9972\n","Epoch 54: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0172 - accuracy: 0.9975 - val_loss: 0.1081 - val_accuracy: 0.9800\n","Epoch 55/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0119 - accuracy: 1.0000\n","Epoch 55: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9800\n","Epoch 56/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n","Epoch 56: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9800\n","Epoch 57/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0099 - accuracy: 0.9973\n","Epoch 57: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0962 - val_accuracy: 0.9800\n","Epoch 58/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n","Epoch 58: val_loss did not improve from 0.07732\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9800\n","Epoch 59/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n","Epoch 59: val_loss did not improve from 0.07732\n","25/25 [==============================] - 1s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9800\n","Epoch 60/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n","Epoch 60: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9800\n","Epoch 61/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n","Epoch 61: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9800\n","Epoch 62/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 62: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9800\n","Epoch 63/150\n","12/25 [=============>................] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000    \n","Epoch 63: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9800\n","Epoch 64/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0099 - accuracy: 0.9955    \n","Epoch 64: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1098 - val_accuracy: 0.9800\n","Epoch 65/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n","Epoch 65: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9800\n","Epoch 66/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000    \n","Epoch 66: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9800\n","Epoch 67/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n","Epoch 67: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9800\n","Epoch 68/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0214 - accuracy: 0.9911    \n","Epoch 68: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.1626 - val_accuracy: 0.9400\n","Epoch 69/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n","Epoch 69: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9600\n","Epoch 70/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n","Epoch 70: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.9723 - val_loss: 0.3169 - val_accuracy: 0.8900\n","Epoch 71/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0505 - accuracy: 0.9667    \n","Epoch 71: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9723 - val_loss: 0.1469 - val_accuracy: 0.9700\n","Epoch 72/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0668 - accuracy: 0.9755\n","Epoch 72: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9773 - val_loss: 0.1385 - val_accuracy: 0.9500\n","Epoch 73/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0197 - accuracy: 0.9922\n","Epoch 73: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9924 - val_loss: 0.1121 - val_accuracy: 0.9800\n","Epoch 74/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.2031 - accuracy: 0.9727    \n","Epoch 74: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.1345 - accuracy: 0.9798 - val_loss: 0.0963 - val_accuracy: 0.9700\n","Epoch 75/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0177 - accuracy: 0.9917\n","Epoch 75: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9924 - val_loss: 0.1001 - val_accuracy: 0.9700\n","Epoch 76/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n","Epoch 76: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.3462 - val_accuracy: 0.9000\n","Epoch 77/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0355 - accuracy: 0.9777\n","Epoch 77: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9849 - val_loss: 0.0943 - val_accuracy: 0.9900\n","Epoch 78/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n","Epoch 78: val_loss did not improve from 0.07732\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9900\n","Epoch 78: early stopping\n","2022-09-16 08:00:49.500392: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"]}],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","source":["!python main.py --config config/config.yaml --test --trained_model result/models/test_model_DNN_111_0.990_0.025587.h5 --data_dir Data/LibPNG --output_dir result/finalResult"],"metadata":{"id":"RWidugIBVf2u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wlUQJMykfuGN"},"source":["##LSTM For LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390611,"status":"ok","timestamp":1660549836122,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"4NlQVs-jb_AU","outputId":"d7fa9f9b-90ee-4b4a-d8de-3f40cfd96334"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start training process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] -------------------------------------------------------\n","[INFO] Data processing completed!\n","[INFO] There are 397 total samples in the tr*aining set. 29 vulnerable samples. \n","[INFO] There are 100 total samples in the validation set. 9 vulnerable samples. \n","[INFO] -------------------------------------------------------\n","[INFO] Loading trained Word2vec model. \n","[INFO] The trained word2vec model: \n","<_io.TextIOWrapper name='result/w2v_model_CBOW_dict.txt' mode='r' encoding='UTF-8'>\n","[INFO] Found 1887 word vectors.\n","[0.53940217 6.84482759]\n","[INFO] -------------------------------------------------------\n","[INFO] Loading the LSTM model.\n","2022-08-15 07:44:11.109872: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] Model structure loaded.\n","Model: \"LSTM_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," cu_dnnlstm (CuDNNLSTM)      (None, 1000, 128)         117760    \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," cu_dnnlstm_1 (CuDNNLSTM)    (None, 1000, 128)         132096    \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 833,325\n","Trainable params: 260,225\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","Epoch 1/150\n","25/25 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.8539\n","Epoch 1: val_loss improved from inf to 0.67194, saving model to result/models/test_model_DNN_01_0.820_0.671941.h5\n","25/25 [==============================] - 6s 129ms/step - loss: 0.7321 - accuracy: 0.8539 - val_loss: 0.6719 - val_accuracy: 0.8200\n","Epoch 2/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.6171\n","Epoch 2: val_loss did not improve from 0.67194\n","25/25 [==============================] - 2s 85ms/step - loss: 0.6857 - accuracy: 0.6171 - val_loss: 0.6836 - val_accuracy: 0.6400\n","Epoch 3/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.5642\n","Epoch 3: val_loss did not improve from 0.67194\n","25/25 [==============================] - 2s 85ms/step - loss: 0.6813 - accuracy: 0.5642 - val_loss: 0.6771 - val_accuracy: 0.7300\n","Epoch 4/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.5365\n","Epoch 4: val_loss did not improve from 0.67194\n","25/25 [==============================] - 2s 90ms/step - loss: 0.6690 - accuracy: 0.5365 - val_loss: 0.6738 - val_accuracy: 0.7300\n","Epoch 5/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.5264\n","Epoch 5: val_loss improved from 0.67194 to 0.63836, saving model to result/models/test_model_DNN_05_0.910_0.638361.h5\n","25/25 [==============================] - 2s 87ms/step - loss: 0.6606 - accuracy: 0.5264 - val_loss: 0.6384 - val_accuracy: 0.9100\n","Epoch 6/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.5793\n","Epoch 6: val_loss improved from 0.63836 to 0.61914, saving model to result/models/test_model_DNN_06_0.920_0.619145.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.6400 - accuracy: 0.5793 - val_loss: 0.6191 - val_accuracy: 0.9200\n","Epoch 7/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.6423\n","Epoch 7: val_loss improved from 0.61914 to 0.60673, saving model to result/models/test_model_DNN_07_0.920_0.606727.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.6363 - accuracy: 0.6423 - val_loss: 0.6067 - val_accuracy: 0.9200\n","Epoch 8/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7154\n","Epoch 8: val_loss improved from 0.60673 to 0.55457, saving model to result/models/test_model_DNN_08_0.930_0.554570.h5\n","25/25 [==============================] - 2s 92ms/step - loss: 0.6096 - accuracy: 0.7154 - val_loss: 0.5546 - val_accuracy: 0.9300\n","Epoch 9/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7128\n","Epoch 9: val_loss improved from 0.55457 to 0.53634, saving model to result/models/test_model_DNN_09_0.930_0.536338.h5\n","25/25 [==============================] - 2s 87ms/step - loss: 0.6111 - accuracy: 0.7128 - val_loss: 0.5363 - val_accuracy: 0.9300\n","Epoch 10/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.7305\n","Epoch 10: val_loss improved from 0.53634 to 0.48948, saving model to result/models/test_model_DNN_10_0.930_0.489481.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.5772 - accuracy: 0.7305 - val_loss: 0.4895 - val_accuracy: 0.9300\n","Epoch 11/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.7557\n","Epoch 11: val_loss improved from 0.48948 to 0.45263, saving model to result/models/test_model_DNN_11_0.930_0.452634.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.5718 - accuracy: 0.7557 - val_loss: 0.4526 - val_accuracy: 0.9300\n","Epoch 12/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.7506\n","Epoch 12: val_loss improved from 0.45263 to 0.41488, saving model to result/models/test_model_DNN_12_0.940_0.414881.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.5425 - accuracy: 0.7506 - val_loss: 0.4149 - val_accuracy: 0.9400\n","Epoch 13/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.8161\n","Epoch 13: val_loss improved from 0.41488 to 0.34419, saving model to result/models/test_model_DNN_13_0.940_0.344192.h5\n","25/25 [==============================] - 2s 92ms/step - loss: 0.4762 - accuracy: 0.8161 - val_loss: 0.3442 - val_accuracy: 0.9400\n","Epoch 14/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8388\n","Epoch 14: val_loss improved from 0.34419 to 0.30958, saving model to result/models/test_model_DNN_14_0.930_0.309584.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.4381 - accuracy: 0.8388 - val_loss: 0.3096 - val_accuracy: 0.9300\n","Epoch 15/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.8161\n","Epoch 15: val_loss improved from 0.30958 to 0.28866, saving model to result/models/test_model_DNN_15_0.940_0.288657.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.4709 - accuracy: 0.8161 - val_loss: 0.2887 - val_accuracy: 0.9400\n","Epoch 16/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.8463\n","Epoch 16: val_loss improved from 0.28866 to 0.26504, saving model to result/models/test_model_DNN_16_0.940_0.265035.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.4151 - accuracy: 0.8463 - val_loss: 0.2650 - val_accuracy: 0.9400\n","Epoch 17/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8489\n","Epoch 17: val_loss improved from 0.26504 to 0.22127, saving model to result/models/test_model_DNN_17_0.930_0.221271.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.3853 - accuracy: 0.8489 - val_loss: 0.2213 - val_accuracy: 0.9300\n","Epoch 18/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3962 - accuracy: 0.8161\n","Epoch 18: val_loss improved from 0.22127 to 0.22122, saving model to result/models/test_model_DNN_18_0.940_0.221220.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.3962 - accuracy: 0.8161 - val_loss: 0.2212 - val_accuracy: 0.9400\n","Epoch 19/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8388\n","Epoch 19: val_loss improved from 0.22122 to 0.18435, saving model to result/models/test_model_DNN_19_0.930_0.184346.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.3664 - accuracy: 0.8388 - val_loss: 0.1843 - val_accuracy: 0.9300\n","Epoch 20/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.8690\n","Epoch 20: val_loss improved from 0.18435 to 0.17577, saving model to result/models/test_model_DNN_20_0.940_0.175765.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.3405 - accuracy: 0.8690 - val_loss: 0.1758 - val_accuracy: 0.9400\n","Epoch 21/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3314 - accuracy: 0.8514\n","Epoch 21: val_loss improved from 0.17577 to 0.16190, saving model to result/models/test_model_DNN_21_0.950_0.161898.h5\n","25/25 [==============================] - 2s 89ms/step - loss: 0.3314 - accuracy: 0.8514 - val_loss: 0.1619 - val_accuracy: 0.9500\n","Epoch 22/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8564\n","Epoch 22: val_loss improved from 0.16190 to 0.15055, saving model to result/models/test_model_DNN_22_0.940_0.150553.h5\n","25/25 [==============================] - 2s 89ms/step - loss: 0.3416 - accuracy: 0.8564 - val_loss: 0.1506 - val_accuracy: 0.9400\n","Epoch 23/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.8690\n","Epoch 23: val_loss did not improve from 0.15055\n","25/25 [==============================] - 2s 87ms/step - loss: 0.3124 - accuracy: 0.8690 - val_loss: 0.1633 - val_accuracy: 0.9400\n","Epoch 24/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.8741\n","Epoch 24: val_loss improved from 0.15055 to 0.14527, saving model to result/models/test_model_DNN_24_0.950_0.145273.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.3002 - accuracy: 0.8741 - val_loss: 0.1453 - val_accuracy: 0.9500\n","Epoch 25/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.8841\n","Epoch 25: val_loss improved from 0.14527 to 0.12718, saving model to result/models/test_model_DNN_25_0.960_0.127184.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.3118 - accuracy: 0.8841 - val_loss: 0.1272 - val_accuracy: 0.9600\n","Epoch 26/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.8816\n","Epoch 26: val_loss did not improve from 0.12718\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2569 - accuracy: 0.8816 - val_loss: 0.1391 - val_accuracy: 0.9400\n","Epoch 27/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2810 - accuracy: 0.8967\n","Epoch 27: val_loss did not improve from 0.12718\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2810 - accuracy: 0.8967 - val_loss: 0.1440 - val_accuracy: 0.9400\n","Epoch 28/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.8866\n","Epoch 28: val_loss improved from 0.12718 to 0.11537, saving model to result/models/test_model_DNN_28_0.960_0.115366.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.2744 - accuracy: 0.8866 - val_loss: 0.1154 - val_accuracy: 0.9600\n","Epoch 29/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.8564\n","Epoch 29: val_loss improved from 0.11537 to 0.11272, saving model to result/models/test_model_DNN_29_0.960_0.112721.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.3105 - accuracy: 0.8564 - val_loss: 0.1127 - val_accuracy: 0.9600\n","Epoch 30/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9144\n","Epoch 30: val_loss improved from 0.11272 to 0.10841, saving model to result/models/test_model_DNN_30_0.960_0.108406.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2133 - accuracy: 0.9144 - val_loss: 0.1084 - val_accuracy: 0.9600\n","Epoch 31/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.8942\n","Epoch 31: val_loss improved from 0.10841 to 0.10700, saving model to result/models/test_model_DNN_31_0.960_0.106998.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2610 - accuracy: 0.8942 - val_loss: 0.1070 - val_accuracy: 0.9600\n","Epoch 32/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9270\n","Epoch 32: val_loss improved from 0.10700 to 0.10534, saving model to result/models/test_model_DNN_32_0.950_0.105338.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.1885 - accuracy: 0.9270 - val_loss: 0.1053 - val_accuracy: 0.9500\n","Epoch 33/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9219\n","Epoch 33: val_loss did not improve from 0.10534\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2114 - accuracy: 0.9219 - val_loss: 0.1078 - val_accuracy: 0.9500\n","Epoch 34/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9194\n","Epoch 34: val_loss improved from 0.10534 to 0.09717, saving model to result/models/test_model_DNN_34_0.960_0.097174.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2460 - accuracy: 0.9194 - val_loss: 0.0972 - val_accuracy: 0.9600\n","Epoch 35/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.8967\n","Epoch 35: val_loss improved from 0.09717 to 0.09679, saving model to result/models/test_model_DNN_35_0.970_0.096792.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2230 - accuracy: 0.8967 - val_loss: 0.0968 - val_accuracy: 0.9700\n","Epoch 36/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.9043\n","Epoch 36: val_loss did not improve from 0.09679\n","25/25 [==============================] - 2s 89ms/step - loss: 0.2309 - accuracy: 0.9043 - val_loss: 0.0999 - val_accuracy: 0.9400\n","Epoch 37/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.9068\n","Epoch 37: val_loss did not improve from 0.09679\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2467 - accuracy: 0.9068 - val_loss: 0.1672 - val_accuracy: 0.9200\n","Epoch 38/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9068\n","Epoch 38: val_loss improved from 0.09679 to 0.08389, saving model to result/models/test_model_DNN_38_0.970_0.083889.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2125 - accuracy: 0.9068 - val_loss: 0.0839 - val_accuracy: 0.9700\n","Epoch 39/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.9270\n","Epoch 39: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2430 - accuracy: 0.9270 - val_loss: 0.0861 - val_accuracy: 0.9700\n","Epoch 40/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9118\n","Epoch 40: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2093 - accuracy: 0.9118 - val_loss: 0.0851 - val_accuracy: 0.9700\n","Epoch 41/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.8514\n","Epoch 41: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2773 - accuracy: 0.8514 - val_loss: 0.0951 - val_accuracy: 0.9600\n","Epoch 42/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.8992\n","Epoch 42: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2564 - accuracy: 0.8992 - val_loss: 0.0920 - val_accuracy: 0.9600\n","Epoch 43/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.7683\n","Epoch 43: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 94ms/step - loss: 0.3753 - accuracy: 0.7683 - val_loss: 0.1845 - val_accuracy: 0.9700\n","Epoch 44/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.8816\n","Epoch 44: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 91ms/step - loss: 0.3024 - accuracy: 0.8816 - val_loss: 0.1284 - val_accuracy: 0.9600\n","Epoch 45/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.8992\n","Epoch 45: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 96ms/step - loss: 0.2172 - accuracy: 0.8992 - val_loss: 0.0886 - val_accuracy: 0.9600\n","Epoch 46/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9169\n","Epoch 46: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 99ms/step - loss: 0.2001 - accuracy: 0.9169 - val_loss: 0.1062 - val_accuracy: 0.9400\n","Epoch 47/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9169\n","Epoch 47: val_loss did not improve from 0.08389\n","25/25 [==============================] - 2s 90ms/step - loss: 0.1853 - accuracy: 0.9169 - val_loss: 0.0887 - val_accuracy: 0.9500\n","Epoch 48/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9270\n","Epoch 48: val_loss improved from 0.08389 to 0.06815, saving model to result/models/test_model_DNN_48_0.980_0.068152.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.1683 - accuracy: 0.9270 - val_loss: 0.0682 - val_accuracy: 0.9800\n","Epoch 49/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8766\n","Epoch 49: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 94ms/step - loss: 0.3383 - accuracy: 0.8766 - val_loss: 0.1007 - val_accuracy: 0.9600\n","Epoch 50/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9144\n","Epoch 50: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 89ms/step - loss: 0.2234 - accuracy: 0.9144 - val_loss: 0.0875 - val_accuracy: 0.9500\n","Epoch 51/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9320\n","Epoch 51: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1730 - accuracy: 0.9320 - val_loss: 0.0712 - val_accuracy: 0.9800\n","Epoch 52/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9194\n","Epoch 52: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2249 - accuracy: 0.9194 - val_loss: 0.0725 - val_accuracy: 0.9800\n","Epoch 53/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9194\n","Epoch 53: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2295 - accuracy: 0.9194 - val_loss: 0.0911 - val_accuracy: 0.9500\n","Epoch 54/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9421\n","Epoch 54: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1310 - accuracy: 0.9421 - val_loss: 0.0692 - val_accuracy: 0.9900\n","Epoch 55/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9169\n","Epoch 55: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 89ms/step - loss: 0.2008 - accuracy: 0.9169 - val_loss: 0.2011 - val_accuracy: 0.9200\n","Epoch 56/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.8892\n","Epoch 56: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 93ms/step - loss: 0.2600 - accuracy: 0.8892 - val_loss: 0.0921 - val_accuracy: 0.9700\n","Epoch 57/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9194\n","Epoch 57: val_loss did not improve from 0.06815\n","25/25 [==============================] - 2s 89ms/step - loss: 0.2793 - accuracy: 0.9194 - val_loss: 0.0868 - val_accuracy: 0.9700\n","Epoch 58/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9446\n","Epoch 58: val_loss improved from 0.06815 to 0.06119, saving model to result/models/test_model_DNN_58_0.980_0.061193.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.1468 - accuracy: 0.9446 - val_loss: 0.0612 - val_accuracy: 0.9800\n","Epoch 59/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9370\n","Epoch 59: val_loss did not improve from 0.06119\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1472 - accuracy: 0.9370 - val_loss: 0.0699 - val_accuracy: 0.9700\n","Epoch 60/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9270\n","Epoch 60: val_loss did not improve from 0.06119\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1694 - accuracy: 0.9270 - val_loss: 0.0862 - val_accuracy: 0.9700\n","Epoch 61/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9370\n","Epoch 61: val_loss did not improve from 0.06119\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1689 - accuracy: 0.9370 - val_loss: 0.0842 - val_accuracy: 0.9700\n","Epoch 62/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9295\n","Epoch 62: val_loss improved from 0.06119 to 0.05683, saving model to result/models/test_model_DNN_62_0.980_0.056834.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.1571 - accuracy: 0.9295 - val_loss: 0.0568 - val_accuracy: 0.9800\n","Epoch 63/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9320\n","Epoch 63: val_loss did not improve from 0.05683\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1714 - accuracy: 0.9320 - val_loss: 0.0627 - val_accuracy: 0.9800\n","Epoch 64/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9194\n","Epoch 64: val_loss did not improve from 0.05683\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1773 - accuracy: 0.9194 - val_loss: 0.0756 - val_accuracy: 0.9800\n","Epoch 65/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.8917\n","Epoch 65: val_loss did not improve from 0.05683\n","25/25 [==============================] - 2s 89ms/step - loss: 0.2083 - accuracy: 0.8917 - val_loss: 0.1002 - val_accuracy: 0.9700\n","Epoch 66/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9345\n","Epoch 66: val_loss did not improve from 0.05683\n","25/25 [==============================] - 2s 88ms/step - loss: 0.1625 - accuracy: 0.9345 - val_loss: 0.0761 - val_accuracy: 0.9800\n","Epoch 67/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9345\n","Epoch 67: val_loss did not improve from 0.05683\n","25/25 [==============================] - 2s 88ms/step - loss: 0.1570 - accuracy: 0.9345 - val_loss: 0.0613 - val_accuracy: 0.9800\n","Epoch 68/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9345\n","Epoch 68: val_loss improved from 0.05683 to 0.04988, saving model to result/models/test_model_DNN_68_0.980_0.049879.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1599 - accuracy: 0.9345 - val_loss: 0.0499 - val_accuracy: 0.9800\n","Epoch 69/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9421\n","Epoch 69: val_loss did not improve from 0.04988\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1290 - accuracy: 0.9421 - val_loss: 0.0606 - val_accuracy: 0.9800\n","Epoch 70/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9345\n","Epoch 70: val_loss did not improve from 0.04988\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1378 - accuracy: 0.9345 - val_loss: 0.0512 - val_accuracy: 0.9800\n","Epoch 71/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9471\n","Epoch 71: val_loss did not improve from 0.04988\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1887 - accuracy: 0.9471 - val_loss: 0.0693 - val_accuracy: 0.9800\n","Epoch 72/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9345\n","Epoch 72: val_loss improved from 0.04988 to 0.04977, saving model to result/models/test_model_DNN_72_0.990_0.049767.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.1331 - accuracy: 0.9345 - val_loss: 0.0498 - val_accuracy: 0.9900\n","Epoch 73/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9496\n","Epoch 73: val_loss did not improve from 0.04977\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1303 - accuracy: 0.9496 - val_loss: 0.0602 - val_accuracy: 0.9800\n","Epoch 74/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9471\n","Epoch 74: val_loss did not improve from 0.04977\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1142 - accuracy: 0.9471 - val_loss: 0.0539 - val_accuracy: 0.9800\n","Epoch 75/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9320\n","Epoch 75: val_loss did not improve from 0.04977\n","25/25 [==============================] - 2s 90ms/step - loss: 0.1690 - accuracy: 0.9320 - val_loss: 0.0845 - val_accuracy: 0.9800\n","Epoch 76/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9597\n","Epoch 76: val_loss did not improve from 0.04977\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0914 - accuracy: 0.9597 - val_loss: 0.0580 - val_accuracy: 0.9800\n","Epoch 77/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9572\n","Epoch 77: val_loss did not improve from 0.04977\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0996 - accuracy: 0.9572 - val_loss: 0.0520 - val_accuracy: 0.9800\n","Epoch 78/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9521\n","Epoch 78: val_loss improved from 0.04977 to 0.04710, saving model to result/models/test_model_DNN_78_0.990_0.047095.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0919 - accuracy: 0.9521 - val_loss: 0.0471 - val_accuracy: 0.9900\n","Epoch 79/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9521\n","Epoch 79: val_loss did not improve from 0.04710\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1145 - accuracy: 0.9521 - val_loss: 0.1369 - val_accuracy: 0.9600\n","Epoch 80/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9597\n","Epoch 80: val_loss improved from 0.04710 to 0.03689, saving model to result/models/test_model_DNN_80_0.990_0.036885.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0898 - accuracy: 0.9597 - val_loss: 0.0369 - val_accuracy: 0.9900\n","Epoch 81/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9647\n","Epoch 81: val_loss did not improve from 0.03689\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0916 - accuracy: 0.9647 - val_loss: 0.0482 - val_accuracy: 0.9900\n","Epoch 82/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9521\n","Epoch 82: val_loss did not improve from 0.03689\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1182 - accuracy: 0.9521 - val_loss: 0.0378 - val_accuracy: 0.9900\n","Epoch 83/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9345\n","Epoch 83: val_loss did not improve from 0.03689\n","25/25 [==============================] - 3s 109ms/step - loss: 0.1382 - accuracy: 0.9345 - val_loss: 0.0416 - val_accuracy: 0.9800\n","Epoch 84/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9647\n","Epoch 84: val_loss did not improve from 0.03689\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0712 - accuracy: 0.9647 - val_loss: 0.0431 - val_accuracy: 0.9900\n","Epoch 85/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9673\n","Epoch 85: val_loss did not improve from 0.03689\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0708 - accuracy: 0.9673 - val_loss: 0.0423 - val_accuracy: 0.9800\n","Epoch 86/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9698\n","Epoch 86: val_loss did not improve from 0.03689\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0938 - accuracy: 0.9698 - val_loss: 0.0960 - val_accuracy: 0.9800\n","Epoch 87/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9521\n","Epoch 87: val_loss improved from 0.03689 to 0.03262, saving model to result/models/test_model_DNN_87_0.990_0.032622.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.0860 - accuracy: 0.9521 - val_loss: 0.0326 - val_accuracy: 0.9900\n","Epoch 88/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9673\n","Epoch 88: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0790 - accuracy: 0.9673 - val_loss: 0.0352 - val_accuracy: 0.9900\n","Epoch 89/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9698\n","Epoch 89: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0725 - accuracy: 0.9698 - val_loss: 0.0352 - val_accuracy: 0.9900\n","Epoch 90/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9647\n","Epoch 90: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0837 - accuracy: 0.9647 - val_loss: 0.0480 - val_accuracy: 0.9800\n","Epoch 91/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9647\n","Epoch 91: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0998 - accuracy: 0.9647 - val_loss: 0.1099 - val_accuracy: 0.9700\n","Epoch 92/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9647\n","Epoch 92: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0665 - accuracy: 0.9647 - val_loss: 0.0449 - val_accuracy: 0.9900\n","Epoch 93/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9471\n","Epoch 93: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1351 - accuracy: 0.9471 - val_loss: 0.1119 - val_accuracy: 0.9600\n","Epoch 94/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9673\n","Epoch 94: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0968 - accuracy: 0.9673 - val_loss: 0.0364 - val_accuracy: 0.9900\n","Epoch 95/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9647\n","Epoch 95: val_loss did not improve from 0.03262\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0704 - accuracy: 0.9647 - val_loss: 0.0338 - val_accuracy: 0.9900\n","Epoch 96/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9698\n","Epoch 96: val_loss improved from 0.03262 to 0.02774, saving model to result/models/test_model_DNN_96_0.990_0.027743.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0563 - accuracy: 0.9698 - val_loss: 0.0277 - val_accuracy: 0.9900\n","Epoch 97/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9597\n","Epoch 97: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1005 - accuracy: 0.9597 - val_loss: 0.0764 - val_accuracy: 0.9600\n","Epoch 98/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9471\n","Epoch 98: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1157 - accuracy: 0.9471 - val_loss: 0.0625 - val_accuracy: 0.9800\n","Epoch 99/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9698\n","Epoch 99: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 99ms/step - loss: 0.0680 - accuracy: 0.9698 - val_loss: 0.0543 - val_accuracy: 0.9800\n","Epoch 100/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9773\n","Epoch 100: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 91ms/step - loss: 0.0769 - accuracy: 0.9773 - val_loss: 0.0591 - val_accuracy: 0.9900\n","Epoch 101/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9748\n","Epoch 101: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0667 - accuracy: 0.9748 - val_loss: 0.0529 - val_accuracy: 0.9800\n","Epoch 102/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9647\n","Epoch 102: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0826 - accuracy: 0.9647 - val_loss: 0.0509 - val_accuracy: 0.9900\n","Epoch 103/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9572\n","Epoch 103: val_loss did not improve from 0.02774\n","25/25 [==============================] - 3s 113ms/step - loss: 0.0969 - accuracy: 0.9572 - val_loss: 0.1824 - val_accuracy: 0.9600\n","Epoch 104/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9194\n","Epoch 104: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 95ms/step - loss: 0.1611 - accuracy: 0.9194 - val_loss: 0.0589 - val_accuracy: 0.9800\n","Epoch 105/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.9244\n","Epoch 105: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1996 - accuracy: 0.9244 - val_loss: 0.0728 - val_accuracy: 0.9700\n","Epoch 106/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9521\n","Epoch 106: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1176 - accuracy: 0.9521 - val_loss: 0.0560 - val_accuracy: 0.9800\n","Epoch 107/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9144\n","Epoch 107: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 89ms/step - loss: 0.2019 - accuracy: 0.9144 - val_loss: 0.1133 - val_accuracy: 0.9700\n","Epoch 108/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9370\n","Epoch 108: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1088 - accuracy: 0.9370 - val_loss: 0.0736 - val_accuracy: 0.9700\n","Epoch 109/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9471\n","Epoch 109: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 90ms/step - loss: 0.1062 - accuracy: 0.9471 - val_loss: 0.0438 - val_accuracy: 0.9900\n","Epoch 110/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9597\n","Epoch 110: val_loss did not improve from 0.02774\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0852 - accuracy: 0.9597 - val_loss: 0.0657 - val_accuracy: 0.9900\n","Epoch 111/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9723\n","Epoch 111: val_loss improved from 0.02774 to 0.02559, saving model to result/models/test_model_DNN_111_0.990_0.025587.h5\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0592 - accuracy: 0.9723 - val_loss: 0.0256 - val_accuracy: 0.9900\n","Epoch 112/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9597\n","Epoch 112: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1209 - accuracy: 0.9597 - val_loss: 0.0500 - val_accuracy: 0.9900\n","Epoch 113/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9547\n","Epoch 113: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0871 - accuracy: 0.9547 - val_loss: 0.1203 - val_accuracy: 0.9800\n","Epoch 114/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9773\n","Epoch 114: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0738 - accuracy: 0.9773 - val_loss: 0.0527 - val_accuracy: 0.9900\n","Epoch 115/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9244\n","Epoch 115: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1698 - accuracy: 0.9244 - val_loss: 0.0695 - val_accuracy: 0.9800\n","Epoch 116/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 0.9345\n","Epoch 116: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1306 - accuracy: 0.9345 - val_loss: 0.0973 - val_accuracy: 0.9500\n","Epoch 117/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9421\n","Epoch 117: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1889 - accuracy: 0.9421 - val_loss: 0.0739 - val_accuracy: 0.9800\n","Epoch 118/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9723\n","Epoch 118: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0704 - accuracy: 0.9723 - val_loss: 0.0574 - val_accuracy: 0.9800\n","Epoch 119/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9723\n","Epoch 119: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0724 - accuracy: 0.9723 - val_loss: 0.0501 - val_accuracy: 0.9900\n","Epoch 120/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9547\n","Epoch 120: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1105 - accuracy: 0.9547 - val_loss: 0.0750 - val_accuracy: 0.9800\n","Epoch 121/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9673\n","Epoch 121: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0860 - accuracy: 0.9673 - val_loss: 0.0384 - val_accuracy: 0.9900\n","Epoch 122/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9773\n","Epoch 122: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 0.0475 - val_accuracy: 0.9900\n","Epoch 123/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9572\n","Epoch 123: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1210 - accuracy: 0.9572 - val_loss: 0.0773 - val_accuracy: 0.9800\n","Epoch 124/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9748\n","Epoch 124: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 90ms/step - loss: 0.0570 - accuracy: 0.9748 - val_loss: 0.0454 - val_accuracy: 0.9800\n","Epoch 125/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9849\n","Epoch 125: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0358 - accuracy: 0.9849 - val_loss: 0.0457 - val_accuracy: 0.9800\n","Epoch 126/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9647\n","Epoch 126: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0875 - accuracy: 0.9647 - val_loss: 0.0506 - val_accuracy: 0.9900\n","Epoch 127/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9773\n","Epoch 127: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0547 - accuracy: 0.9773 - val_loss: 0.0357 - val_accuracy: 0.9900\n","Epoch 128/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9849\n","Epoch 128: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 98ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 0.0596 - val_accuracy: 0.9900\n","Epoch 129/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9874\n","Epoch 129: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.0373 - val_accuracy: 0.9900\n","Epoch 130/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9698\n","Epoch 130: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0889 - accuracy: 0.9698 - val_loss: 0.0553 - val_accuracy: 0.9700\n","Epoch 131/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9824\n","Epoch 131: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 0.0522 - val_accuracy: 0.9800\n","Epoch 132/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9874\n","Epoch 132: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0295 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9700\n","Epoch 133/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9647\n","Epoch 133: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.1060 - accuracy: 0.9647 - val_loss: 0.0427 - val_accuracy: 0.9900\n","Epoch 134/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9874\n","Epoch 134: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.0479 - val_accuracy: 0.9900\n","Epoch 135/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9849\n","Epoch 135: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0416 - accuracy: 0.9849 - val_loss: 0.0404 - val_accuracy: 0.9900\n","Epoch 136/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9673\n","Epoch 136: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0696 - accuracy: 0.9673 - val_loss: 0.0354 - val_accuracy: 0.9900\n","Epoch 137/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9798\n","Epoch 137: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0515 - accuracy: 0.9798 - val_loss: 0.0343 - val_accuracy: 0.9900\n","Epoch 138/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9849\n","Epoch 138: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0363 - accuracy: 0.9849 - val_loss: 0.0393 - val_accuracy: 0.9800\n","Epoch 139/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9798\n","Epoch 139: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0348 - accuracy: 0.9798 - val_loss: 0.0367 - val_accuracy: 0.9900\n","Epoch 140/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9849\n","Epoch 140: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0308 - accuracy: 0.9849 - val_loss: 0.0460 - val_accuracy: 0.9800\n","Epoch 141/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9798\n","Epoch 141: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0587 - accuracy: 0.9798 - val_loss: 0.1160 - val_accuracy: 0.9800\n","Epoch 142/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9798\n","Epoch 142: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0407 - accuracy: 0.9798 - val_loss: 0.0480 - val_accuracy: 0.9900\n","Epoch 143/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9849\n","Epoch 143: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0325 - accuracy: 0.9849 - val_loss: 0.0735 - val_accuracy: 0.9700\n","Epoch 144/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9874\n","Epoch 144: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0216 - accuracy: 0.9874 - val_loss: 0.0477 - val_accuracy: 0.9900\n","Epoch 145/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9698\n","Epoch 145: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 89ms/step - loss: 0.0638 - accuracy: 0.9698 - val_loss: 0.0939 - val_accuracy: 0.9800\n","Epoch 146/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9446\n","Epoch 146: val_loss did not improve from 0.02559\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1264 - accuracy: 0.9446 - val_loss: 0.0767 - val_accuracy: 0.9800\n","Epoch 146: early stopping\n"]}],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10444,"status":"ok","timestamp":1660550178750,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"Jik67qkVfNde","outputId":"1cce8bfe-9592-4213-827d-286f0f60eb6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start testing process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] There are 125 total samples in the test set. 7 vulnerable samples. \n","2022-08-15 07:56:14.008897: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Model: \"LSTM_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," cu_dnnlstm (CuDNNLSTM)      (None, 1000, 128)         117760    \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," cu_dnnlstm_1 (CuDNNLSTM)    (None, 1000, 128)         132096    \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 833,325\n","Trainable params: 260,225\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","8/8 [==============================] - 3s 59ms/step\n","[INFO] LSTM classification result: \n","\n","[INFO] Total accuracy: 0.952\n","[INFO] ----------------------------------------------------\n","[INFO] The confusion matrix: \n","\n","[[113   5]\n"," [  1   6]]\n","\n","\n","                precision    recall  f1-score   support\n","\n","Non-vulnerable       0.99      0.96      0.97       118\n","    Vulnerable       0.55      0.86      0.67         7\n","\n","      accuracy                           0.95       125\n","     macro avg       0.77      0.91      0.82       125\n","  weighted avg       0.97      0.95      0.96       125\n","\n"]}],"source":["!python main.py --config config/config.yaml --test --trained_model result/models/test_model_DNN_111_0.990_0.025587.h5 --data_dir Data/LibPNG --output_dir result/finalResult"]},{"cell_type":"markdown","metadata":{"id":"B5oKcCh5hB55"},"source":["##GRU for LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390905,"status":"ok","timestamp":1660550807594,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"GnZaEVS-hGOv","outputId":"ee9bf63e-836e-4122-caab-e4134b9f0ba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start training process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] -------------------------------------------------------\n","[INFO] Data processing completed!\n","[INFO] There are 397 total samples in the tr*aining set. 29 vulnerable samples. \n","[INFO] There are 100 total samples in the validation set. 9 vulnerable samples. \n","[INFO] -------------------------------------------------------\n","[INFO] Loading trained Word2vec model. \n","[INFO] The trained word2vec model: \n","<_io.TextIOWrapper name='result/w2v_model_CBOW_dict.txt' mode='r' encoding='UTF-8'>\n","[INFO] Found 1887 word vectors.\n","[0.53940217 6.84482759]\n","[INFO] -------------------------------------------------------\n","[INFO] Loading the GRU model.\n","2022-08-15 08:00:22.780549: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] Model structure loaded.\n","Model: \"GRU_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," cu_dnngru (CuDNNGRU)        (None, 1000, 128)         88320     \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," cu_dnngru_1 (CuDNNGRU)      (None, 1000, 128)         99072     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 770,861\n","Trainable params: 197,761\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","Epoch 1/150\n","25/25 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.5038\n","Epoch 1: val_loss improved from inf to 0.70304, saving model to result/models/test_model_DNN_01_0.430_0.703038.h5\n","25/25 [==============================] - 6s 118ms/step - loss: 0.7436 - accuracy: 0.5038 - val_loss: 0.7030 - val_accuracy: 0.4300\n","Epoch 2/150\n","25/25 [==============================] - ETA: 0s - loss: 0.7054 - accuracy: 0.4207\n","Epoch 2: val_loss improved from 0.70304 to 0.68045, saving model to result/models/test_model_DNN_02_0.600_0.680452.h5\n","25/25 [==============================] - 2s 92ms/step - loss: 0.7054 - accuracy: 0.4207 - val_loss: 0.6805 - val_accuracy: 0.6000\n","Epoch 3/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.4232\n","Epoch 3: val_loss improved from 0.68045 to 0.64984, saving model to result/models/test_model_DNN_03_0.760_0.649835.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.6875 - accuracy: 0.4232 - val_loss: 0.6498 - val_accuracy: 0.7600\n","Epoch 4/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.4937\n","Epoch 4: val_loss improved from 0.64984 to 0.61936, saving model to result/models/test_model_DNN_04_0.810_0.619361.h5\n","25/25 [==============================] - 2s 92ms/step - loss: 0.6777 - accuracy: 0.4937 - val_loss: 0.6194 - val_accuracy: 0.8100\n","Epoch 5/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.5869\n","Epoch 5: val_loss improved from 0.61936 to 0.59744, saving model to result/models/test_model_DNN_05_0.850_0.597442.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.6382 - accuracy: 0.5869 - val_loss: 0.5974 - val_accuracy: 0.8500\n","Epoch 6/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.6071\n","Epoch 6: val_loss improved from 0.59744 to 0.53025, saving model to result/models/test_model_DNN_06_0.900_0.530248.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.6092 - accuracy: 0.6071 - val_loss: 0.5302 - val_accuracy: 0.9000\n","Epoch 7/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.6675\n","Epoch 7: val_loss improved from 0.53025 to 0.52790, saving model to result/models/test_model_DNN_07_0.880_0.527897.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.6126 - accuracy: 0.6675 - val_loss: 0.5279 - val_accuracy: 0.8800\n","Epoch 8/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5741 - accuracy: 0.6625\n","Epoch 8: val_loss improved from 0.52790 to 0.48039, saving model to result/models/test_model_DNN_08_0.920_0.480387.h5\n","25/25 [==============================] - 2s 88ms/step - loss: 0.5741 - accuracy: 0.6625 - val_loss: 0.4804 - val_accuracy: 0.9200\n","Epoch 9/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5627 - accuracy: 0.6650\n","Epoch 9: val_loss improved from 0.48039 to 0.45146, saving model to result/models/test_model_DNN_09_0.940_0.451455.h5\n","25/25 [==============================] - 2s 89ms/step - loss: 0.5627 - accuracy: 0.6650 - val_loss: 0.4515 - val_accuracy: 0.9400\n","Epoch 10/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.6977\n","Epoch 10: val_loss improved from 0.45146 to 0.39717, saving model to result/models/test_model_DNN_10_0.950_0.397170.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.5387 - accuracy: 0.6977 - val_loss: 0.3972 - val_accuracy: 0.9500\n","Epoch 11/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.7632\n","Epoch 11: val_loss improved from 0.39717 to 0.37473, saving model to result/models/test_model_DNN_11_0.950_0.374735.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.4989 - accuracy: 0.7632 - val_loss: 0.3747 - val_accuracy: 0.9500\n","Epoch 12/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.7557\n","Epoch 12: val_loss improved from 0.37473 to 0.36334, saving model to result/models/test_model_DNN_12_0.950_0.363341.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.5020 - accuracy: 0.7557 - val_loss: 0.3633 - val_accuracy: 0.9500\n","Epoch 13/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.7783\n","Epoch 13: val_loss improved from 0.36334 to 0.32580, saving model to result/models/test_model_DNN_13_0.950_0.325802.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.4655 - accuracy: 0.7783 - val_loss: 0.3258 - val_accuracy: 0.9500\n","Epoch 14/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.8060\n","Epoch 14: val_loss improved from 0.32580 to 0.28121, saving model to result/models/test_model_DNN_14_0.950_0.281213.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.4290 - accuracy: 0.8060 - val_loss: 0.2812 - val_accuracy: 0.9500\n","Epoch 15/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7809\n","Epoch 15: val_loss did not improve from 0.28121\n","25/25 [==============================] - 2s 91ms/step - loss: 0.4409 - accuracy: 0.7809 - val_loss: 0.2864 - val_accuracy: 0.9500\n","Epoch 16/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8161\n","Epoch 16: val_loss improved from 0.28121 to 0.21957, saving model to result/models/test_model_DNN_16_0.950_0.219566.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.4094 - accuracy: 0.8161 - val_loss: 0.2196 - val_accuracy: 0.9500\n","Epoch 17/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8111\n","Epoch 17: val_loss improved from 0.21957 to 0.21212, saving model to result/models/test_model_DNN_17_0.950_0.212124.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.4054 - accuracy: 0.8111 - val_loss: 0.2121 - val_accuracy: 0.9500\n","Epoch 18/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.8338\n","Epoch 18: val_loss improved from 0.21212 to 0.20107, saving model to result/models/test_model_DNN_18_0.950_0.201071.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.3968 - accuracy: 0.8338 - val_loss: 0.2011 - val_accuracy: 0.9500\n","Epoch 19/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.8161\n","Epoch 19: val_loss did not improve from 0.20107\n","25/25 [==============================] - 2s 91ms/step - loss: 0.3935 - accuracy: 0.8161 - val_loss: 0.2013 - val_accuracy: 0.9500\n","Epoch 20/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8463\n","Epoch 20: val_loss improved from 0.20107 to 0.19143, saving model to result/models/test_model_DNN_20_0.960_0.191435.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.3242 - accuracy: 0.8463 - val_loss: 0.1914 - val_accuracy: 0.9600\n","Epoch 21/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3592 - accuracy: 0.8363\n","Epoch 21: val_loss improved from 0.19143 to 0.16015, saving model to result/models/test_model_DNN_21_0.960_0.160152.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.3592 - accuracy: 0.8363 - val_loss: 0.1602 - val_accuracy: 0.9600\n","Epoch 22/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8312\n","Epoch 22: val_loss improved from 0.16015 to 0.15128, saving model to result/models/test_model_DNN_22_0.950_0.151280.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.3663 - accuracy: 0.8312 - val_loss: 0.1513 - val_accuracy: 0.9500\n","Epoch 23/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8413\n","Epoch 23: val_loss did not improve from 0.15128\n","25/25 [==============================] - 2s 95ms/step - loss: 0.3908 - accuracy: 0.8413 - val_loss: 0.1640 - val_accuracy: 0.9600\n","Epoch 24/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8463\n","Epoch 24: val_loss improved from 0.15128 to 0.13712, saving model to result/models/test_model_DNN_24_0.960_0.137120.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.3090 - accuracy: 0.8463 - val_loss: 0.1371 - val_accuracy: 0.9600\n","Epoch 25/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.8489\n","Epoch 25: val_loss improved from 0.13712 to 0.13283, saving model to result/models/test_model_DNN_25_0.960_0.132832.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.3140 - accuracy: 0.8489 - val_loss: 0.1328 - val_accuracy: 0.9600\n","Epoch 26/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8564\n","Epoch 26: val_loss did not improve from 0.13283\n","25/25 [==============================] - 2s 92ms/step - loss: 0.3242 - accuracy: 0.8564 - val_loss: 0.1426 - val_accuracy: 0.9600\n","Epoch 27/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8338\n","Epoch 27: val_loss improved from 0.13283 to 0.12406, saving model to result/models/test_model_DNN_27_0.980_0.124057.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.3623 - accuracy: 0.8338 - val_loss: 0.1241 - val_accuracy: 0.9800\n","Epoch 28/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.8615\n","Epoch 28: val_loss improved from 0.12406 to 0.11233, saving model to result/models/test_model_DNN_28_0.970_0.112326.h5\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2731 - accuracy: 0.8615 - val_loss: 0.1123 - val_accuracy: 0.9700\n","Epoch 29/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.8917\n","Epoch 29: val_loss improved from 0.11233 to 0.10964, saving model to result/models/test_model_DNN_29_0.960_0.109640.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2496 - accuracy: 0.8917 - val_loss: 0.1096 - val_accuracy: 0.9600\n","Epoch 30/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.8589\n","Epoch 30: val_loss improved from 0.10964 to 0.10266, saving model to result/models/test_model_DNN_30_0.970_0.102658.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2759 - accuracy: 0.8589 - val_loss: 0.1027 - val_accuracy: 0.9700\n","Epoch 31/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8715\n","Epoch 31: val_loss did not improve from 0.10266\n","25/25 [==============================] - 2s 93ms/step - loss: 0.2983 - accuracy: 0.8715 - val_loss: 0.1038 - val_accuracy: 0.9600\n","Epoch 32/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8766\n","Epoch 32: val_loss improved from 0.10266 to 0.09989, saving model to result/models/test_model_DNN_32_0.970_0.099891.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2925 - accuracy: 0.8766 - val_loss: 0.0999 - val_accuracy: 0.9700\n","Epoch 33/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9018\n","Epoch 33: val_loss improved from 0.09989 to 0.09850, saving model to result/models/test_model_DNN_33_0.970_0.098505.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.2435 - accuracy: 0.9018 - val_loss: 0.0985 - val_accuracy: 0.9700\n","Epoch 34/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9018\n","Epoch 34: val_loss improved from 0.09850 to 0.08815, saving model to result/models/test_model_DNN_34_0.980_0.088153.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2016 - accuracy: 0.9018 - val_loss: 0.0882 - val_accuracy: 0.9800\n","Epoch 35/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.8917\n","Epoch 35: val_loss improved from 0.08815 to 0.08743, saving model to result/models/test_model_DNN_35_0.980_0.087434.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2615 - accuracy: 0.8917 - val_loss: 0.0874 - val_accuracy: 0.9800\n","Epoch 36/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.8841\n","Epoch 36: val_loss improved from 0.08743 to 0.08335, saving model to result/models/test_model_DNN_36_0.980_0.083350.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.2584 - accuracy: 0.8841 - val_loss: 0.0833 - val_accuracy: 0.9800\n","Epoch 37/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.8917\n","Epoch 37: val_loss improved from 0.08335 to 0.08178, saving model to result/models/test_model_DNN_37_0.970_0.081780.h5\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2140 - accuracy: 0.8917 - val_loss: 0.0818 - val_accuracy: 0.9700\n","Epoch 38/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.9194\n","Epoch 38: val_loss did not improve from 0.08178\n","25/25 [==============================] - 2s 90ms/step - loss: 0.2430 - accuracy: 0.9194 - val_loss: 0.0828 - val_accuracy: 0.9700\n","Epoch 39/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2061 - accuracy: 0.9093\n","Epoch 39: val_loss improved from 0.08178 to 0.07902, saving model to result/models/test_model_DNN_39_0.980_0.079024.h5\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2061 - accuracy: 0.9093 - val_loss: 0.0790 - val_accuracy: 0.9800\n","Epoch 40/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9018\n","Epoch 40: val_loss improved from 0.07902 to 0.07296, saving model to result/models/test_model_DNN_40_0.980_0.072961.h5\n","25/25 [==============================] - 2s 96ms/step - loss: 0.2140 - accuracy: 0.9018 - val_loss: 0.0730 - val_accuracy: 0.9800\n","Epoch 41/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9118\n","Epoch 41: val_loss improved from 0.07296 to 0.06696, saving model to result/models/test_model_DNN_41_0.980_0.066961.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1819 - accuracy: 0.9118 - val_loss: 0.0670 - val_accuracy: 0.9800\n","Epoch 42/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.8866\n","Epoch 42: val_loss improved from 0.06696 to 0.06222, saving model to result/models/test_model_DNN_42_0.990_0.062215.h5\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2294 - accuracy: 0.8866 - val_loss: 0.0622 - val_accuracy: 0.9900\n","Epoch 43/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.8917\n","Epoch 43: val_loss improved from 0.06222 to 0.06157, saving model to result/models/test_model_DNN_43_0.990_0.061570.h5\n","25/25 [==============================] - 2s 96ms/step - loss: 0.2277 - accuracy: 0.8917 - val_loss: 0.0616 - val_accuracy: 0.9900\n","Epoch 44/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9194\n","Epoch 44: val_loss did not improve from 0.06157\n","25/25 [==============================] - 2s 95ms/step - loss: 0.2046 - accuracy: 0.9194 - val_loss: 0.0622 - val_accuracy: 0.9900\n","Epoch 45/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9068\n","Epoch 45: val_loss did not improve from 0.06157\n","25/25 [==============================] - 2s 95ms/step - loss: 0.2049 - accuracy: 0.9068 - val_loss: 0.0631 - val_accuracy: 0.9900\n","Epoch 46/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.8967\n","Epoch 46: val_loss did not improve from 0.06157\n","25/25 [==============================] - 2s 95ms/step - loss: 0.2143 - accuracy: 0.8967 - val_loss: 0.0646 - val_accuracy: 0.9900\n","Epoch 47/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9169\n","Epoch 47: val_loss did not improve from 0.06157\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2016 - accuracy: 0.9169 - val_loss: 0.0641 - val_accuracy: 0.9900\n","Epoch 48/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.9068\n","Epoch 48: val_loss did not improve from 0.06157\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2744 - accuracy: 0.9068 - val_loss: 0.0657 - val_accuracy: 0.9900\n","Epoch 49/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9144\n","Epoch 49: val_loss improved from 0.06157 to 0.06094, saving model to result/models/test_model_DNN_49_0.990_0.060940.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2075 - accuracy: 0.9144 - val_loss: 0.0609 - val_accuracy: 0.9900\n","Epoch 50/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9093\n","Epoch 50: val_loss improved from 0.06094 to 0.06094, saving model to result/models/test_model_DNN_50_1.000_0.060938.h5\n","25/25 [==============================] - 2s 97ms/step - loss: 0.2122 - accuracy: 0.9093 - val_loss: 0.0609 - val_accuracy: 1.0000\n","Epoch 51/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9018\n","Epoch 51: val_loss improved from 0.06094 to 0.05837, saving model to result/models/test_model_DNN_51_0.990_0.058372.h5\n","25/25 [==============================] - 2s 99ms/step - loss: 0.2214 - accuracy: 0.9018 - val_loss: 0.0584 - val_accuracy: 0.9900\n","Epoch 52/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9194\n","Epoch 52: val_loss improved from 0.05837 to 0.05560, saving model to result/models/test_model_DNN_52_0.990_0.055602.h5\n","25/25 [==============================] - 2s 95ms/step - loss: 0.1794 - accuracy: 0.9194 - val_loss: 0.0556 - val_accuracy: 0.9900\n","Epoch 53/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9043\n","Epoch 53: val_loss improved from 0.05560 to 0.05163, saving model to result/models/test_model_DNN_53_1.000_0.051633.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.2027 - accuracy: 0.9043 - val_loss: 0.0516 - val_accuracy: 1.0000\n","Epoch 54/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9219\n","Epoch 54: val_loss improved from 0.05163 to 0.05025, saving model to result/models/test_model_DNN_54_0.990_0.050245.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1681 - accuracy: 0.9219 - val_loss: 0.0502 - val_accuracy: 0.9900\n","Epoch 55/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9068\n","Epoch 55: val_loss improved from 0.05025 to 0.04820, saving model to result/models/test_model_DNN_55_1.000_0.048198.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2078 - accuracy: 0.9068 - val_loss: 0.0482 - val_accuracy: 1.0000\n","Epoch 56/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9395\n","Epoch 56: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1296 - accuracy: 0.9395 - val_loss: 0.0488 - val_accuracy: 0.9800\n","Epoch 57/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.8942\n","Epoch 57: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 97ms/step - loss: 0.2425 - accuracy: 0.8942 - val_loss: 0.0554 - val_accuracy: 1.0000\n","Epoch 58/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.9320\n","Epoch 58: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1568 - accuracy: 0.9320 - val_loss: 0.0494 - val_accuracy: 0.9900\n","Epoch 59/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9043\n","Epoch 59: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 97ms/step - loss: 0.2024 - accuracy: 0.9043 - val_loss: 0.0504 - val_accuracy: 1.0000\n","Epoch 60/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.9118\n","Epoch 60: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 93ms/step - loss: 0.2206 - accuracy: 0.9118 - val_loss: 0.0521 - val_accuracy: 0.9900\n","Epoch 61/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9169\n","Epoch 61: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1748 - accuracy: 0.9169 - val_loss: 0.0489 - val_accuracy: 0.9900\n","Epoch 62/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9043\n","Epoch 62: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1822 - accuracy: 0.9043 - val_loss: 0.0545 - val_accuracy: 0.9900\n","Epoch 63/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9345\n","Epoch 63: val_loss did not improve from 0.04820\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1940 - accuracy: 0.9345 - val_loss: 0.0482 - val_accuracy: 1.0000\n","Epoch 64/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9370\n","Epoch 64: val_loss improved from 0.04820 to 0.04784, saving model to result/models/test_model_DNN_64_0.990_0.047842.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1388 - accuracy: 0.9370 - val_loss: 0.0478 - val_accuracy: 0.9900\n","Epoch 65/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9118\n","Epoch 65: val_loss did not improve from 0.04784\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1812 - accuracy: 0.9118 - val_loss: 0.0491 - val_accuracy: 0.9900\n","Epoch 66/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9144\n","Epoch 66: val_loss improved from 0.04784 to 0.04703, saving model to result/models/test_model_DNN_66_0.990_0.047025.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1995 - accuracy: 0.9144 - val_loss: 0.0470 - val_accuracy: 0.9900\n","Epoch 67/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9345\n","Epoch 67: val_loss did not improve from 0.04703\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1760 - accuracy: 0.9345 - val_loss: 0.0475 - val_accuracy: 0.9900\n","Epoch 68/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9320\n","Epoch 68: val_loss did not improve from 0.04703\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1735 - accuracy: 0.9320 - val_loss: 0.0497 - val_accuracy: 1.0000\n","Epoch 69/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9194\n","Epoch 69: val_loss improved from 0.04703 to 0.04334, saving model to result/models/test_model_DNN_69_1.000_0.043337.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1772 - accuracy: 0.9194 - val_loss: 0.0433 - val_accuracy: 1.0000\n","Epoch 70/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9395\n","Epoch 70: val_loss did not improve from 0.04334\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1317 - accuracy: 0.9395 - val_loss: 0.0436 - val_accuracy: 1.0000\n","Epoch 71/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.9270\n","Epoch 71: val_loss improved from 0.04334 to 0.04264, saving model to result/models/test_model_DNN_71_1.000_0.042639.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.2052 - accuracy: 0.9270 - val_loss: 0.0426 - val_accuracy: 1.0000\n","Epoch 72/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9471\n","Epoch 72: val_loss did not improve from 0.04264\n","25/25 [==============================] - 2s 97ms/step - loss: 0.1290 - accuracy: 0.9471 - val_loss: 0.0481 - val_accuracy: 0.9900\n","Epoch 73/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9395\n","Epoch 73: val_loss improved from 0.04264 to 0.04187, saving model to result/models/test_model_DNN_73_1.000_0.041875.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1520 - accuracy: 0.9395 - val_loss: 0.0419 - val_accuracy: 1.0000\n","Epoch 74/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9169\n","Epoch 74: val_loss improved from 0.04187 to 0.04090, saving model to result/models/test_model_DNN_74_1.000_0.040895.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1756 - accuracy: 0.9169 - val_loss: 0.0409 - val_accuracy: 1.0000\n","Epoch 75/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.9295\n","Epoch 75: val_loss did not improve from 0.04090\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1496 - accuracy: 0.9295 - val_loss: 0.0443 - val_accuracy: 1.0000\n","Epoch 76/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9118\n","Epoch 76: val_loss did not improve from 0.04090\n","25/25 [==============================] - 2s 91ms/step - loss: 0.2148 - accuracy: 0.9118 - val_loss: 0.0470 - val_accuracy: 0.9900\n","Epoch 77/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9169\n","Epoch 77: val_loss did not improve from 0.04090\n","25/25 [==============================] - 2s 92ms/step - loss: 0.2078 - accuracy: 0.9169 - val_loss: 0.0478 - val_accuracy: 0.9900\n","Epoch 78/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9144\n","Epoch 78: val_loss did not improve from 0.04090\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1775 - accuracy: 0.9144 - val_loss: 0.0465 - val_accuracy: 0.9900\n","Epoch 79/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9194\n","Epoch 79: val_loss improved from 0.04090 to 0.03993, saving model to result/models/test_model_DNN_79_1.000_0.039926.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1646 - accuracy: 0.9194 - val_loss: 0.0399 - val_accuracy: 1.0000\n","Epoch 80/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9320\n","Epoch 80: val_loss improved from 0.03993 to 0.03845, saving model to result/models/test_model_DNN_80_1.000_0.038454.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1622 - accuracy: 0.9320 - val_loss: 0.0385 - val_accuracy: 1.0000\n","Epoch 81/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9395\n","Epoch 81: val_loss improved from 0.03845 to 0.03677, saving model to result/models/test_model_DNN_81_1.000_0.036772.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1374 - accuracy: 0.9395 - val_loss: 0.0368 - val_accuracy: 1.0000\n","Epoch 82/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9194\n","Epoch 82: val_loss did not improve from 0.03677\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1879 - accuracy: 0.9194 - val_loss: 0.0386 - val_accuracy: 1.0000\n","Epoch 83/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9244\n","Epoch 83: val_loss did not improve from 0.03677\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1749 - accuracy: 0.9244 - val_loss: 0.0399 - val_accuracy: 1.0000\n","Epoch 84/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9370\n","Epoch 84: val_loss improved from 0.03677 to 0.03546, saving model to result/models/test_model_DNN_84_1.000_0.035461.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1373 - accuracy: 0.9370 - val_loss: 0.0355 - val_accuracy: 1.0000\n","Epoch 85/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9345\n","Epoch 85: val_loss did not improve from 0.03546\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1277 - accuracy: 0.9345 - val_loss: 0.0432 - val_accuracy: 0.9900\n","Epoch 86/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9446\n","Epoch 86: val_loss improved from 0.03546 to 0.03271, saving model to result/models/test_model_DNN_86_1.000_0.032713.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1162 - accuracy: 0.9446 - val_loss: 0.0327 - val_accuracy: 1.0000\n","Epoch 87/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9471\n","Epoch 87: val_loss did not improve from 0.03271\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1345 - accuracy: 0.9471 - val_loss: 0.0338 - val_accuracy: 1.0000\n","Epoch 88/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9395\n","Epoch 88: val_loss did not improve from 0.03271\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1395 - accuracy: 0.9395 - val_loss: 0.0331 - val_accuracy: 1.0000\n","Epoch 89/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9219\n","Epoch 89: val_loss improved from 0.03271 to 0.03224, saving model to result/models/test_model_DNN_89_1.000_0.032236.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1724 - accuracy: 0.9219 - val_loss: 0.0322 - val_accuracy: 1.0000\n","Epoch 90/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9421\n","Epoch 90: val_loss did not improve from 0.03224\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1604 - accuracy: 0.9421 - val_loss: 0.0331 - val_accuracy: 1.0000\n","Epoch 91/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9219\n","Epoch 91: val_loss did not improve from 0.03224\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1626 - accuracy: 0.9219 - val_loss: 0.0346 - val_accuracy: 1.0000\n","Epoch 92/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9446\n","Epoch 92: val_loss improved from 0.03224 to 0.03186, saving model to result/models/test_model_DNN_92_1.000_0.031857.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1335 - accuracy: 0.9446 - val_loss: 0.0319 - val_accuracy: 1.0000\n","Epoch 93/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9244\n","Epoch 93: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1490 - accuracy: 0.9244 - val_loss: 0.0542 - val_accuracy: 0.9700\n","Epoch 94/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9446\n","Epoch 94: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1492 - accuracy: 0.9446 - val_loss: 0.0358 - val_accuracy: 0.9900\n","Epoch 95/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9421\n","Epoch 95: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1242 - accuracy: 0.9421 - val_loss: 0.0435 - val_accuracy: 0.9900\n","Epoch 96/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.9295\n","Epoch 96: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1261 - accuracy: 0.9295 - val_loss: 0.0482 - val_accuracy: 0.9800\n","Epoch 97/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9244\n","Epoch 97: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1897 - accuracy: 0.9244 - val_loss: 0.0330 - val_accuracy: 1.0000\n","Epoch 98/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9496\n","Epoch 98: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1176 - accuracy: 0.9496 - val_loss: 0.0354 - val_accuracy: 0.9900\n","Epoch 99/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9345\n","Epoch 99: val_loss did not improve from 0.03186\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1601 - accuracy: 0.9345 - val_loss: 0.0382 - val_accuracy: 0.9900\n","Epoch 100/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9471\n","Epoch 100: val_loss improved from 0.03186 to 0.03117, saving model to result/models/test_model_DNN_100_1.000_0.031173.h5\n","25/25 [==============================] - 2s 98ms/step - loss: 0.1250 - accuracy: 0.9471 - val_loss: 0.0312 - val_accuracy: 1.0000\n","Epoch 101/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9295\n","Epoch 101: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1293 - accuracy: 0.9295 - val_loss: 0.0340 - val_accuracy: 0.9900\n","Epoch 102/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9194\n","Epoch 102: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 97ms/step - loss: 0.2017 - accuracy: 0.9194 - val_loss: 0.0348 - val_accuracy: 1.0000\n","Epoch 103/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9446\n","Epoch 103: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 97ms/step - loss: 0.1346 - accuracy: 0.9446 - val_loss: 0.0360 - val_accuracy: 1.0000\n","Epoch 104/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9068\n","Epoch 104: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 95ms/step - loss: 0.1963 - accuracy: 0.9068 - val_loss: 0.0405 - val_accuracy: 1.0000\n","Epoch 105/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9345\n","Epoch 105: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1353 - accuracy: 0.9345 - val_loss: 0.0413 - val_accuracy: 1.0000\n","Epoch 106/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9471\n","Epoch 106: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1143 - accuracy: 0.9471 - val_loss: 0.0438 - val_accuracy: 1.0000\n","Epoch 107/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9622\n","Epoch 107: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1164 - accuracy: 0.9622 - val_loss: 0.0539 - val_accuracy: 0.9800\n","Epoch 108/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9395\n","Epoch 108: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1411 - accuracy: 0.9395 - val_loss: 0.0439 - val_accuracy: 0.9900\n","Epoch 109/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.9370\n","Epoch 109: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1549 - accuracy: 0.9370 - val_loss: 0.0578 - val_accuracy: 0.9600\n","Epoch 110/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9395\n","Epoch 110: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1541 - accuracy: 0.9395 - val_loss: 0.0485 - val_accuracy: 0.9800\n","Epoch 111/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9647\n","Epoch 111: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1067 - accuracy: 0.9647 - val_loss: 0.0584 - val_accuracy: 0.9500\n","Epoch 112/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9547\n","Epoch 112: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1125 - accuracy: 0.9547 - val_loss: 0.0444 - val_accuracy: 0.9900\n","Epoch 113/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9370\n","Epoch 113: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1457 - accuracy: 0.9370 - val_loss: 0.0366 - val_accuracy: 1.0000\n","Epoch 114/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9345\n","Epoch 114: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1428 - accuracy: 0.9345 - val_loss: 0.0689 - val_accuracy: 0.9500\n","Epoch 115/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9521\n","Epoch 115: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1029 - accuracy: 0.9521 - val_loss: 0.0508 - val_accuracy: 0.9800\n","Epoch 116/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9421\n","Epoch 116: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1303 - accuracy: 0.9421 - val_loss: 0.0412 - val_accuracy: 0.9900\n","Epoch 117/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9547\n","Epoch 117: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1028 - accuracy: 0.9547 - val_loss: 0.0643 - val_accuracy: 0.9500\n","Epoch 118/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9547\n","Epoch 118: val_loss did not improve from 0.03117\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1173 - accuracy: 0.9547 - val_loss: 0.0433 - val_accuracy: 0.9800\n","Epoch 119/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9295\n","Epoch 119: val_loss improved from 0.03117 to 0.03112, saving model to result/models/test_model_DNN_119_1.000_0.031118.h5\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1717 - accuracy: 0.9295 - val_loss: 0.0311 - val_accuracy: 1.0000\n","Epoch 120/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9521\n","Epoch 120: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1123 - accuracy: 0.9521 - val_loss: 0.0357 - val_accuracy: 1.0000\n","Epoch 121/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9471\n","Epoch 121: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1161 - accuracy: 0.9471 - val_loss: 0.0511 - val_accuracy: 0.9600\n","Epoch 122/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9673\n","Epoch 122: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0917 - accuracy: 0.9673 - val_loss: 0.0375 - val_accuracy: 1.0000\n","Epoch 123/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9597\n","Epoch 123: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0951 - accuracy: 0.9597 - val_loss: 0.0327 - val_accuracy: 1.0000\n","Epoch 124/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9572\n","Epoch 124: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0998 - accuracy: 0.9572 - val_loss: 0.0476 - val_accuracy: 0.9800\n","Epoch 125/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9673\n","Epoch 125: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0805 - accuracy: 0.9673 - val_loss: 0.0664 - val_accuracy: 0.9500\n","Epoch 126/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9446\n","Epoch 126: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1338 - accuracy: 0.9446 - val_loss: 0.0355 - val_accuracy: 0.9900\n","Epoch 127/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9673\n","Epoch 127: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0943 - accuracy: 0.9673 - val_loss: 0.0375 - val_accuracy: 0.9800\n","Epoch 128/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9673\n","Epoch 128: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0796 - accuracy: 0.9673 - val_loss: 0.0350 - val_accuracy: 0.9800\n","Epoch 129/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9572\n","Epoch 129: val_loss did not improve from 0.03112\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0919 - accuracy: 0.9572 - val_loss: 0.0393 - val_accuracy: 0.9800\n","Epoch 130/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9320\n","Epoch 130: val_loss improved from 0.03112 to 0.02940, saving model to result/models/test_model_DNN_130_1.000_0.029400.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.1362 - accuracy: 0.9320 - val_loss: 0.0294 - val_accuracy: 1.0000\n","Epoch 131/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9597\n","Epoch 131: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 92ms/step - loss: 0.0765 - accuracy: 0.9597 - val_loss: 0.0428 - val_accuracy: 0.9800\n","Epoch 132/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9723\n","Epoch 132: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0821 - accuracy: 0.9723 - val_loss: 0.0414 - val_accuracy: 0.9800\n","Epoch 133/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9421\n","Epoch 133: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1190 - accuracy: 0.9421 - val_loss: 0.0412 - val_accuracy: 0.9900\n","Epoch 134/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9521\n","Epoch 134: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1123 - accuracy: 0.9521 - val_loss: 0.0488 - val_accuracy: 0.9700\n","Epoch 135/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9673\n","Epoch 135: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0805 - accuracy: 0.9673 - val_loss: 0.0344 - val_accuracy: 0.9900\n","Epoch 136/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9496\n","Epoch 136: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1127 - accuracy: 0.9496 - val_loss: 0.0399 - val_accuracy: 0.9800\n","Epoch 137/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9647\n","Epoch 137: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0802 - accuracy: 0.9647 - val_loss: 0.0433 - val_accuracy: 0.9700\n","Epoch 138/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9521\n","Epoch 138: val_loss did not improve from 0.02940\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1144 - accuracy: 0.9521 - val_loss: 0.0343 - val_accuracy: 0.9900\n","Epoch 139/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9597\n","Epoch 139: val_loss improved from 0.02940 to 0.02107, saving model to result/models/test_model_DNN_139_1.000_0.021066.h5\n","25/25 [==============================] - 2s 94ms/step - loss: 0.0945 - accuracy: 0.9597 - val_loss: 0.0211 - val_accuracy: 1.0000\n","Epoch 140/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9798\n","Epoch 140: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 93ms/step - loss: 0.0614 - accuracy: 0.9798 - val_loss: 0.0288 - val_accuracy: 1.0000\n","Epoch 141/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9547\n","Epoch 141: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1137 - accuracy: 0.9547 - val_loss: 0.0298 - val_accuracy: 0.9900\n","Epoch 142/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9521\n","Epoch 142: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1140 - accuracy: 0.9521 - val_loss: 0.0312 - val_accuracy: 0.9900\n","Epoch 143/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9521\n","Epoch 143: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 92ms/step - loss: 0.1006 - accuracy: 0.9521 - val_loss: 0.0508 - val_accuracy: 0.9700\n","Epoch 144/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9547\n","Epoch 144: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 93ms/step - loss: 0.1255 - accuracy: 0.9547 - val_loss: 0.0356 - val_accuracy: 0.9900\n","Epoch 145/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9597\n","Epoch 145: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1022 - accuracy: 0.9597 - val_loss: 0.0341 - val_accuracy: 0.9800\n","Epoch 146/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9723\n","Epoch 146: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 96ms/step - loss: 0.0607 - accuracy: 0.9723 - val_loss: 0.0495 - val_accuracy: 0.9700\n","Epoch 147/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9572\n","Epoch 147: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1103 - accuracy: 0.9572 - val_loss: 0.0589 - val_accuracy: 0.9500\n","Epoch 148/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9446\n","Epoch 148: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 96ms/step - loss: 0.1231 - accuracy: 0.9446 - val_loss: 0.0343 - val_accuracy: 1.0000\n","Epoch 149/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9597\n","Epoch 149: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 97ms/step - loss: 0.0920 - accuracy: 0.9597 - val_loss: 0.0389 - val_accuracy: 0.9900\n","Epoch 150/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9647\n","Epoch 150: val_loss did not improve from 0.02107\n","25/25 [==============================] - 2s 97ms/step - loss: 0.0823 - accuracy: 0.9647 - val_loss: 0.0486 - val_accuracy: 0.9700\n"]}],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9956,"status":"ok","timestamp":1660550867701,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"NOwY60dJhKhH","outputId":"51be4edf-67de-468b-b9d9-df969d86b513"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start testing process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] There are 125 total samples in the test set. 7 vulnerable samples. \n","2022-08-15 08:07:42.897902: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Model: \"GRU_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," cu_dnngru (CuDNNGRU)        (None, 1000, 128)         88320     \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," cu_dnngru_1 (CuDNNGRU)      (None, 1000, 128)         99072     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 770,861\n","Trainable params: 197,761\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","8/8 [==============================] - 3s 66ms/step\n","[INFO] GRU classification result: \n","\n","[INFO] Total accuracy: 0.968\n","[INFO] ----------------------------------------------------\n","[INFO] The confusion matrix: \n","\n","[[117   1]\n"," [  3   4]]\n","\n","\n","                precision    recall  f1-score   support\n","\n","Non-vulnerable       0.97      0.99      0.98       118\n","    Vulnerable       0.80      0.57      0.67         7\n","\n","      accuracy                           0.97       125\n","     macro avg       0.89      0.78      0.82       125\n","  weighted avg       0.97      0.97      0.97       125\n","\n"]}],"source":["!python main.py --config config/config.yaml --test --trained_model result/models/test_model_DNN_139_1.000_0.021066.h5 --data_dir Data/LibPNG --output_dir result/finalResult"]},{"cell_type":"markdown","metadata":{"id":"pDPfatP_hPsZ"},"source":["##BiGRU for LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"w8LZuTaChW8N","outputId":"855ce696-8ab4-4c10-9018-9286d3a1eade"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start training process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] -------------------------------------------------------\n","[INFO] Data processing completed!\n","[INFO] There are 397 total samples in the tr*aining set. 29 vulnerable samples. \n","[INFO] There are 100 total samples in the validation set. 9 vulnerable samples. \n","[INFO] -------------------------------------------------------\n","[INFO] Loading trained Word2vec model. \n","[INFO] The trained word2vec model: \n","<_io.TextIOWrapper name='result/w2v_model_CBOW_dict.txt' mode='r' encoding='UTF-8'>\n","[INFO] Found 1887 word vectors.\n","[0.53940217 6.84482759]\n","[INFO] -------------------------------------------------------\n","[INFO] Loading the BiGRU model.\n","2022-08-15 08:08:05.828157: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] Model structure loaded.\n","Model: \"BiGRU_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 1000, 128)        63744     \n"," l)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 1000, 128)        74496     \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 721,709\n","Trainable params: 148,609\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","Epoch 1/150\n","25/25 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.3854\n","Epoch 1: val_loss improved from inf to 0.70716, saving model to result/models/BiGRU_01_0.490_0.707164.h5\n","25/25 [==============================] - 7s 160ms/step - loss: 0.7739 - accuracy: 0.3854 - val_loss: 0.7072 - val_accuracy: 0.4900\n","Epoch 2/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6784 - accuracy: 0.4055\n","Epoch 2: val_loss improved from 0.70716 to 0.62411, saving model to result/models/BiGRU_02_0.760_0.624115.h5\n","25/25 [==============================] - 3s 122ms/step - loss: 0.6784 - accuracy: 0.4055 - val_loss: 0.6241 - val_accuracy: 0.7600\n","Epoch 3/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.5819\n","Epoch 3: val_loss improved from 0.62411 to 0.61959, saving model to result/models/BiGRU_03_0.720_0.619592.h5\n","25/25 [==============================] - 3s 123ms/step - loss: 0.6453 - accuracy: 0.5819 - val_loss: 0.6196 - val_accuracy: 0.7200\n","Epoch 4/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.5819\n","Epoch 4: val_loss improved from 0.61959 to 0.53093, saving model to result/models/BiGRU_04_0.880_0.530929.h5\n","25/25 [==============================] - 3s 123ms/step - loss: 0.6357 - accuracy: 0.5819 - val_loss: 0.5309 - val_accuracy: 0.8800\n","Epoch 5/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.6196\n","Epoch 5: val_loss improved from 0.53093 to 0.50886, saving model to result/models/BiGRU_05_0.870_0.508857.h5\n","25/25 [==============================] - 3s 122ms/step - loss: 0.6037 - accuracy: 0.6196 - val_loss: 0.5089 - val_accuracy: 0.8700\n","Epoch 6/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6121\n","Epoch 6: val_loss improved from 0.50886 to 0.47215, saving model to result/models/BiGRU_06_0.890_0.472148.h5\n","25/25 [==============================] - 3s 123ms/step - loss: 0.6131 - accuracy: 0.6121 - val_loss: 0.4721 - val_accuracy: 0.8900\n","Epoch 7/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.5592\n","Epoch 7: val_loss did not improve from 0.47215\n","25/25 [==============================] - 3s 130ms/step - loss: 0.6598 - accuracy: 0.5592 - val_loss: 0.4829 - val_accuracy: 0.9200\n","Epoch 8/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5407 - accuracy: 0.6877\n","Epoch 8: val_loss improved from 0.47215 to 0.40550, saving model to result/models/BiGRU_08_0.920_0.405500.h5\n","25/25 [==============================] - 4s 148ms/step - loss: 0.5407 - accuracy: 0.6877 - val_loss: 0.4055 - val_accuracy: 0.9200\n","Epoch 9/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.7078\n","Epoch 9: val_loss improved from 0.40550 to 0.36440, saving model to result/models/BiGRU_09_0.910_0.364402.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.5480 - accuracy: 0.7078 - val_loss: 0.3644 - val_accuracy: 0.9100\n","Epoch 10/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7305\n","Epoch 10: val_loss improved from 0.36440 to 0.33387, saving model to result/models/BiGRU_10_0.900_0.333871.h5\n","25/25 [==============================] - 3s 132ms/step - loss: 0.5379 - accuracy: 0.7305 - val_loss: 0.3339 - val_accuracy: 0.9000\n","Epoch 11/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5406 - accuracy: 0.6877\n","Epoch 11: val_loss improved from 0.33387 to 0.30567, saving model to result/models/BiGRU_11_0.900_0.305672.h5\n","25/25 [==============================] - 3s 130ms/step - loss: 0.5406 - accuracy: 0.6877 - val_loss: 0.3057 - val_accuracy: 0.9000\n","Epoch 12/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.7305\n","Epoch 12: val_loss improved from 0.30567 to 0.30167, saving model to result/models/BiGRU_12_0.950_0.301665.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.5244 - accuracy: 0.7305 - val_loss: 0.3017 - val_accuracy: 0.9500\n","Epoch 13/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7582\n","Epoch 13: val_loss improved from 0.30167 to 0.26618, saving model to result/models/BiGRU_13_0.920_0.266180.h5\n","25/25 [==============================] - 3s 119ms/step - loss: 0.5093 - accuracy: 0.7582 - val_loss: 0.2662 - val_accuracy: 0.9200\n","Epoch 14/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.7758\n","Epoch 14: val_loss improved from 0.26618 to 0.23042, saving model to result/models/BiGRU_14_0.910_0.230415.h5\n","25/25 [==============================] - 3s 119ms/step - loss: 0.4364 - accuracy: 0.7758 - val_loss: 0.2304 - val_accuracy: 0.9100\n","Epoch 15/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8010\n","Epoch 15: val_loss improved from 0.23042 to 0.21098, saving model to result/models/BiGRU_15_0.920_0.210983.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.4407 - accuracy: 0.8010 - val_loss: 0.2110 - val_accuracy: 0.9200\n","Epoch 16/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.8086\n","Epoch 16: val_loss improved from 0.21098 to 0.19160, saving model to result/models/BiGRU_16_0.920_0.191596.h5\n","25/25 [==============================] - 3s 129ms/step - loss: 0.3800 - accuracy: 0.8086 - val_loss: 0.1916 - val_accuracy: 0.9200\n","Epoch 17/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8086\n","Epoch 17: val_loss improved from 0.19160 to 0.18019, saving model to result/models/BiGRU_17_0.940_0.180187.h5\n","25/25 [==============================] - 3s 119ms/step - loss: 0.3855 - accuracy: 0.8086 - val_loss: 0.1802 - val_accuracy: 0.9400\n","Epoch 18/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.8212\n","Epoch 18: val_loss improved from 0.18019 to 0.16617, saving model to result/models/BiGRU_18_0.940_0.166173.h5\n","25/25 [==============================] - 3s 119ms/step - loss: 0.3727 - accuracy: 0.8212 - val_loss: 0.1662 - val_accuracy: 0.9400\n","Epoch 19/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8338\n","Epoch 19: val_loss improved from 0.16617 to 0.15218, saving model to result/models/BiGRU_19_0.940_0.152178.h5\n","25/25 [==============================] - 3s 129ms/step - loss: 0.3413 - accuracy: 0.8338 - val_loss: 0.1522 - val_accuracy: 0.9400\n","Epoch 20/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8212\n","Epoch 20: val_loss improved from 0.15218 to 0.14048, saving model to result/models/BiGRU_20_0.930_0.140481.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.3572 - accuracy: 0.8212 - val_loss: 0.1405 - val_accuracy: 0.9300\n","Epoch 21/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.8287\n","Epoch 21: val_loss improved from 0.14048 to 0.12994, saving model to result/models/BiGRU_21_0.960_0.129935.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.3450 - accuracy: 0.8287 - val_loss: 0.1299 - val_accuracy: 0.9600\n","Epoch 22/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2980 - accuracy: 0.8463\n","Epoch 22: val_loss improved from 0.12994 to 0.12556, saving model to result/models/BiGRU_22_0.950_0.125557.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.2980 - accuracy: 0.8463 - val_loss: 0.1256 - val_accuracy: 0.9500\n","Epoch 23/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8388\n","Epoch 23: val_loss improved from 0.12556 to 0.11773, saving model to result/models/BiGRU_23_0.970_0.117730.h5\n","25/25 [==============================] - 3s 119ms/step - loss: 0.3481 - accuracy: 0.8388 - val_loss: 0.1177 - val_accuracy: 0.9700\n","Epoch 24/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8363\n","Epoch 24: val_loss did not improve from 0.11773\n","25/25 [==============================] - 3s 127ms/step - loss: 0.3090 - accuracy: 0.8363 - val_loss: 0.1277 - val_accuracy: 0.9200\n","Epoch 25/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8363\n","Epoch 25: val_loss improved from 0.11773 to 0.11514, saving model to result/models/BiGRU_25_0.940_0.115145.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.3577 - accuracy: 0.8363 - val_loss: 0.1151 - val_accuracy: 0.9400\n","Epoch 26/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.8791\n","Epoch 26: val_loss did not improve from 0.11514\n","25/25 [==============================] - 3s 118ms/step - loss: 0.2414 - accuracy: 0.8791 - val_loss: 0.1299 - val_accuracy: 0.9100\n","Epoch 27/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.8992\n","Epoch 27: val_loss improved from 0.11514 to 0.10199, saving model to result/models/BiGRU_27_0.960_0.101992.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.2408 - accuracy: 0.8992 - val_loss: 0.1020 - val_accuracy: 0.9600\n","Epoch 28/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.8816\n","Epoch 28: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 118ms/step - loss: 0.2875 - accuracy: 0.8816 - val_loss: 0.1109 - val_accuracy: 0.9400\n","Epoch 29/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.8741\n","Epoch 29: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2793 - accuracy: 0.8741 - val_loss: 0.1079 - val_accuracy: 0.9400\n","Epoch 30/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9093\n","Epoch 30: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 118ms/step - loss: 0.2197 - accuracy: 0.9093 - val_loss: 0.1270 - val_accuracy: 0.9100\n","Epoch 31/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.8841\n","Epoch 31: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 128ms/step - loss: 0.2743 - accuracy: 0.8841 - val_loss: 0.1121 - val_accuracy: 0.9300\n","Epoch 32/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9144\n","Epoch 32: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 118ms/step - loss: 0.1995 - accuracy: 0.9144 - val_loss: 0.1160 - val_accuracy: 0.9300\n","Epoch 33/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.9169\n","Epoch 33: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1926 - accuracy: 0.9169 - val_loss: 0.1115 - val_accuracy: 0.9300\n","Epoch 34/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.8791\n","Epoch 34: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 129ms/step - loss: 0.2580 - accuracy: 0.8791 - val_loss: 0.1301 - val_accuracy: 0.9100\n","Epoch 35/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9345\n","Epoch 35: val_loss did not improve from 0.10199\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1625 - accuracy: 0.9345 - val_loss: 0.1144 - val_accuracy: 0.9300\n","Epoch 36/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9118\n","Epoch 36: val_loss improved from 0.10199 to 0.09234, saving model to result/models/BiGRU_36_0.950_0.092339.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.2102 - accuracy: 0.9118 - val_loss: 0.0923 - val_accuracy: 0.9500\n","Epoch 37/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9018\n","Epoch 37: val_loss improved from 0.09234 to 0.09141, saving model to result/models/BiGRU_37_0.950_0.091412.h5\n","25/25 [==============================] - 3s 129ms/step - loss: 0.2292 - accuracy: 0.9018 - val_loss: 0.0914 - val_accuracy: 0.9500\n","Epoch 38/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.8791\n","Epoch 38: val_loss improved from 0.09141 to 0.08661, saving model to result/models/BiGRU_38_0.960_0.086607.h5\n","25/25 [==============================] - 3s 130ms/step - loss: 0.2771 - accuracy: 0.8791 - val_loss: 0.0866 - val_accuracy: 0.9600\n","Epoch 39/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.8942\n","Epoch 39: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 118ms/step - loss: 0.2368 - accuracy: 0.8942 - val_loss: 0.0918 - val_accuracy: 0.9500\n","Epoch 40/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9068\n","Epoch 40: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1991 - accuracy: 0.9068 - val_loss: 0.1079 - val_accuracy: 0.9300\n","Epoch 41/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.9219\n","Epoch 41: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1944 - accuracy: 0.9219 - val_loss: 0.1178 - val_accuracy: 0.9100\n","Epoch 42/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.9219\n","Epoch 42: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 127ms/step - loss: 0.2123 - accuracy: 0.9219 - val_loss: 0.0973 - val_accuracy: 0.9400\n","Epoch 43/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9144\n","Epoch 43: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 117ms/step - loss: 0.1836 - accuracy: 0.9144 - val_loss: 0.0966 - val_accuracy: 0.9400\n","Epoch 44/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9244\n","Epoch 44: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 118ms/step - loss: 0.1806 - accuracy: 0.9244 - val_loss: 0.0967 - val_accuracy: 0.9400\n","Epoch 45/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9068\n","Epoch 45: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2231 - accuracy: 0.9068 - val_loss: 0.1127 - val_accuracy: 0.9300\n","Epoch 46/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9244\n","Epoch 46: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 130ms/step - loss: 0.1672 - accuracy: 0.9244 - val_loss: 0.1196 - val_accuracy: 0.9100\n","Epoch 47/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9118\n","Epoch 47: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2049 - accuracy: 0.9118 - val_loss: 0.1187 - val_accuracy: 0.9200\n","Epoch 48/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9270\n","Epoch 48: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1862 - accuracy: 0.9270 - val_loss: 0.1348 - val_accuracy: 0.9100\n","Epoch 49/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.8766\n","Epoch 49: val_loss did not improve from 0.08661\n","25/25 [==============================] - 4s 171ms/step - loss: 0.2751 - accuracy: 0.8766 - val_loss: 0.1010 - val_accuracy: 0.9300\n","Epoch 50/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9043\n","Epoch 50: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2136 - accuracy: 0.9043 - val_loss: 0.1077 - val_accuracy: 0.9300\n","Epoch 51/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.8866\n","Epoch 51: val_loss did not improve from 0.08661\n","25/25 [==============================] - 3s 131ms/step - loss: 0.2506 - accuracy: 0.8866 - val_loss: 0.1036 - val_accuracy: 0.9300\n","Epoch 52/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.8866\n","Epoch 52: val_loss improved from 0.08661 to 0.07178, saving model to result/models/BiGRU_52_0.970_0.071779.h5\n","25/25 [==============================] - 3s 120ms/step - loss: 0.2468 - accuracy: 0.8866 - val_loss: 0.0718 - val_accuracy: 0.9700\n","Epoch 53/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.9295\n","Epoch 53: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 118ms/step - loss: 0.1404 - accuracy: 0.9295 - val_loss: 0.1206 - val_accuracy: 0.9200\n","Epoch 54/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9270\n","Epoch 54: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2271 - accuracy: 0.9270 - val_loss: 0.1127 - val_accuracy: 0.9300\n","Epoch 55/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9320\n","Epoch 55: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1808 - accuracy: 0.9320 - val_loss: 0.1049 - val_accuracy: 0.9300\n","Epoch 56/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9270\n","Epoch 56: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 118ms/step - loss: 0.1592 - accuracy: 0.9270 - val_loss: 0.0919 - val_accuracy: 0.9400\n","Epoch 57/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9144\n","Epoch 57: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2221 - accuracy: 0.9144 - val_loss: 0.1233 - val_accuracy: 0.9200\n","Epoch 58/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9118\n","Epoch 58: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2030 - accuracy: 0.9118 - val_loss: 0.1004 - val_accuracy: 0.9400\n","Epoch 59/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9219\n","Epoch 59: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 120ms/step - loss: 0.1689 - accuracy: 0.9219 - val_loss: 0.1056 - val_accuracy: 0.9400\n","Epoch 60/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9219\n","Epoch 60: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 130ms/step - loss: 0.1821 - accuracy: 0.9219 - val_loss: 0.1120 - val_accuracy: 0.9300\n","Epoch 61/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9270\n","Epoch 61: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 130ms/step - loss: 0.1805 - accuracy: 0.9270 - val_loss: 0.1205 - val_accuracy: 0.9200\n","Epoch 62/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9219\n","Epoch 62: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 120ms/step - loss: 0.1708 - accuracy: 0.9219 - val_loss: 0.1172 - val_accuracy: 0.9200\n","Epoch 63/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.8967\n","Epoch 63: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 118ms/step - loss: 0.2226 - accuracy: 0.8967 - val_loss: 0.0981 - val_accuracy: 0.9400\n","Epoch 64/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9496\n","Epoch 64: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1303 - accuracy: 0.9496 - val_loss: 0.1025 - val_accuracy: 0.9300\n","Epoch 65/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9043\n","Epoch 65: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1776 - accuracy: 0.9043 - val_loss: 0.0954 - val_accuracy: 0.9500\n","Epoch 66/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9446\n","Epoch 66: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 128ms/step - loss: 0.1414 - accuracy: 0.9446 - val_loss: 0.1165 - val_accuracy: 0.9300\n","Epoch 67/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9219\n","Epoch 67: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1714 - accuracy: 0.9219 - val_loss: 0.1317 - val_accuracy: 0.9200\n","Epoch 68/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9370\n","Epoch 68: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 118ms/step - loss: 0.1760 - accuracy: 0.9370 - val_loss: 0.1238 - val_accuracy: 0.9200\n","Epoch 69/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9320\n","Epoch 69: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1778 - accuracy: 0.9320 - val_loss: 0.1375 - val_accuracy: 0.9200\n","Epoch 70/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9270\n","Epoch 70: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1749 - accuracy: 0.9270 - val_loss: 0.1353 - val_accuracy: 0.9200\n","Epoch 71/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9421\n","Epoch 71: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 121ms/step - loss: 0.1160 - accuracy: 0.9421 - val_loss: 0.1741 - val_accuracy: 0.9100\n","Epoch 72/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9521\n","Epoch 72: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1390 - accuracy: 0.9521 - val_loss: 0.1652 - val_accuracy: 0.9100\n","Epoch 73/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9043\n","Epoch 73: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 121ms/step - loss: 0.2499 - accuracy: 0.9043 - val_loss: 0.1115 - val_accuracy: 0.9300\n","Epoch 74/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9219\n","Epoch 74: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 120ms/step - loss: 0.1787 - accuracy: 0.9219 - val_loss: 0.1049 - val_accuracy: 0.9300\n","Epoch 75/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9093\n","Epoch 75: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 120ms/step - loss: 0.2140 - accuracy: 0.9093 - val_loss: 0.1806 - val_accuracy: 0.9100\n","Epoch 76/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9345\n","Epoch 76: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.2024 - accuracy: 0.9345 - val_loss: 0.1145 - val_accuracy: 0.9300\n","Epoch 77/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9395\n","Epoch 77: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1401 - accuracy: 0.9395 - val_loss: 0.1244 - val_accuracy: 0.9200\n","Epoch 78/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9320\n","Epoch 78: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1562 - accuracy: 0.9320 - val_loss: 0.1371 - val_accuracy: 0.9200\n","Epoch 79/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9345\n","Epoch 79: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 118ms/step - loss: 0.1468 - accuracy: 0.9345 - val_loss: 0.1653 - val_accuracy: 0.9100\n","Epoch 80/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9471\n","Epoch 80: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 117ms/step - loss: 0.1291 - accuracy: 0.9471 - val_loss: 0.1518 - val_accuracy: 0.9100\n","Epoch 81/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9521\n","Epoch 81: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1105 - accuracy: 0.9521 - val_loss: 0.1375 - val_accuracy: 0.9200\n","Epoch 82/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9345\n","Epoch 82: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 120ms/step - loss: 0.1505 - accuracy: 0.9345 - val_loss: 0.1515 - val_accuracy: 0.9100\n","Epoch 83/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.9471\n","Epoch 83: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1380 - accuracy: 0.9471 - val_loss: 0.1291 - val_accuracy: 0.9200\n","Epoch 84/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9446\n","Epoch 84: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 119ms/step - loss: 0.1315 - accuracy: 0.9446 - val_loss: 0.1218 - val_accuracy: 0.9300\n","Epoch 85/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9471\n","Epoch 85: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 129ms/step - loss: 0.1181 - accuracy: 0.9471 - val_loss: 0.1418 - val_accuracy: 0.9200\n","Epoch 86/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9547\n","Epoch 86: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 128ms/step - loss: 0.1035 - accuracy: 0.9547 - val_loss: 0.1594 - val_accuracy: 0.9200\n","Epoch 87/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9295\n","Epoch 87: val_loss did not improve from 0.07178\n","25/25 [==============================] - 3s 120ms/step - loss: 0.1813 - accuracy: 0.9295 - val_loss: 0.1566 - val_accuracy: 0.9200\n","Epoch 87: early stopping\n"]}],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0nw4jeyhXRq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660553885477,"user_tz":-480,"elapsed":20720,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"}},"outputId":"2813d82f-c955-4fb4-dac7-ce4142ced1cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Start testing process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] There are 125 total samples in the test set. 7 vulnerable samples. \n","2022-08-15 08:57:56.777715: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Model: \"BiGRU_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 1000, 128)        63744     \n"," l)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 1000, 128)        74496     \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 721,709\n","Trainable params: 148,609\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","8/8 [==============================] - 6s 93ms/step\n","[INFO] BiGRU classification result: \n","\n","[INFO] Total accuracy: 0.952\n","[INFO] ----------------------------------------------------\n","[INFO] The confusion matrix: \n","\n","[[118   0]\n"," [  6   1]]\n","\n","\n","                precision    recall  f1-score   support\n","\n","Non-vulnerable       0.95      1.00      0.98       118\n","    Vulnerable       1.00      0.14      0.25         7\n","\n","      accuracy                           0.95       125\n","     macro avg       0.98      0.57      0.61       125\n","  weighted avg       0.95      0.95      0.93       125\n","\n"]}],"source":["!python main.py --config config/config.yaml --test --trained_model result/models/BiGRU_52_0.970_0.071779.h5 --data_dir Data/LibPNG --output_dir result/finalResult"]},{"cell_type":"markdown","metadata":{"id":"wO1KQfSwhcln"},"source":["##BiLSTM for LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5d-6Fugqhhm_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660554608151,"user_tz":-480,"elapsed":571333,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"}},"outputId":"a0fe909d-c489-4765-d5be-825ff5886f66"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Start training process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] -------------------------------------------------------\n","[INFO] Data processing completed!\n","[INFO] There are 397 total samples in the tr*aining set. 29 vulnerable samples. \n","[INFO] There are 100 total samples in the validation set. 9 vulnerable samples. \n","[INFO] -------------------------------------------------------\n","[INFO] Loading trained Word2vec model. \n","[INFO] The trained word2vec model: \n","<_io.TextIOWrapper name='result/w2v_model_CBOW_dict.txt' mode='r' encoding='UTF-8'>\n","[INFO] Found 1887 word vectors.\n","[0.53940217 6.84482759]\n","[INFO] -------------------------------------------------------\n","[INFO] Loading the BiLSTM model.\n","2022-08-15 09:00:42.108380: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] Model structure loaded.\n","Model: \"BiLSTM_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 1000, 128)        84992     \n"," l)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 1000, 128)        99328     \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 767,789\n","Trainable params: 194,689\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","Epoch 1/150\n","25/25 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.4811\n","Epoch 1: val_loss improved from inf to 0.72013, saving model to result/models/BiLSTM_01_0.140_0.720132.h5\n","25/25 [==============================] - 10s 229ms/step - loss: 0.7059 - accuracy: 0.4811 - val_loss: 0.7201 - val_accuracy: 0.1400\n","Epoch 2/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.4660\n","Epoch 2: val_loss improved from 0.72013 to 0.70702, saving model to result/models/BiLSTM_02_0.360_0.707023.h5\n","25/25 [==============================] - 4s 145ms/step - loss: 0.6762 - accuracy: 0.4660 - val_loss: 0.7070 - val_accuracy: 0.3600\n","Epoch 3/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.4332\n","Epoch 3: val_loss improved from 0.70702 to 0.69894, saving model to result/models/BiLSTM_03_0.450_0.698940.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.6823 - accuracy: 0.4332 - val_loss: 0.6989 - val_accuracy: 0.4500\n","Epoch 4/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.4710\n","Epoch 4: val_loss improved from 0.69894 to 0.67482, saving model to result/models/BiLSTM_04_0.690_0.674824.h5\n","25/25 [==============================] - 4s 142ms/step - loss: 0.6549 - accuracy: 0.4710 - val_loss: 0.6748 - val_accuracy: 0.6900\n","Epoch 5/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.4937\n","Epoch 5: val_loss did not improve from 0.67482\n","25/25 [==============================] - 3s 133ms/step - loss: 0.6564 - accuracy: 0.4937 - val_loss: 0.6763 - val_accuracy: 0.6100\n","Epoch 6/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.4660\n","Epoch 6: val_loss improved from 0.67482 to 0.65847, saving model to result/models/BiLSTM_06_0.700_0.658469.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.6463 - accuracy: 0.4660 - val_loss: 0.6585 - val_accuracy: 0.7000\n","Epoch 7/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.5315\n","Epoch 7: val_loss improved from 0.65847 to 0.62834, saving model to result/models/BiLSTM_07_0.750_0.628336.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.6287 - accuracy: 0.5315 - val_loss: 0.6283 - val_accuracy: 0.7500\n","Epoch 8/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.6096\n","Epoch 8: val_loss improved from 0.62834 to 0.60832, saving model to result/models/BiLSTM_08_0.740_0.608319.h5\n","25/25 [==============================] - 4s 148ms/step - loss: 0.6219 - accuracy: 0.6096 - val_loss: 0.6083 - val_accuracy: 0.7400\n","Epoch 9/150\n","25/25 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.6499\n","Epoch 9: val_loss improved from 0.60832 to 0.59657, saving model to result/models/BiLSTM_09_0.740_0.596572.h5\n","25/25 [==============================] - 3s 132ms/step - loss: 0.6174 - accuracy: 0.6499 - val_loss: 0.5966 - val_accuracy: 0.7400\n","Epoch 10/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.6877\n","Epoch 10: val_loss improved from 0.59657 to 0.55486, saving model to result/models/BiLSTM_10_0.810_0.554857.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.5783 - accuracy: 0.6877 - val_loss: 0.5549 - val_accuracy: 0.8100\n","Epoch 11/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.6902\n","Epoch 11: val_loss improved from 0.55486 to 0.53998, saving model to result/models/BiLSTM_11_0.780_0.539983.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.5697 - accuracy: 0.6902 - val_loss: 0.5400 - val_accuracy: 0.7800\n","Epoch 12/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.7028\n","Epoch 12: val_loss improved from 0.53998 to 0.50947, saving model to result/models/BiLSTM_12_0.840_0.509470.h5\n","25/25 [==============================] - 4s 145ms/step - loss: 0.5610 - accuracy: 0.7028 - val_loss: 0.5095 - val_accuracy: 0.8400\n","Epoch 13/150\n","25/25 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.7380\n","Epoch 13: val_loss improved from 0.50947 to 0.50011, saving model to result/models/BiLSTM_13_0.770_0.500106.h5\n","25/25 [==============================] - 4s 174ms/step - loss: 0.5385 - accuracy: 0.7380 - val_loss: 0.5001 - val_accuracy: 0.7700\n","Epoch 14/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.7708\n","Epoch 14: val_loss improved from 0.50011 to 0.45993, saving model to result/models/BiLSTM_14_0.850_0.459927.h5\n","25/25 [==============================] - 4s 160ms/step - loss: 0.4962 - accuracy: 0.7708 - val_loss: 0.4599 - val_accuracy: 0.8500\n","Epoch 15/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7935\n","Epoch 15: val_loss improved from 0.45993 to 0.41734, saving model to result/models/BiLSTM_15_0.860_0.417341.h5\n","25/25 [==============================] - 4s 151ms/step - loss: 0.4540 - accuracy: 0.7935 - val_loss: 0.4173 - val_accuracy: 0.8600\n","Epoch 16/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.7506\n","Epoch 16: val_loss improved from 0.41734 to 0.38279, saving model to result/models/BiLSTM_16_0.900_0.382793.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.4922 - accuracy: 0.7506 - val_loss: 0.3828 - val_accuracy: 0.9000\n","Epoch 17/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.7909\n","Epoch 17: val_loss improved from 0.38279 to 0.34998, saving model to result/models/BiLSTM_17_0.900_0.349982.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.4338 - accuracy: 0.7909 - val_loss: 0.3500 - val_accuracy: 0.9000\n","Epoch 18/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.7935\n","Epoch 18: val_loss improved from 0.34998 to 0.31617, saving model to result/models/BiLSTM_18_0.920_0.316172.h5\n","25/25 [==============================] - 5s 189ms/step - loss: 0.4487 - accuracy: 0.7935 - val_loss: 0.3162 - val_accuracy: 0.9200\n","Epoch 19/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8413\n","Epoch 19: val_loss improved from 0.31617 to 0.28571, saving model to result/models/BiLSTM_19_0.940_0.285713.h5\n","25/25 [==============================] - 4s 146ms/step - loss: 0.3963 - accuracy: 0.8413 - val_loss: 0.2857 - val_accuracy: 0.9400\n","Epoch 20/150\n","25/25 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.8136\n","Epoch 20: val_loss improved from 0.28571 to 0.27831, saving model to result/models/BiLSTM_20_0.940_0.278309.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.4127 - accuracy: 0.8136 - val_loss: 0.2783 - val_accuracy: 0.9400\n","Epoch 21/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.8589\n","Epoch 21: val_loss improved from 0.27831 to 0.22672, saving model to result/models/BiLSTM_21_0.950_0.226722.h5\n","25/25 [==============================] - 3s 134ms/step - loss: 0.3486 - accuracy: 0.8589 - val_loss: 0.2267 - val_accuracy: 0.9500\n","Epoch 22/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.8539\n","Epoch 22: val_loss did not improve from 0.22672\n","25/25 [==============================] - 3s 141ms/step - loss: 0.3615 - accuracy: 0.8539 - val_loss: 0.2297 - val_accuracy: 0.9400\n","Epoch 23/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3400 - accuracy: 0.8615\n","Epoch 23: val_loss improved from 0.22672 to 0.21872, saving model to result/models/BiLSTM_23_0.960_0.218725.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.3400 - accuracy: 0.8615 - val_loss: 0.2187 - val_accuracy: 0.9600\n","Epoch 24/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8791\n","Epoch 24: val_loss improved from 0.21872 to 0.19221, saving model to result/models/BiLSTM_24_0.950_0.192213.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.3130 - accuracy: 0.8791 - val_loss: 0.1922 - val_accuracy: 0.9500\n","Epoch 25/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8287\n","Epoch 25: val_loss improved from 0.19221 to 0.18291, saving model to result/models/BiLSTM_25_0.950_0.182914.h5\n","25/25 [==============================] - 3s 136ms/step - loss: 0.3481 - accuracy: 0.8287 - val_loss: 0.1829 - val_accuracy: 0.9500\n","Epoch 26/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.8715\n","Epoch 26: val_loss improved from 0.18291 to 0.16923, saving model to result/models/BiLSTM_26_0.940_0.169228.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.3035 - accuracy: 0.8715 - val_loss: 0.1692 - val_accuracy: 0.9400\n","Epoch 27/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8665\n","Epoch 27: val_loss improved from 0.16923 to 0.15758, saving model to result/models/BiLSTM_27_0.960_0.157580.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.2983 - accuracy: 0.8665 - val_loss: 0.1576 - val_accuracy: 0.9600\n","Epoch 28/150\n","25/25 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8715\n","Epoch 28: val_loss did not improve from 0.15758\n","25/25 [==============================] - 4s 142ms/step - loss: 0.3056 - accuracy: 0.8715 - val_loss: 0.1717 - val_accuracy: 0.9400\n","Epoch 29/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8942\n","Epoch 29: val_loss improved from 0.15758 to 0.14978, saving model to result/models/BiLSTM_29_0.950_0.149783.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.2682 - accuracy: 0.8942 - val_loss: 0.1498 - val_accuracy: 0.9500\n","Epoch 30/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.9093\n","Epoch 30: val_loss improved from 0.14978 to 0.12859, saving model to result/models/BiLSTM_30_0.960_0.128593.h5\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2589 - accuracy: 0.9093 - val_loss: 0.1286 - val_accuracy: 0.9600\n","Epoch 31/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.8866\n","Epoch 31: val_loss improved from 0.12859 to 0.12416, saving model to result/models/BiLSTM_31_0.960_0.124161.h5\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2483 - accuracy: 0.8866 - val_loss: 0.1242 - val_accuracy: 0.9600\n","Epoch 32/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9018\n","Epoch 32: val_loss improved from 0.12416 to 0.12320, saving model to result/models/BiLSTM_32_0.980_0.123198.h5\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2713 - accuracy: 0.9018 - val_loss: 0.1232 - val_accuracy: 0.9800\n","Epoch 33/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.8917\n","Epoch 33: val_loss improved from 0.12320 to 0.11765, saving model to result/models/BiLSTM_33_0.980_0.117649.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.2625 - accuracy: 0.8917 - val_loss: 0.1176 - val_accuracy: 0.9800\n","Epoch 34/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9043\n","Epoch 34: val_loss did not improve from 0.11765\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2509 - accuracy: 0.9043 - val_loss: 0.1244 - val_accuracy: 0.9500\n","Epoch 35/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.9169\n","Epoch 35: val_loss improved from 0.11765 to 0.10821, saving model to result/models/BiLSTM_35_0.970_0.108215.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.2131 - accuracy: 0.9169 - val_loss: 0.1082 - val_accuracy: 0.9700\n","Epoch 36/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9118\n","Epoch 36: val_loss improved from 0.10821 to 0.10777, saving model to result/models/BiLSTM_36_0.980_0.107773.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.2544 - accuracy: 0.9118 - val_loss: 0.1078 - val_accuracy: 0.9800\n","Epoch 37/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.9093\n","Epoch 37: val_loss improved from 0.10777 to 0.10235, saving model to result/models/BiLSTM_37_0.980_0.102348.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.2361 - accuracy: 0.9093 - val_loss: 0.1023 - val_accuracy: 0.9800\n","Epoch 38/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9093\n","Epoch 38: val_loss improved from 0.10235 to 0.09552, saving model to result/models/BiLSTM_38_0.980_0.095522.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.2064 - accuracy: 0.9093 - val_loss: 0.0955 - val_accuracy: 0.9800\n","Epoch 39/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.8942\n","Epoch 39: val_loss improved from 0.09552 to 0.09048, saving model to result/models/BiLSTM_39_0.980_0.090478.h5\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2251 - accuracy: 0.8942 - val_loss: 0.0905 - val_accuracy: 0.9800\n","Epoch 40/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.9169\n","Epoch 40: val_loss improved from 0.09048 to 0.08899, saving model to result/models/BiLSTM_40_0.970_0.088994.h5\n","25/25 [==============================] - 3s 137ms/step - loss: 0.2206 - accuracy: 0.9169 - val_loss: 0.0890 - val_accuracy: 0.9700\n","Epoch 41/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9169\n","Epoch 41: val_loss improved from 0.08899 to 0.08518, saving model to result/models/BiLSTM_41_0.970_0.085179.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.1815 - accuracy: 0.9169 - val_loss: 0.0852 - val_accuracy: 0.9700\n","Epoch 42/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9395\n","Epoch 42: val_loss improved from 0.08518 to 0.08108, saving model to result/models/BiLSTM_42_0.980_0.081084.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.1647 - accuracy: 0.9395 - val_loss: 0.0811 - val_accuracy: 0.9800\n","Epoch 43/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9118\n","Epoch 43: val_loss improved from 0.08108 to 0.07946, saving model to result/models/BiLSTM_43_0.970_0.079456.h5\n","25/25 [==============================] - 3s 138ms/step - loss: 0.2042 - accuracy: 0.9118 - val_loss: 0.0795 - val_accuracy: 0.9700\n","Epoch 44/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9194\n","Epoch 44: val_loss improved from 0.07946 to 0.07513, saving model to result/models/BiLSTM_44_0.980_0.075134.h5\n","25/25 [==============================] - 3s 136ms/step - loss: 0.1972 - accuracy: 0.9194 - val_loss: 0.0751 - val_accuracy: 0.9800\n","Epoch 45/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9446\n","Epoch 45: val_loss did not improve from 0.07513\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1589 - accuracy: 0.9446 - val_loss: 0.0757 - val_accuracy: 0.9700\n","Epoch 46/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9244\n","Epoch 46: val_loss improved from 0.07513 to 0.07393, saving model to result/models/BiLSTM_46_0.960_0.073934.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1875 - accuracy: 0.9244 - val_loss: 0.0739 - val_accuracy: 0.9600\n","Epoch 47/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9345\n","Epoch 47: val_loss improved from 0.07393 to 0.07141, saving model to result/models/BiLSTM_47_0.980_0.071405.h5\n","25/25 [==============================] - 3s 136ms/step - loss: 0.1723 - accuracy: 0.9345 - val_loss: 0.0714 - val_accuracy: 0.9800\n","Epoch 48/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.8992\n","Epoch 48: val_loss did not improve from 0.07141\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2559 - accuracy: 0.8992 - val_loss: 0.0734 - val_accuracy: 0.9700\n","Epoch 49/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9421\n","Epoch 49: val_loss improved from 0.07141 to 0.07077, saving model to result/models/BiLSTM_49_0.980_0.070775.h5\n","25/25 [==============================] - 4s 160ms/step - loss: 0.1216 - accuracy: 0.9421 - val_loss: 0.0708 - val_accuracy: 0.9800\n","Epoch 50/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9144\n","Epoch 50: val_loss improved from 0.07077 to 0.06746, saving model to result/models/BiLSTM_50_0.980_0.067462.h5\n","25/25 [==============================] - 4s 159ms/step - loss: 0.2113 - accuracy: 0.9144 - val_loss: 0.0675 - val_accuracy: 0.9800\n","Epoch 51/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9219\n","Epoch 51: val_loss improved from 0.06746 to 0.06245, saving model to result/models/BiLSTM_51_0.990_0.062449.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.2115 - accuracy: 0.9219 - val_loss: 0.0624 - val_accuracy: 0.9900\n","Epoch 52/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9421\n","Epoch 52: val_loss did not improve from 0.06245\n","25/25 [==============================] - 4s 142ms/step - loss: 0.1344 - accuracy: 0.9421 - val_loss: 0.0676 - val_accuracy: 0.9700\n","Epoch 53/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9320\n","Epoch 53: val_loss improved from 0.06245 to 0.05726, saving model to result/models/BiLSTM_53_0.980_0.057261.h5\n","25/25 [==============================] - 4s 145ms/step - loss: 0.1518 - accuracy: 0.9320 - val_loss: 0.0573 - val_accuracy: 0.9800\n","Epoch 54/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9370\n","Epoch 54: val_loss did not improve from 0.05726\n","25/25 [==============================] - 3s 134ms/step - loss: 0.1485 - accuracy: 0.9370 - val_loss: 0.0609 - val_accuracy: 0.9800\n","Epoch 55/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9547\n","Epoch 55: val_loss did not improve from 0.05726\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1198 - accuracy: 0.9547 - val_loss: 0.0600 - val_accuracy: 0.9800\n","Epoch 56/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9471\n","Epoch 56: val_loss improved from 0.05726 to 0.05342, saving model to result/models/BiLSTM_56_0.990_0.053417.h5\n","25/25 [==============================] - 3s 136ms/step - loss: 0.1203 - accuracy: 0.9471 - val_loss: 0.0534 - val_accuracy: 0.9900\n","Epoch 57/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9194\n","Epoch 57: val_loss did not improve from 0.05342\n","25/25 [==============================] - 3s 132ms/step - loss: 0.1989 - accuracy: 0.9194 - val_loss: 0.0731 - val_accuracy: 0.9700\n","Epoch 58/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9572\n","Epoch 58: val_loss improved from 0.05342 to 0.05315, saving model to result/models/BiLSTM_58_0.980_0.053153.h5\n","25/25 [==============================] - 3s 136ms/step - loss: 0.1245 - accuracy: 0.9572 - val_loss: 0.0532 - val_accuracy: 0.9800\n","Epoch 59/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9446\n","Epoch 59: val_loss did not improve from 0.05315\n","25/25 [==============================] - 4s 143ms/step - loss: 0.1527 - accuracy: 0.9446 - val_loss: 0.0556 - val_accuracy: 0.9900\n","Epoch 60/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9597\n","Epoch 60: val_loss improved from 0.05315 to 0.05161, saving model to result/models/BiLSTM_60_0.990_0.051611.h5\n","25/25 [==============================] - 3s 136ms/step - loss: 0.1057 - accuracy: 0.9597 - val_loss: 0.0516 - val_accuracy: 0.9900\n","Epoch 61/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9471\n","Epoch 61: val_loss did not improve from 0.05161\n","25/25 [==============================] - 4s 142ms/step - loss: 0.1698 - accuracy: 0.9471 - val_loss: 0.0541 - val_accuracy: 0.9800\n","Epoch 62/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9572\n","Epoch 62: val_loss improved from 0.05161 to 0.04688, saving model to result/models/BiLSTM_62_0.990_0.046877.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.1071 - accuracy: 0.9572 - val_loss: 0.0469 - val_accuracy: 0.9900\n","Epoch 63/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9471\n","Epoch 63: val_loss did not improve from 0.04688\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1114 - accuracy: 0.9471 - val_loss: 0.0480 - val_accuracy: 0.9900\n","Epoch 64/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.9295\n","Epoch 64: val_loss did not improve from 0.04688\n","25/25 [==============================] - 4s 143ms/step - loss: 0.1307 - accuracy: 0.9295 - val_loss: 0.0472 - val_accuracy: 0.9900\n","Epoch 65/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9421\n","Epoch 65: val_loss did not improve from 0.04688\n","25/25 [==============================] - 3s 133ms/step - loss: 0.1534 - accuracy: 0.9421 - val_loss: 0.0496 - val_accuracy: 1.0000\n","Epoch 66/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9521\n","Epoch 66: val_loss did not improve from 0.04688\n","25/25 [==============================] - 4s 143ms/step - loss: 0.1092 - accuracy: 0.9521 - val_loss: 0.0583 - val_accuracy: 0.9900\n","Epoch 67/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9521\n","Epoch 67: val_loss improved from 0.04688 to 0.04339, saving model to result/models/BiLSTM_67_0.990_0.043387.h5\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1058 - accuracy: 0.9521 - val_loss: 0.0434 - val_accuracy: 0.9900\n","Epoch 68/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9622\n","Epoch 68: val_loss did not improve from 0.04339\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0897 - accuracy: 0.9622 - val_loss: 0.0454 - val_accuracy: 0.9900\n","Epoch 69/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9521\n","Epoch 69: val_loss did not improve from 0.04339\n","25/25 [==============================] - 3s 134ms/step - loss: 0.1623 - accuracy: 0.9521 - val_loss: 0.0529 - val_accuracy: 0.9800\n","Epoch 70/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9496\n","Epoch 70: val_loss improved from 0.04339 to 0.04211, saving model to result/models/BiLSTM_70_0.990_0.042113.h5\n","25/25 [==============================] - 3s 137ms/step - loss: 0.1332 - accuracy: 0.9496 - val_loss: 0.0421 - val_accuracy: 0.9900\n","Epoch 71/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9295\n","Epoch 71: val_loss did not improve from 0.04211\n","25/25 [==============================] - 3s 135ms/step - loss: 0.1422 - accuracy: 0.9295 - val_loss: 0.0759 - val_accuracy: 0.9800\n","Epoch 72/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9521\n","Epoch 72: val_loss did not improve from 0.04211\n","25/25 [==============================] - 3s 133ms/step - loss: 0.1063 - accuracy: 0.9521 - val_loss: 0.0571 - val_accuracy: 0.9800\n","Epoch 73/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9622\n","Epoch 73: val_loss did not improve from 0.04211\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0866 - accuracy: 0.9622 - val_loss: 0.0459 - val_accuracy: 0.9800\n","Epoch 74/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9496\n","Epoch 74: val_loss did not improve from 0.04211\n","25/25 [==============================] - 3s 140ms/step - loss: 0.1421 - accuracy: 0.9496 - val_loss: 0.0475 - val_accuracy: 0.9900\n","Epoch 75/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9622\n","Epoch 75: val_loss improved from 0.04211 to 0.03538, saving model to result/models/BiLSTM_75_0.990_0.035380.h5\n","25/25 [==============================] - 4s 141ms/step - loss: 0.0864 - accuracy: 0.9622 - val_loss: 0.0354 - val_accuracy: 0.9900\n","Epoch 76/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9572\n","Epoch 76: val_loss did not improve from 0.03538\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0889 - accuracy: 0.9572 - val_loss: 0.0660 - val_accuracy: 0.9700\n","Epoch 77/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9673\n","Epoch 77: val_loss did not improve from 0.03538\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0747 - accuracy: 0.9673 - val_loss: 0.0408 - val_accuracy: 0.9800\n","Epoch 78/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9748\n","Epoch 78: val_loss improved from 0.03538 to 0.03358, saving model to result/models/BiLSTM_78_0.990_0.033581.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.0336 - val_accuracy: 0.9900\n","Epoch 79/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9370\n","Epoch 79: val_loss did not improve from 0.03358\n","25/25 [==============================] - 3s 141ms/step - loss: 0.1516 - accuracy: 0.9370 - val_loss: 0.0432 - val_accuracy: 0.9900\n","Epoch 80/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9698\n","Epoch 80: val_loss did not improve from 0.03358\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0573 - accuracy: 0.9698 - val_loss: 0.0387 - val_accuracy: 0.9900\n","Epoch 81/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9673\n","Epoch 81: val_loss did not improve from 0.03358\n","25/25 [==============================] - 3s 134ms/step - loss: 0.1139 - accuracy: 0.9673 - val_loss: 0.0369 - val_accuracy: 0.9900\n","Epoch 82/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9572\n","Epoch 82: val_loss improved from 0.03358 to 0.02676, saving model to result/models/BiLSTM_82_1.000_0.026763.h5\n","25/25 [==============================] - 4s 144ms/step - loss: 0.0988 - accuracy: 0.9572 - val_loss: 0.0268 - val_accuracy: 1.0000\n","Epoch 83/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9723\n","Epoch 83: val_loss did not improve from 0.02676\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0716 - accuracy: 0.9723 - val_loss: 0.0291 - val_accuracy: 1.0000\n","Epoch 84/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9698\n","Epoch 84: val_loss did not improve from 0.02676\n","25/25 [==============================] - 3s 135ms/step - loss: 0.0706 - accuracy: 0.9698 - val_loss: 0.0289 - val_accuracy: 1.0000\n","Epoch 85/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9169\n","Epoch 85: val_loss did not improve from 0.02676\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2182 - accuracy: 0.9169 - val_loss: 0.0467 - val_accuracy: 0.9800\n","Epoch 86/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9572\n","Epoch 86: val_loss did not improve from 0.02676\n","25/25 [==============================] - 5s 201ms/step - loss: 0.0957 - accuracy: 0.9572 - val_loss: 0.0424 - val_accuracy: 0.9900\n","Epoch 87/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9471\n","Epoch 87: val_loss did not improve from 0.02676\n","25/25 [==============================] - 3s 131ms/step - loss: 0.1575 - accuracy: 0.9471 - val_loss: 0.0499 - val_accuracy: 0.9900\n","Epoch 88/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9698\n","Epoch 88: val_loss did not improve from 0.02676\n","25/25 [==============================] - 3s 132ms/step - loss: 0.0917 - accuracy: 0.9698 - val_loss: 0.0354 - val_accuracy: 0.9800\n","Epoch 89/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9572\n","Epoch 89: val_loss did not improve from 0.02676\n","25/25 [==============================] - 3s 133ms/step - loss: 0.1355 - accuracy: 0.9572 - val_loss: 0.0952 - val_accuracy: 0.9600\n","Epoch 90/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.9421\n","Epoch 90: val_loss did not improve from 0.02676\n","25/25 [==============================] - 4s 141ms/step - loss: 0.1305 - accuracy: 0.9421 - val_loss: 0.0415 - val_accuracy: 0.9900\n","Epoch 91/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9798\n","Epoch 91: val_loss did not improve from 0.02676\n","25/25 [==============================] - 4s 141ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.0387 - val_accuracy: 0.9800\n","Epoch 92/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9798\n","Epoch 92: val_loss did not improve from 0.02676\n","25/25 [==============================] - 3s 131ms/step - loss: 0.0728 - accuracy: 0.9798 - val_loss: 0.0347 - val_accuracy: 0.9900\n","Epoch 93/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9723\n","Epoch 93: val_loss did not improve from 0.02676\n","25/25 [==============================] - 3s 141ms/step - loss: 0.0568 - accuracy: 0.9723 - val_loss: 0.0291 - val_accuracy: 0.9900\n","Epoch 94/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9824\n","Epoch 94: val_loss did not improve from 0.02676\n","25/25 [==============================] - 4s 143ms/step - loss: 0.0432 - accuracy: 0.9824 - val_loss: 0.0324 - val_accuracy: 0.9900\n","Epoch 95/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9824\n","Epoch 95: val_loss did not improve from 0.02676\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.0376 - val_accuracy: 0.9800\n","Epoch 96/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9698\n","Epoch 96: val_loss improved from 0.02676 to 0.02517, saving model to result/models/BiLSTM_96_0.990_0.025170.h5\n","25/25 [==============================] - 3s 133ms/step - loss: 0.0619 - accuracy: 0.9698 - val_loss: 0.0252 - val_accuracy: 0.9900\n","Epoch 97/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9723\n","Epoch 97: val_loss did not improve from 0.02517\n","25/25 [==============================] - 4s 141ms/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 0.0351 - val_accuracy: 0.9900\n","Epoch 98/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9597\n","Epoch 98: val_loss did not improve from 0.02517\n","25/25 [==============================] - 3s 130ms/step - loss: 0.1058 - accuracy: 0.9597 - val_loss: 0.0481 - val_accuracy: 0.9900\n","Epoch 99/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9597\n","Epoch 99: val_loss improved from 0.02517 to 0.02310, saving model to result/models/BiLSTM_99_0.990_0.023104.h5\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0695 - accuracy: 0.9597 - val_loss: 0.0231 - val_accuracy: 0.9900\n","Epoch 100/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9597\n","Epoch 100: val_loss did not improve from 0.02310\n","25/25 [==============================] - 4s 142ms/step - loss: 0.1092 - accuracy: 0.9597 - val_loss: 0.0328 - val_accuracy: 0.9800\n","Epoch 101/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9698\n","Epoch 101: val_loss did not improve from 0.02310\n","25/25 [==============================] - 3s 140ms/step - loss: 0.0554 - accuracy: 0.9698 - val_loss: 0.0378 - val_accuracy: 0.9800\n","Epoch 102/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9673\n","Epoch 102: val_loss did not improve from 0.02310\n","25/25 [==============================] - 3s 131ms/step - loss: 0.0657 - accuracy: 0.9673 - val_loss: 0.0232 - val_accuracy: 0.9900\n","Epoch 103/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9824\n","Epoch 103: val_loss did not improve from 0.02310\n","25/25 [==============================] - 3s 140ms/step - loss: 0.0401 - accuracy: 0.9824 - val_loss: 0.0407 - val_accuracy: 0.9900\n","Epoch 104/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9798\n","Epoch 104: val_loss improved from 0.02310 to 0.02033, saving model to result/models/BiLSTM_104_0.990_0.020330.h5\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0616 - accuracy: 0.9798 - val_loss: 0.0203 - val_accuracy: 0.9900\n","Epoch 105/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9798\n","Epoch 105: val_loss did not improve from 0.02033\n","25/25 [==============================] - 4s 141ms/step - loss: 0.0490 - accuracy: 0.9798 - val_loss: 0.0473 - val_accuracy: 0.9900\n","Epoch 106/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9849\n","Epoch 106: val_loss improved from 0.02033 to 0.01946, saving model to result/models/BiLSTM_106_0.990_0.019456.h5\n","25/25 [==============================] - 4s 143ms/step - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.0195 - val_accuracy: 0.9900\n","Epoch 107/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9849\n","Epoch 107: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0376 - val_accuracy: 0.9900\n","Epoch 108/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9647\n","Epoch 108: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0750 - accuracy: 0.9647 - val_loss: 0.0439 - val_accuracy: 0.9800\n","Epoch 109/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9723\n","Epoch 109: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0513 - accuracy: 0.9723 - val_loss: 0.0243 - val_accuracy: 0.9900\n","Epoch 110/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9673\n","Epoch 110: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 134ms/step - loss: 0.1068 - accuracy: 0.9673 - val_loss: 0.0450 - val_accuracy: 0.9700\n","Epoch 111/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9874\n","Epoch 111: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0450 - accuracy: 0.9874 - val_loss: 0.0339 - val_accuracy: 0.9900\n","Epoch 112/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9824\n","Epoch 112: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0457 - accuracy: 0.9824 - val_loss: 0.0382 - val_accuracy: 0.9900\n","Epoch 113/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9698\n","Epoch 113: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 141ms/step - loss: 0.0862 - accuracy: 0.9698 - val_loss: 0.0285 - val_accuracy: 0.9800\n","Epoch 114/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9370\n","Epoch 114: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 133ms/step - loss: 0.1527 - accuracy: 0.9370 - val_loss: 0.0709 - val_accuracy: 0.9700\n","Epoch 115/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9471\n","Epoch 115: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 141ms/step - loss: 0.1632 - accuracy: 0.9471 - val_loss: 0.0582 - val_accuracy: 0.9800\n","Epoch 116/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9773\n","Epoch 116: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 143ms/step - loss: 0.0669 - accuracy: 0.9773 - val_loss: 0.0465 - val_accuracy: 0.9700\n","Epoch 117/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9647\n","Epoch 117: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 135ms/step - loss: 0.0900 - accuracy: 0.9647 - val_loss: 0.0467 - val_accuracy: 0.9800\n","Epoch 118/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9723\n","Epoch 118: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 143ms/step - loss: 0.0699 - accuracy: 0.9723 - val_loss: 0.0310 - val_accuracy: 0.9900\n","Epoch 119/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9798\n","Epoch 119: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0479 - accuracy: 0.9798 - val_loss: 0.0303 - val_accuracy: 0.9900\n","Epoch 120/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9748\n","Epoch 120: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0688 - accuracy: 0.9748 - val_loss: 0.0291 - val_accuracy: 0.9900\n","Epoch 121/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9773\n","Epoch 121: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 133ms/step - loss: 0.0467 - accuracy: 0.9773 - val_loss: 0.0488 - val_accuracy: 0.9800\n","Epoch 122/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9899\n","Epoch 122: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 141ms/step - loss: 0.0373 - accuracy: 0.9899 - val_loss: 0.0236 - val_accuracy: 0.9900\n","Epoch 123/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9597\n","Epoch 123: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 167ms/step - loss: 0.1120 - accuracy: 0.9597 - val_loss: 0.0628 - val_accuracy: 0.9800\n","Epoch 124/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9773\n","Epoch 124: val_loss did not improve from 0.01946\n","25/25 [==============================] - 4s 158ms/step - loss: 0.0528 - accuracy: 0.9773 - val_loss: 0.0429 - val_accuracy: 0.9700\n","Epoch 125/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9773\n","Epoch 125: val_loss did not improve from 0.01946\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0588 - accuracy: 0.9773 - val_loss: 0.0243 - val_accuracy: 0.9900\n","Epoch 126/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9723\n","Epoch 126: val_loss improved from 0.01946 to 0.01402, saving model to result/models/BiLSTM_126_1.000_0.014019.h5\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0740 - accuracy: 0.9723 - val_loss: 0.0140 - val_accuracy: 1.0000\n","Epoch 127/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9924\n","Epoch 127: val_loss did not improve from 0.01402\n","25/25 [==============================] - 3s 133ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0161 - val_accuracy: 0.9900\n","Epoch 128/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9849\n","Epoch 128: val_loss did not improve from 0.01402\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.0213 - val_accuracy: 1.0000\n","Epoch 129/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9773\n","Epoch 129: val_loss improved from 0.01402 to 0.01353, saving model to result/models/BiLSTM_129_1.000_0.013526.h5\n","25/25 [==============================] - 4s 145ms/step - loss: 0.0494 - accuracy: 0.9773 - val_loss: 0.0135 - val_accuracy: 1.0000\n","Epoch 130/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9748\n","Epoch 130: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 143ms/step - loss: 0.0664 - accuracy: 0.9748 - val_loss: 0.0232 - val_accuracy: 0.9900\n","Epoch 131/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9824\n","Epoch 131: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0429 - accuracy: 0.9824 - val_loss: 0.0186 - val_accuracy: 0.9900\n","Epoch 132/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9824\n","Epoch 132: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0359 - accuracy: 0.9824 - val_loss: 0.0158 - val_accuracy: 0.9900\n","Epoch 133/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9471\n","Epoch 133: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 143ms/step - loss: 0.1170 - accuracy: 0.9471 - val_loss: 0.0666 - val_accuracy: 0.9900\n","Epoch 134/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9219\n","Epoch 134: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 134ms/step - loss: 0.1874 - accuracy: 0.9219 - val_loss: 0.0549 - val_accuracy: 0.9800\n","Epoch 135/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9118\n","Epoch 135: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.2002 - accuracy: 0.9118 - val_loss: 0.0780 - val_accuracy: 0.9700\n","Epoch 136/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9647\n","Epoch 136: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0874 - accuracy: 0.9647 - val_loss: 0.0614 - val_accuracy: 0.9800\n","Epoch 137/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9496\n","Epoch 137: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 141ms/step - loss: 0.0729 - accuracy: 0.9496 - val_loss: 0.0452 - val_accuracy: 0.9700\n","Epoch 138/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9723\n","Epoch 138: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 134ms/step - loss: 0.0840 - accuracy: 0.9723 - val_loss: 0.0452 - val_accuracy: 0.9800\n","Epoch 139/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9748\n","Epoch 139: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 136ms/step - loss: 0.0650 - accuracy: 0.9748 - val_loss: 0.0318 - val_accuracy: 0.9800\n","Epoch 140/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9874\n","Epoch 140: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0422 - accuracy: 0.9874 - val_loss: 0.0434 - val_accuracy: 0.9800\n","Epoch 141/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9798\n","Epoch 141: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 0.0278 - val_accuracy: 0.9800\n","Epoch 142/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9849\n","Epoch 142: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 141ms/step - loss: 0.0339 - accuracy: 0.9849 - val_loss: 0.0354 - val_accuracy: 0.9800\n","Epoch 143/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9824\n","Epoch 143: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 132ms/step - loss: 0.0432 - accuracy: 0.9824 - val_loss: 0.0248 - val_accuracy: 0.9900\n","Epoch 144/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1684 - accuracy: 0.9597\n","Epoch 144: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 133ms/step - loss: 0.1684 - accuracy: 0.9597 - val_loss: 0.0815 - val_accuracy: 0.9700\n","Epoch 145/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9748\n","Epoch 145: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0422 - accuracy: 0.9748 - val_loss: 0.0348 - val_accuracy: 0.9800\n","Epoch 146/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9874\n","Epoch 146: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 133ms/step - loss: 0.0608 - accuracy: 0.9874 - val_loss: 0.0231 - val_accuracy: 0.9900\n","Epoch 147/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9899\n","Epoch 147: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 133ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0232 - val_accuracy: 0.9900\n","Epoch 148/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9723\n","Epoch 148: val_loss did not improve from 0.01353\n","25/25 [==============================] - 4s 142ms/step - loss: 0.0573 - accuracy: 0.9723 - val_loss: 0.0345 - val_accuracy: 0.9800\n","Epoch 149/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9950\n","Epoch 149: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 140ms/step - loss: 0.0225 - accuracy: 0.9950 - val_loss: 0.0291 - val_accuracy: 0.9800\n","Epoch 150/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9824\n","Epoch 150: val_loss did not improve from 0.01353\n","25/25 [==============================] - 3s 131ms/step - loss: 0.0710 - accuracy: 0.9824 - val_loss: 0.0184 - val_accuracy: 1.0000\n"]}],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7DnM4SLhh3S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660555309567,"user_tz":-480,"elapsed":9893,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"}},"outputId":"eef407ab-760a-4048-8409-64a61940f894"},"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Start testing process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] There are 125 total samples in the test set. 7 vulnerable samples. \n","2022-08-15 09:21:45.339000: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Model: \"BiLSTM_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 1000, 128)        84992     \n"," l)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 1000, 128)         0         \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 1000, 128)        99328     \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 128)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                8256      \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 767,789\n","Trainable params: 194,689\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","8/8 [==============================] - 3s 99ms/step\n","[INFO] BiLSTM classification result: \n","\n","[INFO] Total accuracy: 0.992\n","[INFO] ----------------------------------------------------\n","[INFO] The confusion matrix: \n","\n","[[117   1]\n"," [  0   7]]\n","\n","\n","                precision    recall  f1-score   support\n","\n","Non-vulnerable       1.00      0.99      1.00       118\n","    Vulnerable       0.88      1.00      0.93         7\n","\n","      accuracy                           0.99       125\n","     macro avg       0.94      1.00      0.96       125\n","  weighted avg       0.99      0.99      0.99       125\n","\n"]}],"source":["!python main.py --config config/config.yaml --test --trained_model result/models/BiLSTM_129_1.000_0.013526.h5 --data_dir Data/LibPNG --output_dir result/finalResult"]},{"cell_type":"markdown","source":["##TextCNN for LibPNG\n"],"metadata":{"id":"1KiNnLfjuxEo"}},{"cell_type":"code","source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"],"metadata":{"id":"z9sQM9PQvDV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python main.py --config config/config.yaml --test --trained_model result/models/test_model_DNN_111_0.990_0.025587.h5 --data_dir Data/LibPNG --output_dir result/finalResult"],"metadata":{"id":"G9Br5RpuvE_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oMeuuBQfhjBX"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6922,"status":"ok","timestamp":1659974836455,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"-Wc9Ii74IlEX","outputId":"6c0e899e-3c1d-490b-8ef0-6011d89fed0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start testing process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] There are 125 total samples in the test set. 7 vulnerable samples. \n","2022-08-08 16:07:14.063991: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","Model: \"DNN_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," flatten (Flatten)           (None, 100000)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               12800128  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 13,400,109\n","Trainable params: 12,827,009\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","8/8 [==============================] - 1s 1ms/step\n","[INFO] DNN classification result: \n","\n","[INFO] Total accuracy: 0.952\n","[INFO] ----------------------------------------------------\n","[INFO] The confusion matrix: \n","\n","[[113   5]\n"," [  1   6]]\n","\n","\n","                precision    recall  f1-score   support\n","\n","Non-vulnerable       0.99      0.96      0.97       118\n","    Vulnerable       0.55      0.86      0.67         7\n","\n","      accuracy                           0.95       125\n","     macro avg       0.77      0.91      0.82       125\n","  weighted avg       0.97      0.95      0.96       125\n","\n"]}],"source":["!python main.py --config config/config.yaml --test --trained_model result/models/test_model_DNN_40_0.990_0.079979.h5 --data_dir Data/LibPNG --output_dir result/finalResult"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhEhLFRlIlLs"},"outputs":[],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90019,"status":"ok","timestamp":1660549341734,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"-6NbBKlncrsO","outputId":"84a7e7e1-5c17-4ee6-ea92-3d8b17a3bcf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Start training process....\n","[INFO] Loading data from /content/drive/MyDrive/A benchmark/Function-level-Vulnerability-Dataset_latest/Data/LibPNG....\n","[INFO] The length of the loaded data list is : 622\n","[INFO] Perform tokenization ....\n","[INFO] Pad the sequence to unified length...\n","[INFO] Patition the data ....\n","[INFO] -------------------------------------------------------\n","[INFO] Data processing completed!\n","[INFO] There are 397 total samples in the tr*aining set. 29 vulnerable samples. \n","[INFO] There are 100 total samples in the validation set. 9 vulnerable samples. \n","[INFO] -------------------------------------------------------\n","[INFO] Loading trained Word2vec model. \n","[INFO] The trained word2vec model: \n","<_io.TextIOWrapper name='result/w2v_model_CBOW_dict.txt' mode='r' encoding='UTF-8'>\n","[INFO] Found 1887 word vectors.\n","[0.53940217 6.84482759]\n","[INFO] -------------------------------------------------------\n","[INFO] Loading the DNN model.\n","2022-08-15 07:40:56.546151: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","[INFO] Model structure loaded.\n","Model: \"DNN_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1000)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, 1000, 100)         573100    \n","                                                                 \n"," flatten (Flatten)           (None, 100000)            0         \n","                                                                 \n"," dense (Dense)               (None, 128)               12800128  \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 13,400,109\n","Trainable params: 12,827,009\n","Non-trainable params: 573,100\n","_________________________________________________________________\n","WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n","Epoch 1/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.8332 - accuracy: 0.3250 \n","Epoch 1: val_loss improved from inf to 0.81954, saving model to result/models/test_model_DNN_01_0.630_0.819539.h5\n","25/25 [==============================] - 2s 18ms/step - loss: 0.8434 - accuracy: 0.4106 - val_loss: 0.8195 - val_accuracy: 0.6300\n","Epoch 2/150\n","15/25 [=================>............] - ETA: 0s - loss: 1.3133 - accuracy: 0.4167\n","Epoch 2: val_loss improved from 0.81954 to 0.80573, saving model to result/models/test_model_DNN_02_0.820_0.805726.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 1.0250 - accuracy: 0.4660 - val_loss: 0.8057 - val_accuracy: 0.8200\n","Epoch 3/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.5135 - accuracy: 0.8125\n","Epoch 3: val_loss improved from 0.80573 to 0.60740, saving model to result/models/test_model_DNN_03_0.810_0.607400.h5\n","25/25 [==============================] - 1s 27ms/step - loss: 0.4948 - accuracy: 0.8186 - val_loss: 0.6074 - val_accuracy: 0.8100\n","Epoch 4/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.4038 - accuracy: 0.8333\n","Epoch 4: val_loss improved from 0.60740 to 0.55288, saving model to result/models/test_model_DNN_04_0.830_0.552881.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8388 - val_loss: 0.5529 - val_accuracy: 0.8300\n","Epoch 5/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.3912 - accuracy: 0.8708\n","Epoch 5: val_loss improved from 0.55288 to 0.49413, saving model to result/models/test_model_DNN_05_0.900_0.494128.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.3738 - accuracy: 0.8892 - val_loss: 0.4941 - val_accuracy: 0.9000\n","Epoch 6/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.2960 - accuracy: 0.9598\n","Epoch 6: val_loss improved from 0.49413 to 0.46937, saving model to result/models/test_model_DNN_06_0.910_0.469374.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.2945 - accuracy: 0.9496 - val_loss: 0.4694 - val_accuracy: 0.9100\n","Epoch 7/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.2478 - accuracy: 0.9643\n","Epoch 7: val_loss improved from 0.46937 to 0.43528, saving model to result/models/test_model_DNN_07_0.910_0.435283.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.2547 - accuracy: 0.9673 - val_loss: 0.4353 - val_accuracy: 0.9100\n","Epoch 8/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.2584 - accuracy: 0.9663\n","Epoch 8: val_loss improved from 0.43528 to 0.37590, saving model to result/models/test_model_DNN_08_0.960_0.375900.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9647 - val_loss: 0.3759 - val_accuracy: 0.9600\n","Epoch 9/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.2052 - accuracy: 0.9856\n","Epoch 9: val_loss improved from 0.37590 to 0.35987, saving model to result/models/test_model_DNN_09_0.960_0.359873.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.2177 - accuracy: 0.9698 - val_loss: 0.3599 - val_accuracy: 0.9600\n","Epoch 10/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.2049 - accuracy: 0.9708\n","Epoch 10: val_loss improved from 0.35987 to 0.32391, saving model to result/models/test_model_DNN_10_0.960_0.323907.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.1863 - accuracy: 0.9798 - val_loss: 0.3239 - val_accuracy: 0.9600\n","Epoch 11/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.1498 - accuracy: 0.9955\n","Epoch 11: val_loss improved from 0.32391 to 0.29746, saving model to result/models/test_model_DNN_11_0.970_0.297456.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.1580 - accuracy: 0.9874 - val_loss: 0.2975 - val_accuracy: 0.9700\n","Epoch 12/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1384 - accuracy: 1.0000\n","Epoch 12: val_loss improved from 0.29746 to 0.28065, saving model to result/models/test_model_DNN_12_0.970_0.280653.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.1368 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9700\n","Epoch 13/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1644 - accuracy: 0.9958\n","Epoch 13: val_loss improved from 0.28065 to 0.26960, saving model to result/models/test_model_DNN_13_0.960_0.269605.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.1564 - accuracy: 0.9975 - val_loss: 0.2696 - val_accuracy: 0.9600\n","Epoch 14/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.2008 - accuracy: 0.9375\n","Epoch 14: val_loss improved from 0.26960 to 0.25311, saving model to result/models/test_model_DNN_14_0.960_0.253108.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.1653 - accuracy: 0.9622 - val_loss: 0.2531 - val_accuracy: 0.9600\n","Epoch 15/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.1138 - accuracy: 1.0000\n","Epoch 15: val_loss improved from 0.25311 to 0.23508, saving model to result/models/test_model_DNN_15_0.970_0.235080.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9700\n","Epoch 16/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0925 - accuracy: 1.0000\n","Epoch 16: val_loss improved from 0.23508 to 0.22191, saving model to result/models/test_model_DNN_16_0.970_0.221912.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9700\n","Epoch 17/150\n","25/25 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9975\n","Epoch 17: val_loss improved from 0.22191 to 0.21311, saving model to result/models/test_model_DNN_17_0.980_0.213109.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.1184 - accuracy: 0.9975 - val_loss: 0.2131 - val_accuracy: 0.9800\n","Epoch 18/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1058 - accuracy: 0.9958\n","Epoch 18: val_loss improved from 0.21311 to 0.20022, saving model to result/models/test_model_DNN_18_0.980_0.200225.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0942 - accuracy: 0.9975 - val_loss: 0.2002 - val_accuracy: 0.9800\n","Epoch 19/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0767 - accuracy: 1.0000\n","Epoch 19: val_loss improved from 0.20022 to 0.19870, saving model to result/models/test_model_DNN_19_0.970_0.198695.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9700\n","Epoch 20/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.1336 - accuracy: 0.9708\n","Epoch 20: val_loss improved from 0.19870 to 0.19659, saving model to result/models/test_model_DNN_20_0.960_0.196594.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9773 - val_loss: 0.1966 - val_accuracy: 0.9600\n","Epoch 21/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0695 - accuracy: 1.0000\n","Epoch 21: val_loss improved from 0.19659 to 0.18169, saving model to result/models/test_model_DNN_21_0.980_0.181691.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0704 - accuracy: 0.9975 - val_loss: 0.1817 - val_accuracy: 0.9800\n","Epoch 22/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000\n","Epoch 22: val_loss improved from 0.18169 to 0.17902, saving model to result/models/test_model_DNN_22_0.960_0.179023.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9600\n","Epoch 23/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\n","Epoch 23: val_loss improved from 0.17902 to 0.16577, saving model to result/models/test_model_DNN_23_0.970_0.165774.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9700\n","Epoch 24/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n","Epoch 24: val_loss did not improve from 0.16577\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9975 - val_loss: 0.1669 - val_accuracy: 0.9800\n","Epoch 25/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0705 - accuracy: 1.0000\n","Epoch 25: val_loss improved from 0.16577 to 0.15969, saving model to result/models/test_model_DNN_25_0.980_0.159692.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9800\n","Epoch 26/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0474 - accuracy: 1.0000\n","Epoch 26: val_loss improved from 0.15969 to 0.15956, saving model to result/models/test_model_DNN_26_0.960_0.159562.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9600\n","Epoch 27/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0438 - accuracy: 1.0000\n","Epoch 27: val_loss improved from 0.15956 to 0.15236, saving model to result/models/test_model_DNN_27_0.980_0.152357.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9800\n","Epoch 28/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0450 - accuracy: 1.0000\n","Epoch 28: val_loss did not improve from 0.15236\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9700\n","Epoch 29/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0438 - accuracy: 1.0000\n","Epoch 29: val_loss improved from 0.15236 to 0.14357, saving model to result/models/test_model_DNN_29_0.980_0.143567.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9800\n","Epoch 30/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0474 - accuracy: 0.9974\n","Epoch 30: val_loss did not improve from 0.14357\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 0.9975 - val_loss: 0.1459 - val_accuracy: 0.9600\n","Epoch 31/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.0000\n","Epoch 31: val_loss improved from 0.14357 to 0.13745, saving model to result/models/test_model_DNN_31_0.980_0.137453.h5\n","25/25 [==============================] - 1s 21ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9800\n","Epoch 32/150\n","18/25 [====================>.........] - ETA: 0s - loss: 0.0345 - accuracy: 1.0000\n","Epoch 32: val_loss did not improve from 0.13745\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9700\n","Epoch 33/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9975\n","Epoch 33: val_loss improved from 0.13745 to 0.13510, saving model to result/models/test_model_DNN_33_0.980_0.135097.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 0.0814 - accuracy: 0.9975 - val_loss: 0.1351 - val_accuracy: 0.9800\n","Epoch 34/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0307 - accuracy: 1.0000\n","Epoch 34: val_loss improved from 0.13510 to 0.13400, saving model to result/models/test_model_DNN_34_0.980_0.133999.h5\n","25/25 [==============================] - 1s 21ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9800\n","Epoch 35/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9975\n","Epoch 35: val_loss did not improve from 0.13400\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0526 - accuracy: 0.9975 - val_loss: 0.1367 - val_accuracy: 0.9600\n","Epoch 36/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0943 - accuracy: 0.9967\n","Epoch 36: val_loss did not improve from 0.13400\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0965 - accuracy: 0.9899 - val_loss: 0.2792 - val_accuracy: 0.9000\n","Epoch 37/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0313 - accuracy: 0.9937\n","Epoch 37: val_loss improved from 0.13400 to 0.13254, saving model to result/models/test_model_DNN_37_0.970_0.132543.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0305 - accuracy: 0.9950 - val_loss: 0.1325 - val_accuracy: 0.9700\n","Epoch 38/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0258 - accuracy: 1.0000\n","Epoch 38: val_loss improved from 0.13254 to 0.12856, saving model to result/models/test_model_DNN_38_0.970_0.128562.h5\n","25/25 [==============================] - 1s 21ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9700\n","Epoch 39/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.0000\n","Epoch 39: val_loss improved from 0.12856 to 0.12797, saving model to result/models/test_model_DNN_39_0.970_0.127973.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9700\n","Epoch 40/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000\n","Epoch 40: val_loss did not improve from 0.12797\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9600\n","Epoch 41/150\n","25/25 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9723\n","Epoch 41: val_loss did not improve from 0.12797\n","25/25 [==============================] - 0s 10ms/step - loss: 0.2225 - accuracy: 0.9723 - val_loss: 1.3599 - val_accuracy: 0.7800\n","Epoch 42/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.5587 - accuracy: 0.9245\n","Epoch 42: val_loss did not improve from 0.12797\n","25/25 [==============================] - 0s 9ms/step - loss: 0.5605 - accuracy: 0.9244 - val_loss: 0.4722 - val_accuracy: 0.9200\n","Epoch 43/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.1303 - accuracy: 0.9853\n","Epoch 43: val_loss did not improve from 0.12797\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0986 - accuracy: 0.9899 - val_loss: 0.2463 - val_accuracy: 0.9400\n","Epoch 44/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0975 - accuracy: 0.9853\n","Epoch 44: val_loss did not improve from 0.12797\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9899 - val_loss: 0.1353 - val_accuracy: 0.9600\n","Epoch 45/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000\n","Epoch 45: val_loss improved from 0.12797 to 0.12050, saving model to result/models/test_model_DNN_45_0.980_0.120498.h5\n","25/25 [==============================] - 1s 21ms/step - loss: 0.0323 - accuracy: 0.9975 - val_loss: 0.1205 - val_accuracy: 0.9800\n","Epoch 46/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0256 - accuracy: 1.0000\n","Epoch 46: val_loss did not improve from 0.12050\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 0.9950 - val_loss: 0.2014 - val_accuracy: 0.9200\n","Epoch 47/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0386 - accuracy: 0.9937\n","Epoch 47: val_loss improved from 0.12050 to 0.11534, saving model to result/models/test_model_DNN_47_0.980_0.115335.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0358 - accuracy: 0.9950 - val_loss: 0.1153 - val_accuracy: 0.9800\n","Epoch 48/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9719\n","Epoch 48: val_loss did not improve from 0.11534\n","25/25 [==============================] - 0s 9ms/step - loss: 0.1286 - accuracy: 0.9622 - val_loss: 0.2161 - val_accuracy: 0.9000\n","Epoch 49/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0586 - accuracy: 0.9868\n","Epoch 49: val_loss did not improve from 0.11534\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0508 - accuracy: 0.9899 - val_loss: 0.1232 - val_accuracy: 0.9800\n","Epoch 50/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0398 - accuracy: 0.9969\n","Epoch 50: val_loss improved from 0.11534 to 0.11442, saving model to result/models/test_model_DNN_50_0.980_0.114424.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 0.0365 - accuracy: 0.9975 - val_loss: 0.1144 - val_accuracy: 0.9800\n","Epoch 51/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.0000\n","Epoch 51: val_loss improved from 0.11442 to 0.11147, saving model to result/models/test_model_DNN_51_0.980_0.111469.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9800\n","Epoch 52/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0298 - accuracy: 1.0000\n","Epoch 52: val_loss improved from 0.11147 to 0.10959, saving model to result/models/test_model_DNN_52_0.980_0.109588.h5\n","25/25 [==============================] - 1s 26ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9800\n","Epoch 53/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0193 - accuracy: 1.0000\n","Epoch 53: val_loss improved from 0.10959 to 0.10947, saving model to result/models/test_model_DNN_53_0.980_0.109468.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9800\n","Epoch 54/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000\n","Epoch 54: val_loss did not improve from 0.10947\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9800\n","Epoch 55/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 55: val_loss did not improve from 0.10947\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9800\n","Epoch 56/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n","Epoch 56: val_loss did not improve from 0.10947\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9800\n","Epoch 57/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n","Epoch 57: val_loss improved from 0.10947 to 0.10945, saving model to result/models/test_model_DNN_57_0.980_0.109453.h5\n","25/25 [==============================] - 1s 24ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9800\n","Epoch 58/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0377 - accuracy: 0.9940\n","Epoch 58: val_loss did not improve from 0.10945\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0344 - accuracy: 0.9950 - val_loss: 0.1106 - val_accuracy: 0.9900\n","Epoch 59/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n","Epoch 59: val_loss improved from 0.10945 to 0.10904, saving model to result/models/test_model_DNN_59_0.990_0.109038.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9900\n","Epoch 60/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n","Epoch 60: val_loss improved from 0.10904 to 0.10689, saving model to result/models/test_model_DNN_60_0.980_0.106887.h5\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9800\n","Epoch 61/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n","Epoch 61: val_loss improved from 0.10689 to 0.10556, saving model to result/models/test_model_DNN_61_0.980_0.105556.h5\n","25/25 [==============================] - 1s 31ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9800\n","Epoch 62/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000\n","Epoch 62: val_loss improved from 0.10556 to 0.10448, saving model to result/models/test_model_DNN_62_0.980_0.104480.h5\n","25/25 [==============================] - 1s 24ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9800\n","Epoch 63/150\n","18/25 [====================>.........] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n","Epoch 63: val_loss did not improve from 0.10448\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9900\n","Epoch 64/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000\n","Epoch 64: val_loss did not improve from 0.10448\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9800\n","Epoch 65/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0127 - accuracy: 1.0000\n","Epoch 65: val_loss did not improve from 0.10448\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9800\n","Epoch 66/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\n","Epoch 66: val_loss improved from 0.10448 to 0.10340, saving model to result/models/test_model_DNN_66_0.980_0.103401.h5\n","25/25 [==============================] - 0s 18ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9800\n","Epoch 67/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n","Epoch 67: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9700\n","Epoch 68/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n","Epoch 68: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9800\n","Epoch 69/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n","Epoch 69: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9800\n","Epoch 70/150\n","18/25 [====================>.........] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\n","Epoch 70: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9800\n","Epoch 71/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000\n","Epoch 71: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9800\n","Epoch 72/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.1088 - accuracy: 0.9963\n","Epoch 72: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9975 - val_loss: 0.1064 - val_accuracy: 0.9800\n","Epoch 73/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n","Epoch 73: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9700\n","Epoch 74/150\n","18/25 [====================>.........] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n","Epoch 74: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9700\n","Epoch 75/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n","Epoch 75: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9800\n","Epoch 76/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n","Epoch 76: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9800\n","Epoch 77/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0105 - accuracy: 1.0000\n","Epoch 77: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9700\n","Epoch 78/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n","Epoch 78: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9700\n","Epoch 79/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n","Epoch 79: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9700\n","Epoch 80/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000\n","Epoch 80: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9800\n","Epoch 81/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000\n","Epoch 81: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9800\n","Epoch 82/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\n","Epoch 82: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9800\n","Epoch 83/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n","Epoch 83: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9800\n","Epoch 84/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n","Epoch 84: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9800\n","Epoch 85/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n","Epoch 85: val_loss did not improve from 0.10340\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.1045 - val_accuracy: 0.9600\n","Epoch 86/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000\n","Epoch 86: val_loss improved from 0.10340 to 0.10269, saving model to result/models/test_model_DNN_86_0.980_0.102691.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9800\n","Epoch 87/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n","Epoch 87: val_loss improved from 0.10269 to 0.10176, saving model to result/models/test_model_DNN_87_0.990_0.101757.h5\n","25/25 [==============================] - 1s 23ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9900\n","Epoch 88/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n","Epoch 88: val_loss improved from 0.10176 to 0.10077, saving model to result/models/test_model_DNN_88_0.990_0.100767.h5\n","25/25 [==============================] - 1s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9900\n","Epoch 89/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n","Epoch 89: val_loss improved from 0.10077 to 0.10029, saving model to result/models/test_model_DNN_89_0.990_0.100285.h5\n","25/25 [==============================] - 0s 20ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9900\n","Epoch 90/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n","Epoch 90: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9900\n","Epoch 91/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\n","Epoch 91: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9700\n","Epoch 92/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n","Epoch 92: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9800\n","Epoch 93/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n","Epoch 93: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9800\n","Epoch 94/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n","Epoch 94: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9800\n","Epoch 95/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n","Epoch 95: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9800\n","Epoch 96/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.2330 - accuracy: 0.9583\n","Epoch 96: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9698 - val_loss: 0.1010 - val_accuracy: 0.9800\n","Epoch 97/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n","Epoch 97: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9975 - val_loss: 0.1011 - val_accuracy: 0.9800\n","Epoch 98/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n","Epoch 98: val_loss did not improve from 0.10029\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9800\n","Epoch 99/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n","Epoch 99: val_loss improved from 0.10029 to 0.10013, saving model to result/models/test_model_DNN_99_0.980_0.100132.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9800\n","Epoch 100/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n","Epoch 100: val_loss improved from 0.10013 to 0.09951, saving model to result/models/test_model_DNN_100_0.980_0.099511.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9800\n","Epoch 101/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n","Epoch 101: val_loss improved from 0.09951 to 0.09927, saving model to result/models/test_model_DNN_101_0.980_0.099274.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9800\n","Epoch 102/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n","Epoch 102: val_loss improved from 0.09927 to 0.09877, saving model to result/models/test_model_DNN_102_0.980_0.098771.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9800\n","Epoch 103/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n","Epoch 103: val_loss improved from 0.09877 to 0.09846, saving model to result/models/test_model_DNN_103_0.980_0.098461.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9800\n","Epoch 104/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n","Epoch 104: val_loss improved from 0.09846 to 0.09816, saving model to result/models/test_model_DNN_104_0.980_0.098157.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9800\n","Epoch 105/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n","Epoch 105: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9800\n","Epoch 106/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 106: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9800\n","Epoch 107/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 107: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9800\n","Epoch 108/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n","Epoch 108: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9800\n","Epoch 109/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n","Epoch 109: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9975 - val_loss: 0.1065 - val_accuracy: 0.9600\n","Epoch 110/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 110: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9975 - val_loss: 0.1040 - val_accuracy: 0.9600\n","Epoch 111/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n","Epoch 111: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9600\n","Epoch 112/150\n","16/25 [==================>...........] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n","Epoch 112: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 7ms/step - loss: 0.1979 - accuracy: 0.9773 - val_loss: 0.2686 - val_accuracy: 0.8900\n","Epoch 113/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0512 - accuracy: 0.9732\n","Epoch 113: val_loss did not improve from 0.09816\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9849 - val_loss: 0.0985 - val_accuracy: 0.9700\n","Epoch 114/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n","Epoch 114: val_loss improved from 0.09816 to 0.09795, saving model to result/models/test_model_DNN_114_0.970_0.097951.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9700\n","Epoch 115/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n","Epoch 115: val_loss improved from 0.09795 to 0.09788, saving model to result/models/test_model_DNN_115_0.980_0.097876.h5\n","25/25 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9800\n","Epoch 116/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n","Epoch 116: val_loss did not improve from 0.09788\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9800\n","Epoch 117/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 117: val_loss improved from 0.09788 to 0.09787, saving model to result/models/test_model_DNN_117_0.980_0.097875.h5\n","25/25 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9800\n","Epoch 118/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 118: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9700\n","Epoch 119/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n","Epoch 119: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9700\n","Epoch 120/150\n","12/25 [=============>................] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n","Epoch 120: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9700\n","Epoch 121/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n","Epoch 121: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9700\n","Epoch 122/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n","Epoch 122: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9975 - val_loss: 0.1023 - val_accuracy: 0.9700\n","Epoch 123/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 123: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9700\n","Epoch 124/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n","Epoch 124: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9700\n","Epoch 125/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n","Epoch 125: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9700\n","Epoch 126/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n","Epoch 126: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9700\n","Epoch 127/150\n","14/25 [===============>..............] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n","Epoch 127: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9700\n","Epoch 128/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n","Epoch 128: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9700\n","Epoch 129/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 129: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9800\n","Epoch 130/150\n","15/25 [=================>............] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n","Epoch 130: val_loss did not improve from 0.09787\n","25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9800\n","Epoch 131/150\n","13/25 [==============>...............] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n","Epoch 131: val_loss improved from 0.09787 to 0.09741, saving model to result/models/test_model_DNN_131_0.980_0.097406.h5\n","25/25 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9800\n","Epoch 132/150\n","24/25 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n","Epoch 132: val_loss improved from 0.09741 to 0.09662, saving model to result/models/test_model_DNN_132_0.980_0.096619.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9800\n","Epoch 133/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n","Epoch 133: val_loss did not improve from 0.09662\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9800\n","Epoch 134/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n","Epoch 134: val_loss did not improve from 0.09662\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9800\n","Epoch 135/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n","Epoch 135: val_loss improved from 0.09662 to 0.09623, saving model to result/models/test_model_DNN_135_0.980_0.096235.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9800\n","Epoch 136/150\n","18/25 [====================>.........] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n","Epoch 136: val_loss improved from 0.09623 to 0.09508, saving model to result/models/test_model_DNN_136_0.980_0.095080.h5\n","25/25 [==============================] - 1s 25ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9800\n","Epoch 137/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 137: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9800\n","Epoch 138/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 138: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9800\n","Epoch 139/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n","Epoch 139: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9800\n","Epoch 140/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.1077 - accuracy: 0.9969\n","Epoch 140: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0877 - accuracy: 0.9975 - val_loss: 0.0957 - val_accuracy: 0.9800\n","Epoch 141/150\n","21/25 [========================>.....] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n","Epoch 141: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9800\n","Epoch 142/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 142: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9800\n","Epoch 143/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n","Epoch 143: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9700\n","Epoch 144/150\n","22/25 [=========================>....] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n","Epoch 144: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9700\n","Epoch 145/150\n","17/25 [===================>..........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n","Epoch 145: val_loss did not improve from 0.09508\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9800\n","Epoch 146/150\n","18/25 [====================>.........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n","Epoch 146: val_loss improved from 0.09508 to 0.09423, saving model to result/models/test_model_DNN_146_0.990_0.094233.h5\n","25/25 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9900\n","Epoch 147/150\n","23/25 [==========================>...] - ETA: 0s - loss: 0.2546 - accuracy: 0.9565\n","Epoch 147: val_loss did not improve from 0.09423\n","25/25 [==============================] - 0s 10ms/step - loss: 0.2364 - accuracy: 0.9597 - val_loss: 0.1364 - val_accuracy: 0.9600\n","Epoch 148/150\n","25/25 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n","Epoch 148: val_loss did not improve from 0.09423\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9700\n","Epoch 149/150\n","20/25 [=======================>......] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n","Epoch 149: val_loss did not improve from 0.09423\n","25/25 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9700\n","Epoch 150/150\n","19/25 [=====================>........] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n","Epoch 150: val_loss did not improve from 0.09423\n","25/25 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9700\n","2022-08-15 07:42:19.503741: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"]}],"source":["!python main.py --config config/config.yaml --data_dir Data/LibPNG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4037,"status":"ok","timestamp":1659340183189,"user":{"displayName":"Haojun Liu","userId":"13755718293357117199"},"user_tz":-480},"id":"WmZa8RMk9teL","outputId":"a019c3cd-a1c3-455a-b617-b21662a33d85"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-4-4a3f57d5652e>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.test.is_gpu_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Ikq0K74FYcu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fm1pLBOENRKq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyM+dK9Q/TzHsP+lJ1McHN8s"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}